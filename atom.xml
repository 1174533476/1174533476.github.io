<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JellyGoGo Blog</title>
  <subtitle>扯淡,发呆,思考之处</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://jellygogo.com/"/>
  <updated>2017-01-18T05:39:48.787Z</updated>
  <id>http://jellygogo.com/</id>
  
  <author>
    <name>Gordon Young</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数学基础</title>
    <link href="http://jellygogo.com/2017/01/07/%E6%A6%82%E7%8E%87%E8%AE%BA%20%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%20%E7%9F%A9%E9%98%B5%E7%AD%89%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <id>http://jellygogo.com/2017/01/07/概率论 数理统计 矩阵等数学基础/</id>
    <published>2017-01-07T15:00:26.000Z</published>
    <updated>2017-01-18T05:39:48.787Z</updated>
    
    <content type="html">&lt;h1 id=&quot;统计概述&quot;&gt;&lt;a href=&quot;#统计概述&quot; class=&quot;headerlink&quot; title=&quot;统计概述&quot;&gt;&lt;/a&gt;统计概述&lt;/h1&gt;&lt;p&gt;统计学可分为：描述统计学与推断统计学&lt;/p&gt;
&lt;h1 id=&quot;统计学概念&quot;&gt;&lt;a href=&quot;#统计学概念&quot; class=&quot;headerlink&quot; title=&quot;统计学概念&quot;&gt;&lt;/a&gt;统计学概念&lt;/h1&gt;&lt;h2 id=&quot;集中趋势描述&quot;&gt;&lt;a href=&quot;#集中趋势描述&quot; class=&quot;headerlink&quot; title=&quot;集中趋势描述&quot;&gt;&lt;/a&gt;集中趋势描述&lt;/h2&gt;&lt;p&gt;均值（优点实用性强，缺点容易受极端值影响） 中位数（不受极端值影响，缺乏敏感性） 众数（代表性好，有集中趋势，不受极端值影响，但可能会有多个） 各有优劣&lt;/p&gt;
&lt;h2 id=&quot;离散程度描述&quot;&gt;&lt;a href=&quot;#离散程度描述&quot; class=&quot;headerlink&quot; title=&quot;离散程度描述&quot;&gt;&lt;/a&gt;离散程度描述&lt;/h2&gt;&lt;p&gt;极差 最大值-最小值，简单地描述数据的范围大小&lt;br&gt;方差 数据离中心越远越离散&lt;br&gt;标准差 方差的开方&lt;/p&gt;
&lt;h2 id=&quot;图表类型&quot;&gt;&lt;a href=&quot;#图表类型&quot; class=&quot;headerlink&quot; title=&quot;图表类型&quot;&gt;&lt;/a&gt;图表类型&lt;/h2&gt;&lt;p&gt;直方图 频数直方图。根据频数分布表，可以画出频数直方图。频数作为纵坐标，成绩作为横坐标。通过直方图可以对成绩的分布有了一个直观的印象&lt;br&gt;茎叶图：茎叶图可以在保留全部数据信息的情冴下，直观地显示出数据的分布情冴&lt;br&gt;折线图：以时间为横坐标，变量为纵坐标，反映变量随时间推秱的变化趋势&lt;br&gt;柱形图：显示一段时间内的数据变化或显示各项乊间的比较情冴&lt;br&gt;饼图（饼状图），根据各项所占百分比决定在饼图中的扇形面积。简单易懂，通俗明了，可以更加形象地看出各个项目所占的比例大小&lt;br&gt;箱线图：&lt;br&gt;下四分位数：Q1，将所有数据按照从小到大的顺序排序排在第25%位置的数字&lt;br&gt;上四分位数：Q3，将所有数据按照从小到大的顺序排序排在第75%位置的数字&lt;br&gt;四分位距：IQR，等于Q3-Q1，衡量数据离散程度的一个统计量&lt;br&gt;异常点：小于Q1－1.5IQR或大于Q3+1.5IQR的值&lt;br&gt;上边缘：除异常点以外的数据中的最大值&lt;br&gt;下边缘：除异常点以外的数据中的最小值&lt;/p&gt;
&lt;p&gt;[图片 20170107153417.jpg]&lt;/p&gt;
&lt;h1 id=&quot;概率基础知识&quot;&gt;&lt;a href=&quot;#概率基础知识&quot; class=&quot;headerlink&quot; title=&quot;概率基础知识&quot;&gt;&lt;/a&gt;概率基础知识&lt;/h1&gt;&lt;h2 id=&quot;概率学概念&quot;&gt;&lt;a href=&quot;#概率学概念&quot; class=&quot;headerlink&quot; title=&quot;概率学概念&quot;&gt;&lt;/a&gt;概率学概念&lt;/h2&gt;&lt;p&gt;随机试验：具有以下特点： 1. 可以在相同的条件下重复进行 2. 试验的可能结果不止一个，但在试验前可以知道所有可能结果 3. 试验前丌能确定哪个结果会出现，拥有以上3个特点的试验称为随机试验&lt;br&gt;样本空间：对于随机试验E，E的所有可能结果组成的集合称为E的样本空间，记为S。其中，S中的&lt;br&gt;元素，即E的每个可能结果，称为样本点。&lt;/p&gt;
&lt;p&gt;事件：我们称试验E的样本空间Ｓ的某个子集为Ｅ的随机事件，简称事件。一般用大写字母Ａ，Ｂ，Ｃ……表示。&lt;br&gt;必然事件：在每个试验中一定会发生的事件&lt;br&gt;不可能事件：在每个试验中一定不会发生的事件,用∅ 表示。&lt;br&gt;事件关系：&lt;br&gt;[图片]&lt;/p&gt;
&lt;p&gt;事件运算定律&lt;br&gt;交换律 结合律 分配率&lt;br&gt;德摩根律：&lt;br&gt;图片 20170107162859.jpg&lt;/p&gt;
&lt;p&gt;频率：&lt;/p&gt;
&lt;h2 id=&quot;概率模型&quot;&gt;&lt;a href=&quot;#概率模型&quot; class=&quot;headerlink&quot; title=&quot;概率模型&quot;&gt;&lt;/a&gt;概率模型&lt;/h2&gt;&lt;p&gt;古典概型：对于试验E，若满足：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;试验的样本空间只包含有限个元素&lt;/li&gt;
&lt;li&gt;试验中每个基本事件发生的可能性相同，即每个基本事件发生的概率相等&lt;br&gt;则称这样的试验E为古典概型，也叫等可能概型&lt;br&gt;几何概型：在这个模型下，随机实验所有可能的结果是无限的，并且每个基本结果发生的概率是相同的&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;条件概率&quot;&gt;&lt;a href=&quot;#条件概率&quot; class=&quot;headerlink&quot; title=&quot;条件概率&quot;&gt;&lt;/a&gt;条件概率&lt;/h2&gt;&lt;p&gt;已知某个事件A发生的条件下，另一个事件B发生的概率称为条件概率，记为P(B|A)&lt;br&gt;P（A） p（B） p(AB)&lt;br&gt;p(B|A) = p(AB)/p(A)&lt;/p&gt;
&lt;h2 id=&quot;贝叶斯公式&quot;&gt;&lt;a href=&quot;#贝叶斯公式&quot; class=&quot;headerlink&quot; title=&quot;贝叶斯公式&quot;&gt;&lt;/a&gt;贝叶斯公式&lt;/h2&gt;&lt;p&gt;当样本空间划分为一对对立事件B和B非时&lt;br&gt;P（B|A）&lt;br&gt;= p(AB)/p(A)&lt;br&gt;=p(A|B)p(B)/[p(A|B)p(B)+p(A|B非)p（B非）]&lt;/p&gt;
&lt;h2 id=&quot;独立性&quot;&gt;&lt;a href=&quot;#独立性&quot; class=&quot;headerlink&quot; title=&quot;独立性&quot;&gt;&lt;/a&gt;独立性&lt;/h2&gt;&lt;h2 id=&quot;随机变量&quot;&gt;&lt;a href=&quot;#随机变量&quot; class=&quot;headerlink&quot; title=&quot;随机变量&quot;&gt;&lt;/a&gt;随机变量&lt;/h2&gt;&lt;p&gt; 分为离散型与连续型&lt;br&gt;用分布律,概率密度和分布函数来表示&lt;/p&gt;
&lt;h2 id=&quot;两点分布（0-1）分布&quot;&gt;&lt;a href=&quot;#两点分布（0-1）分布&quot; class=&quot;headerlink&quot; title=&quot;两点分布（0-1）分布&quot;&gt;&lt;/a&gt;两点分布（0-1）分布&lt;/h2&gt;&lt;p&gt;试验的可能结果只分为两种情况&lt;/p&gt;
&lt;h2 id=&quot;二项分布&quot;&gt;&lt;a href=&quot;#二项分布&quot; class=&quot;headerlink&quot; title=&quot;二项分布&quot;&gt;&lt;/a&gt;二项分布&lt;/h2&gt;&lt;p&gt;二项分布是离散情况下的正态分布。&lt;/p&gt;
&lt;h2 id=&quot;分布函数&quot;&gt;&lt;a href=&quot;#分布函数&quot; class=&quot;headerlink&quot; title=&quot;分布函数&quot;&gt;&lt;/a&gt;分布函数&lt;/h2&gt;&lt;h2 id=&quot;正态分布&quot;&gt;&lt;a href=&quot;#正态分布&quot; class=&quot;headerlink&quot; title=&quot;正态分布&quot;&gt;&lt;/a&gt;正态分布&lt;/h2&gt;&lt;h2 id=&quot;二维随机变量&quot;&gt;&lt;a href=&quot;#二维随机变量&quot; class=&quot;headerlink&quot; title=&quot;二维随机变量&quot;&gt;&lt;/a&gt;二维随机变量&lt;/h2&gt;&lt;p&gt;一般，设E是一个随机试验，它的样本空间是S={e}，设X=X{e}和Y={e}是定义在S上的&lt;br&gt;随机变量，由X与Y构成的向量（X,Y）叫做二维随机向量或是二维随机变量（Two&lt;br&gt;dimensional random vector）&lt;/p&gt;
&lt;h2 id=&quot;联合分布函数&quot;&gt;&lt;a href=&quot;#联合分布函数&quot; class=&quot;headerlink&quot; title=&quot;联合分布函数&quot;&gt;&lt;/a&gt;联合分布函数&lt;/h2&gt;&lt;p&gt;设（X,Y）是二维随机变量，对于任意实数x，y，二元函数：&lt;br&gt;F(x,y)=P{(X≤x)∪(Y≤y)}=P{X≤x,Y≤y}&lt;br&gt;称为二维随机变量（X,Y）的联合分布函数(Joint probability distribution)&lt;/p&gt;
&lt;h2 id=&quot;联合分布律&quot;&gt;&lt;a href=&quot;#联合分布律&quot; class=&quot;headerlink&quot; title=&quot;联合分布律&quot;&gt;&lt;/a&gt;联合分布律&lt;/h2&gt;&lt;p&gt;对于离散型的二维随机变量（X,Y）的所有可能取值为（xi,yi），I,j=1,2,……，称P{X=xi,Y=yi}=pij，i,j=1,2，…… 为随机变量X和Y的联合分布律（ Joint distribution law ）&lt;/p&gt;
&lt;p&gt;联合分布可以唯一地确定边缘分布和条件分布&lt;/p&gt;
&lt;h2 id=&quot;条件分布&quot;&gt;&lt;a href=&quot;#条件分布&quot; class=&quot;headerlink&quot; title=&quot;条件分布&quot;&gt;&lt;/a&gt;条件分布&lt;/h2&gt;&lt;h2 id=&quot;边缘分布&quot;&gt;&lt;a href=&quot;#边缘分布&quot; class=&quot;headerlink&quot; title=&quot;边缘分布&quot;&gt;&lt;/a&gt;边缘分布&lt;/h2&gt;&lt;p&gt;边缘分布律具有一维分布律的性质&lt;br&gt;联合分布律唯一决定边缘分布律. 具体求法是将联合分布律写成表格形式, 然后各行分&lt;br&gt;别相加得关于X的分布律；各列相加得Y的分布律&lt;/p&gt;
&lt;h1 id=&quot;数学期望&quot;&gt;&lt;a href=&quot;#数学期望&quot; class=&quot;headerlink&quot; title=&quot;数学期望&quot;&gt;&lt;/a&gt;数学期望&lt;/h1&gt;&lt;p&gt;随机变量的期望值=均值&lt;br&gt;例如&lt;br&gt;X的期望值：8&lt;em&gt;0.3+9&lt;/em&gt;0.1+10&lt;em&gt;0.6=9.3&lt;br&gt;Y的期望值：8&lt;/em&gt;0.2+9&lt;em&gt;0.5+10&lt;/em&gt;0.3=9.1&lt;br&gt;概率*值的连加和&lt;br&gt;二项分布的数学期望&lt;br&gt;连续型随机变量的数学期望&lt;br&gt;均匀分布的数学期望&lt;br&gt;正态分布的数学期望&lt;/p&gt;
&lt;h2 id=&quot;数学期望的性质&quot;&gt;&lt;a href=&quot;#数学期望的性质&quot; class=&quot;headerlink&quot; title=&quot;数学期望的性质&quot;&gt;&lt;/a&gt;数学期望的性质&lt;/h2&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;统计概述&quot;&gt;&lt;a href=&quot;#统计概述&quot; class=&quot;headerlink&quot; title=&quot;统计概述&quot;&gt;&lt;/a&gt;统计概述&lt;/h1&gt;&lt;p&gt;统计学可分为：描述统计学与推断统计学&lt;/p&gt;
&lt;h1 id=&quot;统计学概念&quot;&gt;&lt;a href=&quot;#统计学概念&quot; class=&quot;
    
    </summary>
    
    
      <category term="数学，概率论，矩阵，统计" scheme="http://jellygogo.com/tags/%E6%95%B0%E5%AD%A6%EF%BC%8C%E6%A6%82%E7%8E%87%E8%AE%BA%EF%BC%8C%E7%9F%A9%E9%98%B5%EF%BC%8C%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>考研复试准备</title>
    <link href="http://jellygogo.com/2017/01/01/%E5%A4%8D%E8%AF%95%E5%87%86%E5%A4%87/"/>
    <id>http://jellygogo.com/2017/01/01/复试准备/</id>
    <published>2017-01-01T15:00:26.000Z</published>
    <updated>2017-01-16T12:36:28.341Z</updated>
    
    <content type="html">&lt;p&gt;会的和打算接下来学的&lt;br&gt;1.熟悉hadoop pig hive hbase等工具的使用，熟悉mapreduce编写基本数据分析的流程，&lt;br&gt;2.熟悉linux的基本使用&lt;br&gt;3.熟练使用java语言，有过一年多java web开发与学习的经历；熟悉python语言的使用；熟悉简单shell脚本的编写&lt;br&gt;4.了解基本数据挖掘的相关知识，自学过机器学习相关教程&lt;br&gt;5.对技术抱有热情，期待挑战，&lt;/p&gt;
&lt;h1 id=&quot;复试英语&quot;&gt;&lt;a href=&quot;#复试英语&quot; class=&quot;headerlink&quot; title=&quot;复试英语&quot;&gt;&lt;/a&gt;复试英语&lt;/h1&gt;&lt;h2 id=&quot;听力题型&quot;&gt;&lt;a href=&quot;#听力题型&quot; class=&quot;headerlink&quot; title=&quot;听力题型&quot;&gt;&lt;/a&gt;听力题型&lt;/h2&gt;&lt;p&gt;1.小对话 语速较快，贴近生活&lt;br&gt;2.长对话 生活化的 与学术化的&lt;br&gt;3.短文 记述文与说明文&lt;br&gt;4.讲座 难度最大&lt;br&gt;5.听力和填空 &lt;/p&gt;
&lt;h2 id=&quot;学生目前存在的问题&quot;&gt;&lt;a href=&quot;#学生目前存在的问题&quot; class=&quot;headerlink&quot; title=&quot;学生目前存在的问题&quot;&gt;&lt;/a&gt;学生目前存在的问题&lt;/h2&gt;&lt;p&gt;1.思维问题 回去继续复习考研词汇，注重拼读而不是拼写&lt;br&gt;2.发音的精准程度&lt;br&gt;3.英式发音与美式发音&lt;br&gt;4.连读的规矩&lt;br&gt;5.重读与弱读&lt;/p&gt;
&lt;h2 id=&quot;口语题型&quot;&gt;&lt;a href=&quot;#口语题型&quot; class=&quot;headerlink&quot; title=&quot;口语题型&quot;&gt;&lt;/a&gt;口语题型&lt;/h2&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;会的和打算接下来学的&lt;br&gt;1.熟悉hadoop pig hive hbase等工具的使用，熟悉mapreduce编写基本数据分析的流程，&lt;br&gt;2.熟悉linux的基本使用&lt;br&gt;3.熟练使用java语言，有过一年多java web开发与学习的经历；熟悉python语言的
    
    </summary>
    
    
      <category term="英语，复试" scheme="http://jellygogo.com/tags/%E8%8B%B1%E8%AF%AD%EF%BC%8C%E5%A4%8D%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习（1）</title>
    <link href="http://jellygogo.com/2016/12/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%801/"/>
    <id>http://jellygogo.com/2016/12/31/机器学习基础1/</id>
    <published>2016-12-31T15:52:42.000Z</published>
    <updated>2017-01-16T13:41:47.248Z</updated>
    
    <content type="html">&lt;h1 id=&quot;机器学习算法基础学习&quot;&gt;&lt;a href=&quot;#机器学习算法基础学习&quot; class=&quot;headerlink&quot; title=&quot;机器学习算法基础学习&quot;&gt;&lt;/a&gt;机器学习算法基础学习&lt;/h1&gt;&lt;p&gt;主要侧重点是在将机器学习算法用于大数据挖掘，会使用R python MATLAB hadoop Mahout等工具&lt;/p&gt;
&lt;h2 id=&quot;机器学习概述&quot;&gt;&lt;a href=&quot;#机器学习概述&quot; class=&quot;headerlink&quot; title=&quot;机器学习概述&quot;&gt;&lt;/a&gt;机器学习概述&lt;/h2&gt;&lt;p&gt;机器学习指的是一门多领域交叉学科。专门研究计算机或其它软硬件设备怎样模拟或&lt;br&gt;实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改&lt;br&gt;善自身的性能。&lt;br&gt;机器学习是人工智能研究的核心内容。（新瓶装旧酒） 它的应用已遍及人工智能的各个分支，如专家系统、自动推理、自然语言理解、模式识别、计算机视觉、智能机器人等领域&lt;br&gt;机器学习在数据挖掘里被大量使用，其技术内涵几乎通用，可以看作同一座山峰在不同视角下的侧影。&lt;/p&gt;
&lt;h2 id=&quot;机器学习比较灵活的领域&quot;&gt;&lt;a href=&quot;#机器学习比较灵活的领域&quot; class=&quot;headerlink&quot; title=&quot;机器学习比较灵活的领域&quot;&gt;&lt;/a&gt;机器学习比较灵活的领域&lt;/h2&gt;&lt;p&gt;数据分析和数据挖掘：机器学习实现一套工具、方法或程式，从现实世界的海量数据里提炼出有价值的知识，规则和模式。并把该提炼成果应用到前台系统，辅助业务的进行，使其达到更好的效果，例如推荐，辅助决策（沙盘推演，博弈，预测结果），精准辨别，参于服务等，使到业务能产生更大的效益&lt;br&gt;图像和语音识别：语音输入，OCR，手写输入，通讯监控，车牌识别，指纹识别，虹膜识别，脸像识别&lt;br&gt;智慧机器，机器人：生产线机器人，人机对话，电脑博弈&lt;/p&gt;
&lt;h2 id=&quot;典型应用场景&quot;&gt;&lt;a href=&quot;#典型应用场景&quot; class=&quot;headerlink&quot; title=&quot;典型应用场景&quot;&gt;&lt;/a&gt;典型应用场景&lt;/h2&gt;&lt;p&gt;推荐系统：图书推荐 电影推荐 商品推荐&lt;br&gt;贝叶斯分类：判定垃圾邮件 网站自动分类&lt;br&gt;频率挖掘&lt;br&gt;语音识别&lt;br&gt;图像识别&lt;/p&gt;
&lt;h2 id=&quot;常用软件&quot;&gt;&lt;a href=&quot;#常用软件&quot; class=&quot;headerlink&quot; title=&quot;常用软件&quot;&gt;&lt;/a&gt;常用软件&lt;/h2&gt;&lt;p&gt;R&lt;br&gt;python&lt;br&gt;MATLAB 具有功能十分强大的神经网络包&lt;br&gt;WEKA 免费的，非商业化的，基于JAVA环境下开源的机器学习以及数据挖掘软件&lt;/p&gt;
&lt;h1 id=&quot;线性回归与Logistic&quot;&gt;&lt;a href=&quot;#线性回归与Logistic&quot; class=&quot;headerlink&quot; title=&quot;线性回归与Logistic&quot;&gt;&lt;/a&gt;线性回归与Logistic&lt;/h1&gt;&lt;p&gt;回归分析就是利用样本（已知数据），产生拟合方程，从而（对未知数据）进行预测&lt;br&gt;用途：预测，判别合理性&lt;br&gt;例子：利用身高预测体重；利用广告费用预测商品销售额；等等.&lt;br&gt;线性回归分析：一元线性；多元线性；广义线性&lt;br&gt;非线性回归分析&lt;br&gt;困难：选定变量（多元），避免多重共线性，观察拟合方程，避免过度拟合，检验模&lt;br&gt;型是否合理&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;机器学习算法基础学习&quot;&gt;&lt;a href=&quot;#机器学习算法基础学习&quot; class=&quot;headerlink&quot; title=&quot;机器学习算法基础学习&quot;&gt;&lt;/a&gt;机器学习算法基础学习&lt;/h1&gt;&lt;p&gt;主要侧重点是在将机器学习算法用于大数据挖掘，会使用R python MATL
    
    </summary>
    
    
      <category term="机器学习" scheme="http://jellygogo.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop从零开始重学1</title>
    <link href="http://jellygogo.com/2016/12/31/Hadoop%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E9%87%8D%E5%AD%A6(1)hadoop%20pig%20hive%20hbase%E5%AE%89%E8%A3%85/"/>
    <id>http://jellygogo.com/2016/12/31/Hadoop从零开始重学(1)hadoop pig hive hbase安装/</id>
    <published>2016-12-31T15:52:21.000Z</published>
    <updated>2017-01-18T12:32:31.163Z</updated>
    
    <content type="html">&lt;p&gt;&lt;strong&gt;不论何时，请勿好高骛远！写给曾经自我膨胀的我！&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;hadoop基础与安装&quot;&gt;&lt;a href=&quot;#hadoop基础与安装&quot; class=&quot;headerlink&quot; title=&quot;hadoop基础与安装&quot;&gt;&lt;/a&gt;hadoop基础与安装&lt;/h1&gt;&lt;h2 id=&quot;hadoop子项目家族&quot;&gt;&lt;a href=&quot;#hadoop子项目家族&quot; class=&quot;headerlink&quot; title=&quot;hadoop子项目家族&quot;&gt;&lt;/a&gt;hadoop子项目家族&lt;/h2&gt;&lt;p&gt;我接触与使用过的系列&lt;/p&gt;
&lt;h2 id=&quot;streaming&quot;&gt;&lt;a href=&quot;#streaming&quot; class=&quot;headerlink&quot; title=&quot;streaming&quot;&gt;&lt;/a&gt;streaming&lt;/h2&gt;&lt;p&gt;使得命令行脚本都可以通过streaming来调用mapreduce框架&lt;br&gt;HDFS:&lt;br&gt;Namenode：HDFS的守护程序&lt;br&gt;Secondary Namenode&lt;br&gt;DataNode：数据节点&lt;br&gt;JobTracker：用于处理作业的后台程序&lt;br&gt;TaskTracker：与DataNode结合，管理各自节点上的task&lt;br&gt;HBase： 非关系型数据库&lt;br&gt;Pig：与hive类似，编写快速查找的命令 轻量级脚本语言&lt;br&gt;Hive：使可以使用sql语言来查找数据&lt;br&gt;MAPReduce模型：&lt;br&gt;Mahout机器学习平台&lt;/p&gt;
&lt;p&gt;ZooKeeper&lt;/p&gt;
&lt;h1 id=&quot;hadoop的完全分布式安装&quot;&gt;&lt;a href=&quot;#hadoop的完全分布式安装&quot; class=&quot;headerlink&quot; title=&quot;hadoop的完全分布式安装&quot;&gt;&lt;/a&gt;hadoop的完全分布式安装&lt;/h1&gt;&lt;p&gt;在虚拟机下安装三台linux主机；对之实现ssh免秘密登录；创建grid用户作为hadoop安装用户；&lt;/p&gt;
&lt;p&gt;hadoop1.x完全分布式模式的安装和配置&lt;br&gt;配置hosts文件&lt;br&gt;建立hadoop运行账号&lt;br&gt;配置ssh免密码连入&lt;br&gt;下载幵解压hadoop安装包&lt;br&gt;配置namenode，修改site文件&lt;br&gt;配置hadoop-env.sh&lt;br&gt;配置masters和slaves文件&lt;br&gt;向各节点复制hadoop&lt;br&gt;格式化namenode&lt;br&gt;吭劢hadoop&lt;br&gt;用jps检验各后台迚程是否成功启动&lt;/p&gt;
&lt;p&gt;hadoop2.x安装&lt;br&gt;安装JDK&lt;br&gt;编辑hosts文件&lt;br&gt;关闭防火墙&lt;br&gt;部署免密码ssh&lt;br&gt;下载hadoop 2.x幵解压&lt;br&gt;修改配置文件&lt;br&gt;分步hadoop到各个节点&lt;br&gt;启动集群&lt;/p&gt;
&lt;p&gt;涉及到的配置文件有7个：&lt;br&gt;~/hadoop-2.2.0/etc/hadoop/hadoop-env.sh&lt;br&gt;~/hadoop-2.2.0/etc/hadoop/yarn-env.sh&lt;br&gt;~/hadoop-2.2.0/etc/hadoop/slaves&lt;br&gt;~/hadoop-2.2.0/etc/hadoop/core-site.xml&lt;br&gt;~/hadoop-2.2.0/etc/hadoop/hdfs-site.xml&lt;br&gt;~/hadoop-2.2.0/etc/hadoop/mapred-site.xml&lt;br&gt;~/hadoop-2.2.0/etc/hadoop/yarn-site.xml&lt;br&gt;以上个别文件默认不存在的，可以复制相应的template文件获得。&lt;br&gt;&lt;a href=&quot;http://www.w2bc.com/Article/19645&quot; title=&quot;详细配置&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.w2bc.com/Article/19645&lt;/a&gt;&lt;br&gt;格式化namenode：./bin/hdfs namenode –format&lt;br&gt;启动hdfs: ./sbin/start-dfs.sh&lt;br&gt;此时在h1上面运行的迚程有：namenode，secondarynamenode&lt;br&gt;h2和h3上面运行的迚程有：datanode&lt;br&gt;吭劢yarn: ./sbin/start-yarn.sh&lt;br&gt;此时在h1上运行的迚程有：namenode，secondarynamenode，resourcemanager&lt;br&gt;h2和h3上面运行的迚程有：datanode，nodemanager&lt;br&gt;ps：scp -r hadoop-2.5.2 grid@h1:/home/grid/hadoop &lt;/p&gt;
&lt;p&gt;终于~安装成功&lt;/p&gt;
&lt;h1 id=&quot;HDFS&quot;&gt;&lt;a href=&quot;#HDFS&quot; class=&quot;headerlink&quot; title=&quot;HDFS&quot;&gt;&lt;/a&gt;HDFS&lt;/h1&gt;&lt;p&gt;NameNode&lt;br&gt;DataNode&lt;br&gt;事务日志&lt;br&gt;映像文件&lt;br&gt;SecondaryNameNode&lt;/p&gt;
&lt;h2 id=&quot;读取数据流程&quot;&gt;&lt;a href=&quot;#读取数据流程&quot; class=&quot;headerlink&quot; title=&quot;读取数据流程&quot;&gt;&lt;/a&gt;读取数据流程&lt;/h2&gt;&lt;p&gt;客户端要访问HDFS中的一个文件&lt;br&gt;首先从namenode获得组成返个文件的数据块位置列表&lt;br&gt;根据列表知道存储数据块的datanode&lt;br&gt;访问datanode获取数据&lt;br&gt;Namenode并不直接参与数据实际传输&lt;/p&gt;
&lt;h2 id=&quot;写入数据流程&quot;&gt;&lt;a href=&quot;#写入数据流程&quot; class=&quot;headerlink&quot; title=&quot;写入数据流程&quot;&gt;&lt;/a&gt;写入数据流程&lt;/h2&gt;&lt;p&gt;客户端请求namenode创建新文件&lt;br&gt;客户端将数据写入DFSOutputStream&lt;br&gt;建立pipeline依次将目标数据块写入各个datanode，建立多个副本&lt;/p&gt;
&lt;h2 id=&quot;hdfs常用命令&quot;&gt;&lt;a href=&quot;#hdfs常用命令&quot; class=&quot;headerlink&quot; title=&quot;hdfs常用命令&quot;&gt;&lt;/a&gt;hdfs常用命令&lt;/h2&gt;&lt;p&gt;查看目录&lt;br&gt;[grid@h1 hadoop-2.5.2]$ bin/hadoop fs -ls /&lt;br&gt;Found 1 items&lt;br&gt;-rw-r–r–   3 grid supergroup         12 2017-01-16 10:21 /test&lt;/p&gt;
&lt;p&gt;上传&lt;br&gt;bin/hadoop fs -put test.txt ./in&lt;/p&gt;
&lt;p&gt;将HDFS的文件复制到本地&lt;br&gt;bin/hadoop fs -get /fromHDFS /filesystem&lt;/p&gt;
&lt;p&gt;删除HDFS下面的文档&lt;br&gt;bin/hadoop fs -rmr /fromHDFS&lt;/p&gt;
&lt;p&gt;输出某个文件的内容&lt;br&gt;[grid@h1 hadoop-2.5.2]$ bin/hadoop fs -cat /test&lt;br&gt;hello world&lt;/p&gt;
&lt;p&gt;查看HDFS基本统计信息&lt;br&gt;[grid@h1 hadoop-2.5.2]$ bin/hadoop dfsadmin -report&lt;br&gt;DEPRECATED: Use of this script to execute hdfs command is deprecated.&lt;br&gt;Instead use the hdfs command for it.&lt;/p&gt;
&lt;p&gt;Configured Capacity: 40147877888 (37.39 GB)&lt;br&gt;Present Capacity: 31229685760 (29.08 GB)&lt;br&gt;DFS Remaining: 31229644800 (29.08 GB)&lt;br&gt;DFS Used: 40960 (40 KB)&lt;br&gt;DFS Used%: 0.00%&lt;br&gt;Under replicated blocks: 1&lt;br&gt;Blocks with corrupt replicas: 0&lt;br&gt;Missing blocks: 0&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Live datanodes (2):&lt;/p&gt;
&lt;p&gt;Name: 192.168.146.100:50010 (h3)&lt;br&gt;Hostname: h3&lt;br&gt;Decommission Status : Normal&lt;br&gt;Configured Capacity: 20073938944 (18.70 GB)&lt;br&gt;DFS Used: 20480 (20 KB)&lt;br&gt;Non DFS Used: 4274286592 (3.98 GB)&lt;br&gt;DFS Remaining: 15799631872 (14.71 GB)&lt;br&gt;DFS Used%: 0.00%&lt;br&gt;DFS Remaining%: 78.71%&lt;br&gt;Configured Cache Capacity: 0 (0 B)&lt;br&gt;Cache Used: 0 (0 B)&lt;br&gt;Cache Remaining: 0 (0 B)&lt;br&gt;Cache Used%: 100.00%&lt;br&gt;Cache Remaining%: 0.00%&lt;br&gt;Xceivers: 1&lt;br&gt;Last contact: Tue Jan 17 04:50:33 PST 2017&lt;/p&gt;
&lt;p&gt;Name: 192.168.146.101:50010 (h2)&lt;br&gt;Hostname: h2&lt;br&gt;Decommission Status : Normal&lt;br&gt;Configured Capacity: 20073938944 (18.70 GB)&lt;br&gt;DFS Used: 20480 (20 KB)&lt;br&gt;Non DFS Used: 4643905536 (4.32 GB)&lt;br&gt;DFS Remaining: 15430012928 (14.37 GB)&lt;br&gt;DFS Used%: 0.00%&lt;br&gt;DFS Remaining%: 76.87%&lt;br&gt;Configured Cache Capacity: 0 (0 B)&lt;br&gt;Cache Used: 0 (0 B)&lt;br&gt;Cache Remaining: 0 (0 B)&lt;br&gt;Cache Used%: 100.00%&lt;br&gt;Cache Remaining%: 0.00%&lt;br&gt;Xceivers: 1&lt;br&gt;Last contact: Tue Jan 17 04:50:31 PST 2017&lt;/p&gt;
&lt;h1 id=&quot;Pig安装与基本操作&quot;&gt;&lt;a href=&quot;#Pig安装与基本操作&quot; class=&quot;headerlink&quot; title=&quot;Pig安装与基本操作&quot;&gt;&lt;/a&gt;Pig安装与基本操作&lt;/h1&gt;&lt;h2 id=&quot;Grunt-shell命令&quot;&gt;&lt;a href=&quot;#Grunt-shell命令&quot; class=&quot;headerlink&quot; title=&quot;Grunt shell命令&quot;&gt;&lt;/a&gt;Grunt shell命令&lt;/h2&gt;&lt;p&gt;“cat” … 输出&lt;br&gt;“clear” …&lt;br&gt;“fs” …&lt;br&gt;“sh” …  &lt;strong&gt;执行操作系统命令&lt;/strong&gt;&lt;br&gt;    grunt&amp;gt; sh jps&lt;br&gt;    5156 SecondaryNameNode&lt;br&gt;    34325 RunJar&lt;br&gt;    34441 Jps&lt;br&gt;    4877 NameNode&lt;br&gt;“cd” …  打开&lt;br&gt;“cp” …&lt;br&gt;“copyFromLocal” … 从本地输入&lt;br&gt;“copyToLocal” …    输出到本地&lt;br&gt;“dump” …&lt;br&gt;“\d” …&lt;br&gt;“describe” …&lt;br&gt;“\de” …&lt;br&gt;“aliases” …&lt;br&gt;“explain” …&lt;br&gt;“\e” …&lt;br&gt;“help” …&lt;br&gt;“history” …&lt;br&gt;“kill” …&lt;br&gt;“ls” …  显示列表内的信息&lt;br&gt;“mv” …&lt;br&gt;“mkdir” …&lt;br&gt;“pwd” …&lt;br&gt;“quit” …&lt;br&gt;“\q” …&lt;br&gt;“register” …&lt;br&gt;“rm” …&lt;br&gt;“rmf” …&lt;br&gt;“set” …&lt;br&gt;“illustrate” …&lt;br&gt;“\i” …&lt;br&gt;“run” …&lt;br&gt;“exec” …&lt;br&gt;“%default” …&lt;br&gt;“%declare” …&lt;br&gt;“scriptDone” …&lt;br&gt;“” …&lt;br&gt;“” …&lt;/p&gt;
&lt;p&gt;&lt;eol&gt; …&lt;br&gt;“;” …&lt;/eol&gt;&lt;/p&gt;
&lt;h2 id=&quot;pig数据模型&quot;&gt;&lt;a href=&quot;#pig数据模型&quot; class=&quot;headerlink&quot; title=&quot;pig数据模型&quot;&gt;&lt;/a&gt;pig数据模型&lt;/h2&gt;&lt;p&gt;Bag：表&lt;br&gt;Tuple：行，记录&lt;br&gt;Field：属性&lt;br&gt;Pig不要求同一个bag里面的各个tuple有相同数量或相同类型的field&lt;/p&gt;
&lt;h2 id=&quot;Pig-latin常用语句&quot;&gt;&lt;a href=&quot;#Pig-latin常用语句&quot; class=&quot;headerlink&quot; title=&quot;Pig latin常用语句&quot;&gt;&lt;/a&gt;Pig latin常用语句&lt;/h2&gt;&lt;p&gt;LOAD：指出载入数据的方法&lt;br&gt;FOREACH：逐行扫描迚行某种处理&lt;br&gt;FILTER：过滤行&lt;br&gt;DUMP：把结果显示到屏幕&lt;br&gt;STORE：把结果保存到文件&lt;/p&gt;
&lt;h2 id=&quot;Pig里面进行操作&quot;&gt;&lt;a href=&quot;#Pig里面进行操作&quot; class=&quot;headerlink&quot; title=&quot;Pig里面进行操作&quot;&gt;&lt;/a&gt;Pig里面进行操作&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://guoyunsky.iteye.com/blog/1317084&quot; title=&quot;各种sql在pig中的实现&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://guoyunsky.iteye.com/blog/1317084&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;不论何时，请勿好高骛远！写给曾经自我膨胀的我！&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;hadoop基础与安装&quot;&gt;&lt;a href=&quot;#hadoop基础与安装&quot; class=&quot;headerlink&quot; title=&quot;hadoop基础与安装&quot;&gt;&lt;/a&gt;hadoo
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="安装，虚拟机" scheme="http://jellygogo.com/tags/%E5%AE%89%E8%A3%85%EF%BC%8C%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>Python 基础语法知识</title>
    <link href="http://jellygogo.com/2016/12/31/Python-%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A01/"/>
    <id>http://jellygogo.com/2016/12/31/Python-基础学习1/</id>
    <published>2016-12-31T15:00:26.000Z</published>
    <updated>2017-01-18T04:57:07.083Z</updated>
    
    <content type="html">&lt;h1 id=&quot;基础语法部分&quot;&gt;&lt;a href=&quot;#基础语法部分&quot; class=&quot;headerlink&quot; title=&quot;基础语法部分&quot;&gt;&lt;/a&gt;基础语法部分&lt;/h1&gt;&lt;p&gt;1.tab缩进语法，不像其他语言用{}&lt;br&gt;2.不需要声明变量&lt;br&gt;3.常用的语法（1）函数 函数参数  条件语句&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##函数 函数参数  条件语句
def  fun():
    print &amp;quot;hello world&amp;quot;
    a = 1000
## 999 1000 1001
    type(bool)
    if (a&amp;gt;1000) :
        print &amp;quot;Gogo&amp;quot;
    elif a&amp;lt;1000:
        print  &amp;quot;False GOGO&amp;quot;
    else:
        print &amp;quot;No&amp;quot;
    print type(True)
    print type(a)
fun()

def fun(x,y):
    print  x,y
    return x+y
print fun(2,5)
&amp;apos;&amp;apos;&amp;apos;默认值函数 而且默认值函数的参数只能在后面&amp;apos;&amp;apos;&amp;apos;
def foo(s,ss=&amp;apos;test&amp;apos;):
print s,ss

foo(1,2)
foo(1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常用的语法（2） 循环结构&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##
l = [1,2,3]
for i in l:
    print  i
for i in range(9):
    print i
a = 0
while a&amp;lt;5:
    print  a
    a = a+1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常用的语法（3）lambda&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## lambda表达式相当于只有一个return语句的精简函数
s = lambda x,y:x+y
print s(2,3)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常用的语法（4） 类的定义与调用&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Demo(object):

    def __init__(self,name,age):
        self.name = name
        self.age = age
    def __del__(self):
        print &amp;quot;delete.....&amp;quot;
    def say(self):
        print self.name
        print self.age
f1 = Demo(&amp;apos;xiaoming&amp;apos;,10)
f1.say()
print  f1.name
print  f1.age
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常用的语法（5） 列表与元组&lt;br&gt;元组（） 不可修改&lt;br&gt;列表[] 可以修改&lt;br&gt;元组列表学习链接：&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/bolike/article/details/19996667&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/bolike/article/details/19996667&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;t = (1,2,3,&amp;apos;pjjjj&amp;apos;)
print t
## &amp;apos;打印2之后的元素&amp;apos;
print t[2:]
print t[3]

l = [1,2,3,&amp;apos;pjjjj&amp;apos;]
print  l
l[2] = &amp;apos;hahahha&amp;apos;
print l
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常用的语法（6）字典 map&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;map1 = {&amp;apos;a&amp;apos;:1,&amp;apos;b&amp;apos;:2}
print map1[&amp;apos;a&amp;apos;]
print  map1
print  type(map1)
print dir(map1)
help(map1)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;常用的语法（7） type dir help 与直接打印对象&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class test:
    def __init__(self):
        pass;
    def __str__(self):
        return &amp;apos;strfun&amp;apos;
    def __say__(self):
        print &amp;apos;say function&amp;apos;
dd = test()
print  dd
print  type(dd)
print dir(dd)
help(dd)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;打印的内容为：&lt;br&gt;    C:\Python27\python.exe D:/PythonSrc/20170101test/test1.py&lt;br&gt;    strfun&lt;br&gt;    &lt;type &#39;instance&#39;=&quot;&quot;&gt;&lt;br&gt;    [‘&lt;strong&gt;doc&lt;/strong&gt;‘, ‘&lt;strong&gt;init&lt;/strong&gt;‘, ‘&lt;strong&gt;module&lt;/strong&gt;‘, ‘&lt;strong&gt;say&lt;/strong&gt;‘, ‘&lt;strong&gt;str&lt;/strong&gt;‘]&lt;br&gt;    Help on instance of test in module &lt;strong&gt;main&lt;/strong&gt;:&lt;/type&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class test
 |  Methods defined here:
 |  
 |  __init__(self)
 |  
 |  __say__(self)
 |  
 |  __str__(self)


Process finished with exit code 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;homework1：&lt;br&gt;分别写2个函数打印出当前目录中两张图片中的图形，在用户进入后通过输入不同的代码则打印对应的画面或退出程序。&lt;br&gt;如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;  1. print love
&amp;gt;&amp;gt;  2. print feb
&amp;gt;&amp;gt;  3. exit


def printlove():
    print &amp;apos;love&amp;apos;;

def printfeb():
    print&amp;apos;f2&amp;apos;;

print &amp;apos;1. print love&amp;apos;
print &amp;apos;2. print feb&amp;apos;
print &amp;apos;3. exit&amp;apos;
va = input()
if(va==1):
    printlove()
elif(va==2):
    printfeb()
else:
print &amp;apos;end------------&amp;apos;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;python数据结构&quot;&gt;&lt;a href=&quot;#python数据结构&quot; class=&quot;headerlink&quot; title=&quot;python数据结构&quot;&gt;&lt;/a&gt;python数据结构&lt;/h1&gt;&lt;h2 id=&quot;1-元组tuple&quot;&gt;&lt;a href=&quot;#1-元组tuple&quot; class=&quot;headerlink&quot; title=&quot;1.元组tuple&quot;&gt;&lt;/a&gt;1.元组tuple&lt;/h2&gt;&lt;p&gt;相当于数组，内容不可变&lt;br&gt;有序不可变的tuple有什么意义？&lt;br&gt;因为tuple不可变，所以代码更安全；内容确保不会在任意环节中被改变；通常是作为参数在函数调用时被使用，保证内容没有被所调用的函数所改变。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 将l转成元组t，将一个可迭代的对象l转换成元组t，l还能是字典
l=[1,2,3]
t = tuple(l)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;元组的成员：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;dir(tuple)&lt;br&gt;[‘&lt;strong&gt;add&lt;/strong&gt;‘, ‘&lt;strong&gt;class&lt;/strong&gt;‘, ‘&lt;strong&gt;contains&lt;/strong&gt;‘, ‘&lt;strong&gt;delattr&lt;/strong&gt;‘, ‘&lt;strong&gt;doc&lt;/strong&gt;‘, ‘&lt;strong&gt;eq&lt;/strong&gt;‘, ‘&lt;strong&gt;format&lt;/strong&gt;‘, ‘&lt;strong&gt;ge&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;getattribute&lt;/strong&gt;‘, ‘&lt;strong&gt;getitem&lt;/strong&gt;‘, ‘&lt;strong&gt;getnewargs&lt;/strong&gt;‘, ‘&lt;strong&gt;getslice&lt;/strong&gt;‘, ‘&lt;strong&gt;gt&lt;/strong&gt;‘, ‘&lt;strong&gt;hash&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;init&lt;/strong&gt;‘, ‘&lt;strong&gt;iter&lt;/strong&gt;‘, ‘&lt;strong&gt;le&lt;/strong&gt;‘, ‘&lt;strong&gt;len&lt;/strong&gt;‘, ‘&lt;strong&gt;lt&lt;/strong&gt;‘, ‘&lt;strong&gt;mul&lt;/strong&gt;‘, ‘&lt;strong&gt;ne&lt;/strong&gt;‘, ‘&lt;strong&gt;new&lt;/strong&gt;‘, ‘&lt;strong&gt;reduce&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;reduce_ex&lt;/strong&gt;‘, ‘&lt;strong&gt;repr&lt;/strong&gt;‘, ‘&lt;strong&gt;rmul&lt;/strong&gt;‘, ‘&lt;strong&gt;setattr&lt;/strong&gt;‘, ‘&lt;strong&gt;sizeof&lt;/strong&gt;‘, ‘&lt;strong&gt;str&lt;/strong&gt;‘, ‘&lt;strong&gt;subclasshook&lt;/strong&gt;‘,&lt;br&gt;‘count’, ‘index’]&lt;/p&gt;
&lt;h2 id=&quot;2-列表list&quot;&gt;&lt;a href=&quot;#2-列表list&quot; class=&quot;headerlink&quot; title=&quot;2.列表list&quot;&gt;&lt;/a&gt;2.列表list&lt;/h2&gt;&lt;p&gt;相当于可进行增删改查的元组&lt;br&gt;有序可变的list有什么意义？&lt;br&gt;可变是为了可以保存过程的中间结果，动态的保存了函数体内动态执行结果&lt;br&gt;list成员&lt;br&gt;dir(list)&lt;br&gt;[‘&lt;strong&gt;add&lt;/strong&gt;‘, ‘&lt;strong&gt;class&lt;/strong&gt;‘, ‘&lt;strong&gt;contains&lt;/strong&gt;‘, ‘&lt;strong&gt;delattr&lt;/strong&gt;‘, ‘&lt;strong&gt;delitem&lt;/strong&gt;‘, ‘&lt;strong&gt;delslice&lt;/strong&gt;‘, ‘&lt;strong&gt;doc&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;eq&lt;/strong&gt;‘, ‘&lt;strong&gt;format&lt;/strong&gt;‘, ‘&lt;strong&gt;ge&lt;/strong&gt;‘, ‘&lt;strong&gt;getattribute&lt;/strong&gt;‘, ‘&lt;strong&gt;getitem&lt;/strong&gt;‘, ‘&lt;strong&gt;getslice&lt;/strong&gt;‘, ‘&lt;strong&gt;gt&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;hash&lt;/strong&gt;‘, ‘&lt;strong&gt;iadd&lt;/strong&gt;‘, ‘&lt;strong&gt;imul&lt;/strong&gt;‘, ‘&lt;strong&gt;init&lt;/strong&gt;‘, ‘&lt;strong&gt;iter&lt;/strong&gt;‘, ‘&lt;strong&gt;le&lt;/strong&gt;‘, ‘&lt;strong&gt;len&lt;/strong&gt;‘, ‘&lt;strong&gt;lt&lt;/strong&gt;‘, ‘&lt;strong&gt;mul&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;ne&lt;/strong&gt;‘, ‘&lt;strong&gt;new&lt;/strong&gt;‘, ‘&lt;strong&gt;reduce&lt;/strong&gt;‘, ‘&lt;strong&gt;reduce_ex&lt;/strong&gt;‘, ‘&lt;strong&gt;repr&lt;/strong&gt;‘, ‘&lt;strong&gt;reversed&lt;/strong&gt;‘, ‘&lt;strong&gt;rmul&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;setattr&lt;/strong&gt;‘, ‘&lt;strong&gt;setitem&lt;/strong&gt;‘, ‘&lt;strong&gt;setslice&lt;/strong&gt;‘, ‘&lt;strong&gt;sizeof&lt;/strong&gt;‘, ‘&lt;strong&gt;str&lt;/strong&gt;‘, ‘&lt;strong&gt;subclasshook&lt;/strong&gt;‘, ‘append’,&lt;br&gt;‘count’, ‘extend’, ‘index’, ‘insert’, ‘pop’, ‘remove’, ‘reverse’, ‘sort’]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;list方法&lt;br&gt;l3=l1+l2 两个列表可以直接相加&lt;br&gt;‘count’, ‘index‘ =&amp;gt; 同 tuple&lt;br&gt;‘append‘ =&amp;gt; 追加&lt;br&gt;‘extend‘ =&amp;gt; 扩展&lt;br&gt;‘insert‘ =&amp;gt; 插入&lt;br&gt;‘pop‘ =&amp;gt; 弹出&lt;br&gt;‘remove‘ =&amp;gt; 删除&lt;br&gt;‘reverse‘ =&amp;gt; 反转&lt;br&gt;‘sort‘ =&amp;gt; 排序&lt;/p&gt;
&lt;h2 id=&quot;3-字典-dict&quot;&gt;&lt;a href=&quot;#3-字典-dict&quot; class=&quot;headerlink&quot; title=&quot;3.字典 dict&quot;&gt;&lt;/a&gt;3.字典 dict&lt;/h2&gt;&lt;p&gt;相当于java中的HashMap&lt;br&gt;无序可变的dict有什么意义？&lt;br&gt;映射key-value对通常用来作为hash存储。&lt;/p&gt;
&lt;p&gt;dict成员&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;dir(dict)&lt;br&gt;[‘&lt;strong&gt;class&lt;/strong&gt;‘, ‘&lt;strong&gt;cmp&lt;/strong&gt;‘, ‘&lt;strong&gt;contains&lt;/strong&gt;‘, ‘&lt;strong&gt;delattr&lt;/strong&gt;‘, ‘&lt;strong&gt;delitem&lt;/strong&gt;‘, ‘&lt;strong&gt;doc&lt;/strong&gt;‘, ‘&lt;strong&gt;eq&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;format&lt;/strong&gt;‘, ‘&lt;strong&gt;ge&lt;/strong&gt;‘, ‘&lt;strong&gt;getattribute&lt;/strong&gt;‘, ‘&lt;strong&gt;getitem&lt;/strong&gt;‘, ‘&lt;strong&gt;gt&lt;/strong&gt;‘, ‘&lt;strong&gt;hash&lt;/strong&gt;‘, ‘&lt;strong&gt;init&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;iter&lt;/strong&gt;‘, ‘&lt;strong&gt;le&lt;/strong&gt;‘, ‘&lt;strong&gt;len&lt;/strong&gt;‘, ‘&lt;strong&gt;lt&lt;/strong&gt;‘, ‘&lt;strong&gt;ne&lt;/strong&gt;‘, ‘&lt;strong&gt;new&lt;/strong&gt;‘, ‘&lt;strong&gt;reduce&lt;/strong&gt;‘, ‘&lt;strong&gt;reduce_ex&lt;/strong&gt;‘,&lt;br&gt;‘&lt;strong&gt;repr&lt;/strong&gt;‘, ‘&lt;strong&gt;setattr&lt;/strong&gt;‘, ‘&lt;strong&gt;setitem&lt;/strong&gt;‘, ‘&lt;strong&gt;sizeof&lt;/strong&gt;‘, ‘&lt;strong&gt;str&lt;/strong&gt;‘, ‘&lt;strong&gt;subclasshook&lt;/strong&gt;‘, ‘clear’,&lt;br&gt;‘copy’, ‘fromkeys’, ‘get’, ‘has_key’, ‘items’, ‘iteritems’, ‘iterkeys’, ‘itervalues’, ‘keys’, ‘pop’,&lt;br&gt;‘popitem’, ‘setdefault’, ‘update’, ‘values’, ‘viewitems’, ‘viewkeys’, ‘viewvalues’]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;字典的方法&lt;br&gt;‘clear’,&lt;br&gt;‘copy’,浅复制&lt;br&gt;‘fromkeys’,&lt;br&gt;‘get’,&lt;br&gt;‘has_key’,&lt;br&gt;‘items’,&lt;br&gt;‘iteritems’,&lt;br&gt;‘iterkeys’,&lt;br&gt;&lt;strong&gt;若想增加新的字典项使用下面的方法即可&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 若已存在key3，则覆盖其值
map[3] = 10086
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;4-集合-set&quot;&gt;&lt;a href=&quot;#4-集合-set&quot; class=&quot;headerlink&quot; title=&quot;4.集合 set&quot;&gt;&lt;/a&gt;4.集合 set&lt;/h2&gt;&lt;p&gt;集合操作，方便使用一些集合的运算&lt;/p&gt;
&lt;p&gt;集合的方法&lt;br&gt;‘add’, ‘clear’, ‘copy’, ‘difference’, ‘difference_update‘ =&amp;gt; -=, ‘discard’, ‘intersection’,&lt;br&gt;‘intersection_update‘ =&amp;gt; &amp;amp;=, ‘isdisjoint’, ‘issubset’, ‘issuperset’, ‘pop’, ‘remove’,&lt;br&gt;‘symmetric_difference‘, ‘symmetric_difference_update‘ =&amp;gt; ^=, ‘union’, ‘update‘=&amp;gt;&lt;br&gt;|=&lt;br&gt;非运算符版本的 update(), intersection_update(), difference_update()和&lt;br&gt;symmetric_difference_update()将会接受任意 iterable 作为参数&lt;/p&gt;
&lt;p&gt;集合的操作&lt;br&gt;a = t | s # t 和 s的并集&lt;br&gt;b = t &amp;amp; s # t 和 s的交集&lt;br&gt;c = t – s # 求差集（项在t中，但不在s中）&lt;br&gt;d = t ^ s # 对称差集（项在t戒s中，但不会同时出现在二者中）&lt;/p&gt;
&lt;h2 id=&quot;深复制与浅复制&quot;&gt;&lt;a href=&quot;#深复制与浅复制&quot; class=&quot;headerlink&quot; title=&quot;深复制与浅复制&quot;&gt;&lt;/a&gt;深复制与浅复制&lt;/h2&gt;&lt;p&gt;浅复制：只复制父对象，不会拷贝对象的内部的子对象&lt;br&gt;深复制：拷贝对象及其子对象&lt;br&gt;    Import copy&lt;br&gt;    copy.copy() ##浅复制&lt;br&gt;    copy.deepcopy() ##深复制&lt;/p&gt;
&lt;h1 id=&quot;python表达式&quot;&gt;&lt;a href=&quot;#python表达式&quot; class=&quot;headerlink&quot; title=&quot;python表达式&quot;&gt;&lt;/a&gt;python表达式&lt;/h1&gt;&lt;h2 id=&quot;运算表达式&quot;&gt;&lt;a href=&quot;#运算表达式&quot; class=&quot;headerlink&quot; title=&quot;运算表达式&quot;&gt;&lt;/a&gt;运算表达式&lt;/h2&gt;&lt;p&gt;与其他语言类似,都有这些基本表达式&lt;br&gt;算术运算符&lt;br&gt;+，-，&lt;em&gt;，/，//, %，**&lt;br&gt;赋值运算符&lt;br&gt;=, +=, -=, &lt;/em&gt;=, /=, //=, %=, **=(乘方)&lt;br&gt;比较运算符&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;, &amp;lt;, ==, !=, &amp;lt;&amp;gt;, &amp;lt;=, &amp;gt;=&lt;br&gt;逻辑运算符&lt;br&gt;not, and, or&lt;br&gt;成员运算符&lt;br&gt;in, not in, is, is not&lt;br&gt;位移运算符&lt;br&gt;&amp;lt;&amp;lt;, &amp;gt;&amp;gt;, &amp;amp;, |, ^, ~(x的按位翻转是-(x+1))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;三元表达式&quot;&gt;&lt;a href=&quot;#三元表达式&quot; class=&quot;headerlink&quot; title=&quot;三元表达式&quot;&gt;&lt;/a&gt;三元表达式&lt;/h2&gt;&lt;p&gt;不支持c语言中的三目运算符,但是可以&lt;br&gt;    a=b if b&amp;gt;c else c&lt;br&gt;精简运算&lt;/p&gt;
&lt;h2 id=&quot;列表解析表达式&quot;&gt;&lt;a href=&quot;#列表解析表达式&quot; class=&quot;headerlink&quot; title=&quot;列表解析表达式&quot;&gt;&lt;/a&gt;列表解析表达式&lt;/h2&gt;&lt;p&gt;a = [do(i) for i in iter] // 只有一个iter参数的map函数&lt;br&gt;    print [i&lt;em&gt;2 for i in range(10)]&lt;br&gt;a = [do(i) for i in iter if condition] //if 后为filter函数,过滤功能&lt;br&gt;    print [i&lt;/em&gt;2 for i in range(10) if i&amp;gt;4]&lt;br&gt;嵌套&lt;br&gt;a = [do(i, j) for in iter if condition for j in iter2 if condition2]&lt;br&gt;列表解析式相比于for循环更加高效。&lt;/p&gt;
&lt;h2 id=&quot;生成器表达式&quot;&gt;&lt;a href=&quot;#生成器表达式&quot; class=&quot;headerlink&quot; title=&quot;生成器表达式&quot;&gt;&lt;/a&gt;生成器表达式&lt;/h2&gt;&lt;p&gt;返回一个迭代器的表达式&lt;br&gt;a = (do(i) for i in iter) ##返回一个迭代器&lt;br&gt;a = (do(i) for i in iter if condition)  ##返回一个迭代器&lt;br&gt;    a = [i&lt;em&gt;2 for i in range(10) if i&amp;gt;4]&lt;br&gt;    b = (i&lt;/em&gt;2 for i in range(10) if i&amp;gt;4)&lt;br&gt;    print a,type(a)&lt;br&gt;    print b,type(b),b.next(),b.next()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##输出为
[10, 12, 14, 16, 18] &amp;lt;type &amp;apos;list&amp;apos;&amp;gt;
&amp;lt;generator object &amp;lt;genexpr&amp;gt; at 0x02A3D968&amp;gt; &amp;lt;type &amp;apos;generator&amp;apos;&amp;gt; 10 12 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;区别是一个返回的是列表,一个是迭代器&lt;br&gt;表达式区别就是 []列表 与 ()迭代器&lt;/p&gt;
&lt;h2 id=&quot;Lambda表达式&quot;&gt;&lt;a href=&quot;#Lambda表达式&quot; class=&quot;headerlink&quot; title=&quot;Lambda表达式&quot;&gt;&lt;/a&gt;Lambda表达式&lt;/h2&gt;&lt;p&gt;lambda x: express for x&lt;br&gt;a = lambda x,y: x+y&lt;/p&gt;
&lt;p&gt;特点&lt;br&gt;只有一行语法&lt;br&gt;没有return语句&lt;br&gt;没有函数名&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基础语法部分&quot;&gt;&lt;a href=&quot;#基础语法部分&quot; class=&quot;headerlink&quot; title=&quot;基础语法部分&quot;&gt;&lt;/a&gt;基础语法部分&lt;/h1&gt;&lt;p&gt;1.tab缩进语法，不像其他语言用{}&lt;br&gt;2.不需要声明变量&lt;br&gt;3.常用的语法（1）函数 函数参数 
    
    </summary>
    
    
      <category term="python" scheme="http://jellygogo.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>New Year New Beginning</title>
    <link href="http://jellygogo.com/2016/12/31/New-Year-New-Beginning/"/>
    <id>http://jellygogo.com/2016/12/31/New-Year-New-Beginning/</id>
    <published>2016-12-31T09:34:51.000Z</published>
    <updated>2017-01-16T11:44:30.403Z</updated>
    
    <content type="html">&lt;h1 id=&quot;新的一年，新的开始！&quot;&gt;&lt;a href=&quot;#新的一年，新的开始！&quot; class=&quot;headerlink&quot; title=&quot;新的一年，新的开始！&quot;&gt;&lt;/a&gt;新的一年，新的开始！&lt;/h1&gt;&lt;p&gt;考研已经结束了5天了，这几天一直在休息，但是休息的时候竟然会有一种失落感，感觉自己没有目标了，唉，我四不四剑。&lt;br&gt;这次考研正常发挥，数学比较简单，专业课有点难，题量有点大，不过过线应该没有太大问题。&lt;/p&gt;
&lt;h1 id=&quot;Now，新的征程又要开始了！&quot;&gt;&lt;a href=&quot;#Now，新的征程又要开始了！&quot; class=&quot;headerlink&quot; title=&quot;Now，新的征程又要开始了！&quot;&gt;&lt;/a&gt;Now，新的征程又要开始了！&lt;/h1&gt;&lt;p&gt;经过8个月的考研复习，以前学习的东西基本上都还给老师了，现在需要巩固复习以前学习的java hadoop python相关的东西，然后学习些新的东西。&lt;br&gt;所以，现在是时候做出下一阶段的计划和复试准备计划！&lt;/p&gt;
&lt;h2 id=&quot;扬帆起航&quot;&gt;&lt;a href=&quot;#扬帆起航&quot; class=&quot;headerlink&quot; title=&quot;扬帆起航~~&quot;&gt;&lt;/a&gt;扬帆起航~~&lt;/h2&gt;&lt;p&gt;下一步整个寒假的重点还是在hadoop体系上面，了解数据挖掘与机器学习，语言重点还是java与python&lt;/p&gt;
&lt;p&gt;第一门：英语 听力和口语，继续记单词，每天半小时，提神醒脑算法设计，刷算法题，毕竟复试有四个题；408其他课程的学习，基础课程不能挺，按照408的基础讲义来吧，矩阵和概率-大数据的矩阵计算基础（第11期）&lt;br&gt;第二门：python学习，python在dataguru上面的python基础，爬虫，数据分析三连击&lt;br&gt;第三门：hadoop 主要是mapreduce加强，这是重心；然后熟悉pig hive、hbase这一系列的工具&lt;br&gt;第四门：机器学习 入门和了解&lt;/p&gt;
&lt;h1 id=&quot;每天的博客写作计划，坚持下去&quot;&gt;&lt;a href=&quot;#每天的博客写作计划，坚持下去&quot; class=&quot;headerlink&quot; title=&quot;每天的博客写作计划，坚持下去&quot;&gt;&lt;/a&gt;每天的博客写作计划，坚持下去&lt;/h1&gt;&lt;p&gt;目前的书目：（有点多）&lt;br&gt;python语言程序设计&lt;br&gt;数据挖掘技术与工程实践&lt;br&gt;机器学习相关：机器学习 周志华；机器学习的哲学探索；机器学习系统设计；mahout算法解析与案例实战；Mahout in action；&lt;/p&gt;
&lt;p&gt;hadoop相关：hadoop mapReduceV2 参考手册 ；hadoop技术内幕-深入解析yarn架构设计与实现原理  ；深入理解hadoop；hadoop技术内幕-深入解析mapreduce架构设计和实现原理；&lt;br&gt;mapreduce 2.0源码分析与编程实战；mapreduce设计模式；mahout算法解析与案例实战；Mahout in action；&lt;/p&gt;
&lt;p&gt;杂记：BigData大数据日知录-架构与算法；大数据智能；大数据架构师指南；hadoop mapreduce 实战手册（第一版中文）；探路大数据：海量大数据与大规模分析；大话数据挖掘；&lt;/p&gt;
&lt;h2 id=&quot;需要了解的算法：&quot;&gt;&lt;a href=&quot;#需要了解的算法：&quot; class=&quot;headerlink&quot; title=&quot;需要了解的算法：&quot;&gt;&lt;/a&gt;需要了解的算法：&lt;/h2&gt;&lt;p&gt;回归，时间序列分析，分类器，聚类，频繁模式挖掘，&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;需要关注的点：&lt;br&gt;主流：Map-Reduce java 程序&lt;br&gt;轻量级脚本语言：pig&lt;br&gt;SQL技巧过渡：Hive&lt;br&gt;机器学习平台：Mahout&lt;br&gt;Nosql：HBase&lt;/p&gt;
&lt;p&gt;需要了解的工具：R SAS &lt;/p&gt;
&lt;p&gt;下一步要报的课程：&lt;br&gt;基于案例学习bash脚本编程（第一期）1月14日 待考虑&lt;br&gt;Python网络爬虫（第四期）与&lt;br&gt;Python数据分析&lt;br&gt;机器学习（第16期）1月11日贯彻这个假期的学习；&lt;/p&gt;
&lt;p&gt;具体课程计划：&lt;br&gt;一.hadoop&lt;br&gt;1.hadoop集群安装&lt;br&gt;2.mapreduce&lt;br&gt;3.Mahout&lt;br&gt;二.机器学习&lt;br&gt;1.机器学习先导数学课，&lt;br&gt;2.dataguru炼数成金课程&lt;br&gt;三.python&lt;br&gt;1.1.11之前python魔鬼训练营结束课程准备网络爬虫部分的课程看完&lt;br&gt;2.第二部分是python网络爬虫&lt;br&gt;3.与第二部分一起的还有python数据分析&lt;br&gt;四，读书计划&lt;br&gt;上述书单，每天坚持读书&lt;/p&gt;
&lt;h1 id=&quot;具体计划&quot;&gt;&lt;a href=&quot;#具体计划&quot; class=&quot;headerlink&quot; title=&quot;具体计划&quot;&gt;&lt;/a&gt;具体计划&lt;/h1&gt;&lt;hr&gt;
&lt;p&gt;一月一号：&lt;br&gt;早起第一件事：A出三道算法题&lt;br&gt;hadoop集群安装，pig hive hbase 等工具的安装（以前的环境删了，怎么弄也忘了）&lt;br&gt;Python语言学习第一天，&lt;br&gt;机器学习语言学习第一天，&lt;br&gt;英语尝试听力和口语，&lt;br&gt;翻看大数据数学基础课程，&lt;br&gt;啊。。今天没安装成hadoop。。。&lt;br&gt;一月七号：&lt;br&gt;回家好几天了，终于可以开始学习了！&lt;br&gt;1月16号&lt;br&gt;在家真是堕落！今天熬夜敲代码吧！&lt;/p&gt;
&lt;p&gt;2月15日 考研初试成绩公布&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;新的一年，新的开始！&quot;&gt;&lt;a href=&quot;#新的一年，新的开始！&quot; class=&quot;headerlink&quot; title=&quot;新的一年，新的开始！&quot;&gt;&lt;/a&gt;新的一年，新的开始！&lt;/h1&gt;&lt;p&gt;考研已经结束了5天了，这几天一直在休息，但是休息的时候竟然会有一种失落感，感
    
    </summary>
    
    
      <category term="计划" scheme="http://jellygogo.com/tags/%E8%AE%A1%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>我决定了，要去考研了！</title>
    <link href="http://jellygogo.com/2016/04/27/every_end/"/>
    <id>http://jellygogo.com/2016/04/27/every_end/</id>
    <published>2016-04-26T19:47:26.000Z</published>
    <updated>2016-04-26T11:54:12.668Z</updated>
    
    <content type="html">&lt;p&gt;我知道自己如果现在不试试的话，以后一定会后悔，就像高三没有好好学习一样，后悔进入这个普通二本。&lt;br&gt;我不想哪天自己不顺利的时候，会说这样的话：&lt;br&gt;如果当年我努努力，要是考上研究生，或许生活就不会这样了~~&lt;/p&gt;
&lt;p&gt;我不想以后自己后悔，我也知道我为了什么而去考研，为了我心底，那尚存的一丝希望。&lt;/p&gt;
&lt;p&gt;Hope！&lt;br&gt;永远都是最致命，最美好的东西！&lt;br&gt;以前的low Blog是时候停止了，是时候真正为自己拼一把了！我绝不后悔！&lt;/p&gt;
&lt;p&gt;2016年4月26日 19:52分，离今年考研只有242天。我能创造奇迹，零基础考上自己想要的大学！&lt;br&gt;等我博客重开日，定是春花烂漫时！&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;我知道自己如果现在不试试的话，以后一定会后悔，就像高三没有好好学习一样，后悔进入这个普通二本。&lt;br&gt;我不想哪天自己不顺利的时候，会说这样的话：&lt;br&gt;如果当年我努努力，要是考上研究生，或许生活就不会这样了~~&lt;/p&gt;
&lt;p&gt;我不想以后自己后悔，我也知道我为了什么而去考研，
    
    </summary>
    
    
      <category term="考研，stop the world！" scheme="http://jellygogo.com/tags/%E8%80%83%E7%A0%94%EF%BC%8Cstop-the-world%EF%BC%81/"/>
    
  </entry>
  
  <entry>
    <title>java并发实战-多任务执行</title>
    <link href="http://jellygogo.com/2016/04/24/java%E5%B9%B6%E5%8F%91%E5%AE%9E%E6%88%98_%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C/"/>
    <id>http://jellygogo.com/2016/04/24/java并发实战_多任务执行/</id>
    <published>2016-04-23T17:06:26.000Z</published>
    <updated>2016-04-23T12:45:31.782Z</updated>
    
    <content type="html">&lt;h1 id=&quot;1-延时任务与周期任务&quot;&gt;&lt;a href=&quot;#1-延时任务与周期任务&quot; class=&quot;headerlink&quot; title=&quot;1.延时任务与周期任务&quot;&gt;&lt;/a&gt;1.延时任务与周期任务&lt;/h1&gt;&lt;p&gt;DelayQueue类的主要作用：是一个无界的BlockingQueue，用于放置实现了Delayed接口的对象，其中的对象只能在其到期时才能从队列中取走。这种队列是有序的，即队头对象的延迟到期时间最长&lt;br&gt;.DelayQueue队列中保存的是实现了Delayed接口的实现类，里面必须实现getDelay()和compareTo()方法，&lt;br&gt;前者用于返回与此对象相关的剩余延迟时间，以给定的时间单位表示&lt;br&gt;compareTo()方法用于进行队列内部的排序&lt;/p&gt;
&lt;p&gt;Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部 是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且 poll 将返回 null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于 0 的值时，将发生到期。即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。例如，size 方法同时返回到期和未到期元素的计数。此队列不允许使用 null 元素。 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.basejava;

import java.util.concurrent.Callable;
import java.util.concurrent.DelayQueue;
import java.util.concurrent.Delayed;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

public class DelayQueueTest {

    public static void main(String[] args) {
        ExecutorService exec = Executors.newFixedThreadPool(10);
        DelayQueue&amp;lt;MyTask&amp;gt; queue = new DelayQueue&amp;lt;&amp;gt;();
        queue.add(new MyTask(1000, &amp;quot;Task1:1s:&amp;quot;));
        queue.add(new MyTask(9000, &amp;quot;Task2:9s:&amp;quot;));
        queue.add(new MyTask(3000, &amp;quot;Task3:3s:&amp;quot;));
        try {
            while (!queue.isEmpty()) {
                MyTask my =  queue.take();
                Future&amp;lt;String&amp;gt; future = exec.submit(my);
                System.out.println(&amp;quot;start thread&amp;quot;+my.getTaskName());
                System.out.println(future.get(4,TimeUnit.SECONDS ));
                System.out.println(&amp;quot;end thread&amp;quot;+my.getTaskName());
                if (queue.isEmpty()) {
                    System.out.println(&amp;quot;Empty!&amp;quot;);
                    break;
                }
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();

        }catch (TimeoutException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
            System.out.println(&amp;quot;超时!&amp;quot;);
        }
        System.out.println(&amp;quot;main Thread end&amp;quot;);
    }
}

class MyTask implements Delayed, Callable&amp;lt;String&amp;gt; {

    private long waitTime;
    private String taskName;
    private long endTime;
    public MyTask(long waitTime, String taskName) {
        this.waitTime = waitTime;
        this.taskName = taskName;
        this.endTime = System.currentTimeMillis() + waitTime;
    }
    public long getDelay(TimeUnit unit) {
        return this.endTime - System.currentTimeMillis();
    }
    public String call() throws Exception {
        // sleep waitTime 
        System.out.println(this.taskName + &amp;quot;sleep before&amp;quot;);
        //wait(100);
        Thread.sleep(this.waitTime);
        System.out.println(this.taskName + &amp;quot;sleep end&amp;quot;);
        return &amp;quot;SUCCESS&amp;quot;;
    }

    public int compareTo(Delayed o) {
        MyTask other = (MyTask) o;
        return endTime - other.endTime &amp;gt; 0 ? 1 : 0;
    }
    public String getTaskName() {
        return taskName;
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Demo 解释.&lt;br&gt;例子中使用了Future get(long timeout, TimeUnit unit) 这个方法,指如果在规定时间内不能get()到结果,就抛异常&lt;br&gt;一个很实用的例子:&lt;a href=&quot;http://blog.csdn.net/yjl49/article/details/7088121&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/yjl49/article/details/7088121&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;2-CompletionService-Executor与BlockingQueue&quot;&gt;&lt;a href=&quot;#2-CompletionService-Executor与BlockingQueue&quot; class=&quot;headerlink&quot; title=&quot;2.CompletionService:Executor与BlockingQueue&quot;&gt;&lt;/a&gt;2.CompletionService:Executor与BlockingQueue&lt;/h1&gt;&lt;p&gt;CompletionService是结合了BlockingQueue&lt;/p&gt;
&lt;p&gt;Demo2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.basejava;

import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorCompletionService;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class CompletionServiceTest {

    public static void main(String[] args) {
        ExecutorService exec = Executors.newFixedThreadPool(10);
        ExecutorCompletionService&amp;lt;String&amp;gt; cs = new ExecutorCompletionService&amp;lt;&amp;gt;(exec);
        cs.submit(new MyTask(1000, &amp;quot;Task1:1s:&amp;quot;));
        cs.submit(new MyTask(9000, &amp;quot;Task2:9s:&amp;quot;));
        cs.submit(new MyTask(3000, &amp;quot;Task3:3s:&amp;quot;));
        int size = 3;
        while (size--==0) {
            System.out.println(&amp;quot;start thread&amp;quot;);
            try {
                System.out.println(cs.take());
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(&amp;quot;end thread&amp;quot;);
        }
    }
}

class MyTask2 implements Callable&amp;lt;String&amp;gt; {

    private long waitTime;
    private String taskName;
    public MyTask2(long waitTime, String taskName) {
        this.waitTime = waitTime;
        this.taskName = taskName;
    }
    public String call() throws Exception {
        System.out.println(this.taskName + &amp;quot;sleep before&amp;quot;);
        Thread.sleep(this.waitTime);
        System.out.println(this.taskName + &amp;quot;sleep end&amp;quot;);
        return &amp;quot;SUCCESS&amp;quot;;
    }

    public String getTaskName() {
        return taskName;
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此种方法不能设定获取时间,不如第一种灵活,但是更容易实现&lt;/p&gt;
&lt;h1 id=&quot;3-invokeAll&quot;&gt;&lt;a href=&quot;#3-invokeAll&quot; class=&quot;headerlink&quot; title=&quot;3.invokeAll&quot;&gt;&lt;/a&gt;3.invokeAll&lt;/h1&gt;&lt;p&gt;此种方法更容易实现,而且能解决第二种出现的弊端&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.basejava;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

public class InvokaAll {

    public static void main(String[] args) {
        ExecutorService exec = Executors.newFixedThreadPool(10);
        List&amp;lt;MyTask3&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        list.add(new MyTask3(1000, &amp;quot;Task1:1s:&amp;quot;));
        list.add(new MyTask3(10000, &amp;quot;Task2:9s:&amp;quot;));
        list.add(new MyTask3(3000, &amp;quot;Task3:3s:&amp;quot;));
        try {
            List&amp;lt;Future&amp;lt;String&amp;gt;&amp;gt; futures = exec.invokeAll(list,4,TimeUnit.SECONDS );
            for(Future f:futures){
                try {
                    System.out.println(f.get());
                } catch (ExecutionException e) {
                    e.printStackTrace();
                }
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

class MyTask3 implements Callable&amp;lt;String&amp;gt; {

    private long waitTime;
    private String taskName;
    public MyTask3(long waitTime, String taskName) {
        this.waitTime = waitTime;
        this.taskName = taskName;
    }
    public String call() throws Exception {
        System.out.println(this.taskName + &amp;quot;sleep before&amp;quot;+&amp;quot;wait:&amp;quot;+waitTime);
        Thread.sleep(waitTime);
        System.out.println(this.taskName + &amp;quot;sleep end&amp;quot;);
        return &amp;quot;SUCCESS&amp;quot;;
    }

    public String getTaskName() {
        return taskName;
    }

}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-延时任务与周期任务&quot;&gt;&lt;a href=&quot;#1-延时任务与周期任务&quot; class=&quot;headerlink&quot; title=&quot;1.延时任务与周期任务&quot;&gt;&lt;/a&gt;1.延时任务与周期任务&lt;/h1&gt;&lt;p&gt;DelayQueue类的主要作用：是一个无界的BlockingQue
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="并发" scheme="http://jellygogo.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>java并发实战-任务终止</title>
    <link href="http://jellygogo.com/2016/04/24/jvm_%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/"/>
    <id>http://jellygogo.com/2016/04/24/jvm_内存管理机制/</id>
    <published>2016-04-23T17:06:26.000Z</published>
    <updated>2016-04-23T14:26:21.995Z</updated>
    
    <content type="html">&lt;h1 id=&quot;内存区域划分&quot;&gt;&lt;a href=&quot;#内存区域划分&quot; class=&quot;headerlink&quot; title=&quot;内存区域划分&quot;&gt;&lt;/a&gt;内存区域划分&lt;/h1&gt;&lt;h2 id=&quot;程序计数区&quot;&gt;&lt;a href=&quot;#程序计数区&quot; class=&quot;headerlink&quot; title=&quot;程序计数区&quot;&gt;&lt;/a&gt;程序计数区&lt;/h2&gt;&lt;p&gt;唯一没有规定任务OutOfmemery异常的区域&lt;/p&gt;
&lt;h2 id=&quot;java虚拟机栈&quot;&gt;&lt;a href=&quot;#java虚拟机栈&quot; class=&quot;headerlink&quot; title=&quot;java虚拟机栈&quot;&gt;&lt;/a&gt;java虚拟机栈&lt;/h2&gt;&lt;p&gt;java虚拟机栈是线程私有区域,每个方法执行时都会在java虚拟机栈中创建一个栈帧(Stack Flame)用于存储局部变量表,方法出口,操作数栈等参数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.jvm;

//Exception in thread &amp;quot;main&amp;quot; java.lang.StackOverflowError
//通过无限调用递归方法,来模拟StackOverflowError
public class JvmOutOfMemoryTest {
/*
 * -Xss128k
 */

    public static void main(String[] args) {
        new JvmOutOfMemoryTest().stack(1);
    }

    public void stack(int i){
        stack(++i);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;本地方法区&quot;&gt;&lt;a href=&quot;#本地方法区&quot; class=&quot;headerlink&quot; title=&quot;本地方法区&quot;&gt;&lt;/a&gt;本地方法区&lt;/h2&gt;&lt;p&gt;与java虚拟机栈类似,区别是执行native方法&lt;/p&gt;
&lt;h2 id=&quot;java堆&quot;&gt;&lt;a href=&quot;#java堆&quot; class=&quot;headerlink&quot; title=&quot;java堆&quot;&gt;&lt;/a&gt;java堆&lt;/h2&gt;&lt;p&gt;所有线程共享,此内存区域唯一目的是存放方法实例.&lt;br&gt;java堆可以分为新生代和老年代&lt;/p&gt;
&lt;p&gt;java堆溢出异常测试&lt;br&gt;只需要不断创建对象就可以模拟出这种现象&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.jvm;

import java.util.ArrayList;
import java.util.List;

public class JvmOutOfMemoryTest {
/*
 * -Xms10m -Xmx10m
 */

    public static void main(String[] args) {
        List l = new ArrayList&amp;lt;&amp;gt;();
        while(true)
        l.add(new JvmOutOfMemoryTest());
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;方法区&quot;&gt;&lt;a href=&quot;#方法区&quot; class=&quot;headerlink&quot; title=&quot;方法区&quot;&gt;&lt;/a&gt;方法区&lt;/h2&gt;&lt;p&gt;所有线程共享的区域,存储已被类加载的类信息,常量,静态变量.&lt;/p&gt;
&lt;h2 id=&quot;运行时常量池&quot;&gt;&lt;a href=&quot;#运行时常量池&quot; class=&quot;headerlink&quot; title=&quot;运行时常量池&quot;&gt;&lt;/a&gt;运行时常量池&lt;/h2&gt;&lt;p&gt;属于方法区的一部分,储存编译器生成的字面量与符号引用&lt;/p&gt;
&lt;h1 id=&quot;垃圾收集器&quot;&gt;&lt;a href=&quot;#垃圾收集器&quot; class=&quot;headerlink&quot; title=&quot;垃圾收集器&quot;&gt;&lt;/a&gt;垃圾收集器&lt;/h1&gt;&lt;p&gt;常用的垃圾收集算法：&lt;br&gt;标记-清除算法：&lt;br&gt;复制算法：新生代算法&lt;br&gt;标记-整理：&lt;br&gt;分代收集算法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/img/2016/04/Collectors.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;内存分配策略&quot;&gt;&lt;a href=&quot;#内存分配策略&quot; class=&quot;headerlink&quot; title=&quot;内存分配策略&quot;&gt;&lt;/a&gt;内存分配策略&lt;/h1&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;内存区域划分&quot;&gt;&lt;a href=&quot;#内存区域划分&quot; class=&quot;headerlink&quot; title=&quot;内存区域划分&quot;&gt;&lt;/a&gt;内存区域划分&lt;/h1&gt;&lt;h2 id=&quot;程序计数区&quot;&gt;&lt;a href=&quot;#程序计数区&quot; class=&quot;headerlink&quot; title=
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="并发" scheme="http://jellygogo.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>java并发实战-任务终止</title>
    <link href="http://jellygogo.com/2016/04/24/java%E5%B9%B6%E5%8F%91%E5%AE%9E%E6%88%98_%E4%BB%BB%E5%8A%A1%E7%BB%88%E6%AD%A2/"/>
    <id>http://jellygogo.com/2016/04/24/java并发实战_任务终止/</id>
    <published>2016-04-23T17:06:26.000Z</published>
    <updated>2016-04-23T13:07:55.670Z</updated>
    
    <content type="html"></content>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="并发" scheme="http://jellygogo.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>常用数据查找(搜索)算法总结</title>
    <link href="http://jellygogo.com/2016/04/19/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>http://jellygogo.com/2016/04/19/常用数据搜索算法总结/</id>
    <published>2016-04-18T17:06:26.000Z</published>
    <updated>2016-04-20T04:05:10.258Z</updated>
    
    <content type="html">&lt;p&gt;散列表&lt;br&gt;静态散列与动态散列 &lt;/p&gt;
&lt;p&gt;散列是一个非常有用的、非常基础的数据结构，在数据的查找方面尤其重要，应用的非常广泛。然而，任何事物都有两面性，散列也存在缺点，即数据的局部集中性会使散列的性能急剧下降，且越集中，性能越低。&lt;br&gt;数据集中，即搜索键在通过hash函数运算后，得到同一个结果，指向同一个桶，这时便产生了数据冲突。&lt;br&gt;通常解决数据冲突的方法有：拉链法(open hashing)和开地址法(open addressing)。拉链法我们用的非常多，即存在冲突时，简单的将元素链在当前桶的最后元素的尾部。开放地址法有线性探测再散列、二次线性探测再散列、再hash等方法。&lt;br&gt;在HashMap中采用拉链法,在每个桶后面使用一个链表储存冲突的数据&lt;br&gt;以上介绍的解决冲突的方法，存在一个前提：hash表(又称散列表)的桶的数目保持不变，即hash表在初始化时指定一个数，以后在使用的过程中，只允许在其中添加、删除、查找元素等操作，而不允许改变桶的数目。&lt;br&gt;在实际的应用中，当hash表较小，元素个数不多时，采用以上方法完全可以应付。但是，一旦元素较多，或数据存在一定的偏斜性(数据集中分布在某个桶上)时，以上方法不足以解决这一问题。我们引入一种称之为动态散列的方法：在hash表的元素增长的同时，动态的调整hash桶的数目&lt;br&gt;挖坑:动态哈希表~~&lt;br&gt;散列表:&lt;a href=&quot;http://blog.sina.com.cn/s/blog_5e4516af01019frj.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.sina.com.cn/s/blog_5e4516af01019frj.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;布隆过滤器&lt;/p&gt;
&lt;p&gt;布隆过滤器原理:&lt;a href=&quot;http://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html&lt;/a&gt;&lt;br&gt;布隆过滤器java代码:&lt;a href=&quot;http://blog.csdn.net/hwwzyh/article/details/38944513&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/hwwzyh/article/details/38944513&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;B树即二叉搜索树：&lt;br&gt;1.所有非叶子结点至多拥有两个儿子（Left和Right）；&lt;br&gt;2.所有结点存储一个关键字；&lt;br&gt;3.非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树；&lt;br&gt;B-树是一种多路搜索树（并不是二叉的）&lt;br&gt;B+树B-树的一种变种,在B-树基础上为所有叶子结点增加一个链指针&lt;br&gt;B*树,B+树的一种变种,为非叶节点的中间节点增加一个链指针&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/oldhorse/archive/2009/11/16/1604009.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/oldhorse/archive/2009/11/16/1604009.html&lt;/a&gt;&lt;br&gt;java二叉树实现:&lt;a href=&quot;http://blog.csdn.net/cdnight/article/details/11266969&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/cdnight/article/details/11266969&lt;/a&gt;&lt;br&gt;AVL树&lt;br&gt;红黑树&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;散列表&lt;br&gt;静态散列与动态散列 &lt;/p&gt;
&lt;p&gt;散列是一个非常有用的、非常基础的数据结构，在数据的查找方面尤其重要，应用的非常广泛。然而，任何事物都有两面性，散列也存在缺点，即数据的局部集中性会使散列的性能急剧下降，且越集中，性能越低。&lt;br&gt;数据集中，即搜索键在通过ha
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="算法" scheme="http://jellygogo.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="搜索" scheme="http://jellygogo.com/tags/%E6%90%9C%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>hbase学习</title>
    <link href="http://jellygogo.com/2016/04/19/hbase_learn/"/>
    <id>http://jellygogo.com/2016/04/19/hbase_learn/</id>
    <published>2016-04-18T17:06:26.000Z</published>
    <updated>2016-04-20T04:49:38.492Z</updated>
    
    <content type="html">&lt;h2 id=&quot;hbase应用场景&quot;&gt;&lt;a href=&quot;#hbase应用场景&quot; class=&quot;headerlink&quot; title=&quot;hbase应用场景&quot;&gt;&lt;/a&gt;hbase应用场景&lt;/h2&gt;&lt;p&gt;1、爬虫网站URL的写入。&lt;br&gt;2、淘宝在2011年之前所有的后端持久化存储基本上都是在mysql上进行的(不排除少量oracle/bdb/tair/mongdb等)，mysql由于开源，并且生态系统良好，本身拥有分库分表等多种解决方案，因此很长一段时间内都满足淘宝大量业务的需求。&lt;br&gt;但是由于业务的多样化发展，有越来越多的业务系统的需求开始发生了变化。一般来说有以下几类变化：&lt;br&gt;数据量变得越来越多，事实上现在淘宝几乎任何一个与用户相关的在线业务的数据量都在亿级别，每日系统调用次数从亿到百亿都有，且历史数据不能轻易删除。这需要有一个海量分布式文件系统，能对TB级甚至PB级别的数据提供在线服务&lt;br&gt;数据量的增长很快且不一定能准确预计，大多数应用系统从上线起在一段时间内数据量都呈很快的上升趋势，因此从成本的角度考虑对系统水平扩展能力有比较强烈的需求，且不希望存在单点制约&lt;br&gt;只需要简单的kv读取，没有复杂的join等需求。但对系统的并发能力以及吞吐量、响应延时有非常高的需求，并且希望系统能够保持强一致性&lt;br&gt;通常系统的写入非常频繁，尤其是大量系统依赖于实时的日志分析&lt;br&gt;希望能够快速读取批量数据 &lt;/p&gt;
&lt;p&gt;参考博客:&lt;a href=&quot;http://www.cnblogs.com/zhwl/p/3654346.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/zhwl/p/3654346.html&lt;/a&gt;&lt;br&gt;hbase应用场景重点参考博客:&lt;a href=&quot;http://blog.sina.com.cn/s/blog_ae33b83901016azb.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.sina.com.cn/s/blog_ae33b83901016azb.html&lt;/a&gt;  &lt;/p&gt;
&lt;h2 id=&quot;学习进度一-2016-04-20&quot;&gt;&lt;a href=&quot;#学习进度一-2016-04-20&quot; class=&quot;headerlink&quot; title=&quot;学习进度一:2016-04-20&quot;&gt;&lt;/a&gt;学习进度一:2016-04-20&lt;/h2&gt;&lt;p&gt;hbase的学习参考书籍为:Hbase权威指南&lt;br&gt;目前学习进度为hbase简单使用与java API:基础知识部分(此书前三章),后面的部分等到需要使用时再具体学习.&lt;/p&gt;
&lt;p&gt;Demo1 hbase数据插入&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;hbase应用场景&quot;&gt;&lt;a href=&quot;#hbase应用场景&quot; class=&quot;headerlink&quot; title=&quot;hbase应用场景&quot;&gt;&lt;/a&gt;hbase应用场景&lt;/h2&gt;&lt;p&gt;1、爬虫网站URL的写入。&lt;br&gt;2、淘宝在2011年之前所有的后端持久化存储基本上
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="hbase" scheme="http://jellygogo.com/tags/hbase/"/>
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>pig学习</title>
    <link href="http://jellygogo.com/2016/04/19/pig_learn/"/>
    <id>http://jellygogo.com/2016/04/19/pig_learn/</id>
    <published>2016-04-18T17:06:26.000Z</published>
    <updated>2016-04-18T05:28:52.324Z</updated>
    
    <content type="html">&lt;p&gt;grunt&amp;gt; cat hdfs://h1:9000/user/grip/toolSample.txt&lt;br&gt;2016 99&lt;br&gt;2015 6&lt;br&gt;2016 999&lt;br&gt;2015 5&lt;/p&gt;
&lt;p&gt;grunt&amp;gt; a = load ‘hdfs://h1:9000/user/grip/toolSample.txt’ using PigStorage(‘ ‘) as (year,max) ;&lt;/p&gt;
&lt;p&gt;grunt&amp;gt; a = load ‘hdfs://h1:9000/user/grip/toolSample.txt’ as (year,max) using PigStorage(‘ ‘);&lt;br&gt;2016-04-17 22:26:19,929 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: &lt;line 65=&quot;&quot; 16,=&quot;&quot; column=&quot;&quot;&gt;&lt;/line&gt;  mismatched input ‘using’ expecting SEMI_COLON&lt;br&gt;Details at logfile: /home/grip/hadoop-2.5.2/pig_1460955057730.log&lt;br&gt;grunt&amp;gt; a = load ‘hdfs://h1:9000/user/grip/toolSample.txt’ using PigStorage(‘ ‘) as (year,max) ;&lt;br&gt;2016-04-17 22:26:57,098 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS&lt;br&gt;grunt&amp;gt; dump a;&lt;br&gt;2016-04-17 22:27:05,950 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: UNKNOWN&lt;br&gt;2016-04-17 22:27:05,951 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter], RULES_DISABLED=[FilterLogicExpressionSimplifier]}&lt;br&gt;2016-04-17 22:27:06,028 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized&lt;br&gt;2016-04-17 22:27:06,047 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1&lt;br&gt;2016-04-17 22:27:06,047 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1&lt;br&gt;2016-04-17 22:27:06,140 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task ‘attempt&lt;strong&gt;0001_m_000001_1’ to hdfs://h1:9000/tmp/temp342437142/tmp293532517/_temporary/0/task&lt;/strong&gt;0001_m_000001&lt;br&gt;2016-04-17 22:27:06,180 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized&lt;br&gt;2016-04-17 22:27:06,185 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1&lt;br&gt;2016-04-17 22:27:06,185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1&lt;br&gt;(2016,99)&lt;br&gt;(2015,6)&lt;br&gt;(2016,999)&lt;br&gt;(2015,5)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;grunt&amp;gt; cat hdfs://h1:9000/user/grip/toolSample.txt&lt;br&gt;2016 99&lt;br&gt;2015 6&lt;br&gt;2016 999&lt;br&gt;2015 5&lt;/p&gt;
&lt;p&gt;grunt&amp;gt; a = load ‘hdfs://h1:900
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="算法" scheme="http://jellygogo.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="排序" scheme="http://jellygogo.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>Hive学习</title>
    <link href="http://jellygogo.com/2016/04/13/hiveLearn/"/>
    <id>http://jellygogo.com/2016/04/13/hiveLearn/</id>
    <published>2016-04-13T12:50:55.000Z</published>
    <updated>2016-04-18T07:26:45.866Z</updated>
    
    <content type="html">&lt;p&gt;hive数据仓库,基于mapreduce计算模型，结构化数据的离线分析。&lt;br&gt;hive 应用场景:对搜索日志数据进行统计分析。&lt;br&gt;集团搜索刚上线不久，日志量并不大 。这些日志分布在 5 台前端机，按小时保存，并以小时为周期定时将上一小时产生的数据同步到日志分析机，统计数据要求按小时更新。这些统计项，&lt;br&gt;包括关键词搜索量 pv ，类别访问量，每秒访问量 tps 等等。&lt;br&gt;基于 Hive ，我们将这些数据按天为单位建表，每天一个表，后台脚本根据时间戳将每小时同步过来的 5 台前端机的日志数据合并成一个日志文件，导入 Hive 系统，每小时同步的日志数据&lt;br&gt;被追加到当天数据表中，导入完成后，当天各项统计项将被重新计算并输出统计结果。&lt;br&gt;以上需求若直接基于 hadoop 开发，需要自行管理数据，针对多个统计需求开发不同的 map/reduce 运算任务，对合并、排序等多项操作进行定制，并检测任务运行状态，工作量并不小。但&lt;br&gt;使用 Hive ，从导入到分析、排序、去重、结果输出，这些操作都可以运用 hql 语句来解决，一条语句经过处理被解析成几个任务来运行，即使是关键词访问量增量这种需要同时访问多天数&lt;br&gt;据的较为复杂的需求也能通过表关联这样的语句自动完 成，节省了大量工作量。&lt;/p&gt;
&lt;p&gt;参考博客:&lt;a href=&quot;http://www.cnblogs.com/zhwl/p/3654346.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/zhwl/p/3654346.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;hive基础操作&quot;&gt;&lt;a href=&quot;#hive基础操作&quot; class=&quot;headerlink&quot; title=&quot;hive基础操作&quot;&gt;&lt;/a&gt;hive基础操作&lt;/h2&gt;&lt;p&gt;hive导入数据方法:&lt;a href=&quot;http://blog.csdn.net/lifuxiangcaohui/article/details/40588929&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/lifuxiangcaohui/article/details/40588929&lt;/a&gt;&lt;br&gt;    hive&amp;gt; dfs -cat hdfs://h1:9000/user/grip/word.txt&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hive&amp;gt; create database test;
OK
Time taken: 8.764 seconds

hive&amp;gt; use test;
OK
Time taken: 1.91 seconds

hive&amp;gt;
hive&amp;gt; set hivevar:v=name;
hive&amp;gt; create table tabletest(id int,${hivevar:v} string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &amp;apos;\t&amp;apos; ;
OK
Time taken: 15.879 seconds

hive&amp;gt; describe tabletest;
OK
id                      int                                    
name                    string                                 
Time taken: 4.328 seconds, Fetched: 2 row(s)

[grip@h1 tData]$ cat hivedata.txt
101     jelly
102     gogo

hive (test)&amp;gt; load data local inpath &amp;quot;/home/grip/tData/hivedata.txt&amp;quot; into table tabletest;
Loading data to table test.tabletest
OK
Time taken: 2.252 seconds
hive (test)&amp;gt; select * from tabletest;
OK
101     jelly
102     gogo
Time taken: 0.569 seconds, Fetched: 2 row(s)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;wordcount-hive-Demo&quot;&gt;&lt;a href=&quot;#wordcount-hive-Demo&quot; class=&quot;headerlink&quot; title=&quot;wordcount hive Demo&quot;&gt;&lt;/a&gt;wordcount hive Demo&lt;/h2&gt;&lt;p&gt;create database wordcount;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;hive数据仓库,基于mapreduce计算模型，结构化数据的离线分析。&lt;br&gt;hive 应用场景:对搜索日志数据进行统计分析。&lt;br&gt;集团搜索刚上线不久，日志量并不大 。这些日志分布在 5 台前端机，按小时保存，并以小时为周期定时将上一小时产生的数据同步到日志分析机，统计
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="hive" scheme="http://jellygogo.com/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>常用排序算法总结</title>
    <link href="http://jellygogo.com/2016/04/08/%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>http://jellygogo.com/2016/04/08/常用排序算法总结/</id>
    <published>2016-04-07T17:06:26.000Z</published>
    <updated>2016-04-18T04:22:12.804Z</updated>
    
    <content type="html">&lt;p&gt;常用的排序算法我知道的有9种&lt;br&gt;在whuslei博客中发现这么一张图片能概括这9种算法.&lt;br&gt;&lt;img src=&quot;/img/2016/04/001.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些算法主要比较的是时间复杂性,稳定性,和实现的复杂度&lt;br&gt;稳定性，就是有两个相同的元素，排序先后的相对位置是否变化，主要用在排序时有多个排序规则的情况下。在插入排序中，K1是已排序部分中的元素，当K2和K1比较时，直接插到K1的后面(没有必要插到K1的前面，这样做还需要移动！！)&lt;/p&gt;
&lt;h1 id=&quot;直接插入排序法&quot;&gt;&lt;a href=&quot;#直接插入排序法&quot; class=&quot;headerlink&quot; title=&quot;直接插入排序法&quot;&gt;&lt;/a&gt;直接插入排序法&lt;/h1&gt;&lt;p&gt;陆续将一个记录插入到前面已经排好序的有序表中, 从而得到一个新的,记录数增1的有序表&lt;br&gt;算法时间复杂度。&lt;br&gt;最好的情况下：正序有序(从小到大)，这样只需要比较n次，不需要移动。因此时间复杂度为O(n)&lt;br&gt;最坏的情况下：逆序有序,这样每一个元素就需要比较n次，共有n个元素，因此实际复杂度为O(n­2)&lt;br&gt;平均情况下：O(n­2)&lt;br&gt;可以在原来存储的数组上面直接排序&lt;/p&gt;
&lt;p&gt;插入排序是稳定的。&lt;/p&gt;
&lt;p&gt;时间复杂度也为O(n^2), 比冒泡法和选择排序的性能要更好一些&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class InsertionSort {

    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        if(in.size()==1||in.size()==0)
            return in;
        for(int i=1;i&amp;lt;in.size();i++){
            if(in.get(i)&amp;lt;in.get(0)){
                move(in,in.get(i),0,i);
            }
            if(in.get(i)&amp;lt;in.get(i-1)){
                for(int j=0;j&amp;lt;i;j++){
                    if(in.get(j)&amp;lt;=in.get(i)&amp;amp;&amp;amp;in.get(j+1)&amp;gt;=in.get(i)){
                        move(in,in.get(i),j+1,i);
                        break;
                    }
                }
            }
        }
        return in;
    }
    public static void move(LinkedList&amp;lt;Integer&amp;gt; in,int value,int start,int end){
        int tmp = value;
        for(int i = start;i&amp;lt;end;i++){
            int ttmp = in.get(i);
            in.set(i, tmp);
            tmp = ttmp;
        }
        in.set(end, tmp);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;直接选择排序&quot;&gt;&lt;a href=&quot;#直接选择排序&quot; class=&quot;headerlink&quot; title=&quot;直接选择排序&quot;&gt;&lt;/a&gt;直接选择排序&lt;/h1&gt;&lt;p&gt;通过n-i次关键字之间的比较,从n-i+1 个记录中选择关键字最小的记录,并和第i(1&amp;lt;=i&amp;lt;=n)个记录交换之&lt;br&gt;尽管与冒泡排序同为O(n^2),但简单选择排序的性能要略优于冒泡排序&lt;br&gt;最好情况下：交换0次，但是每次都要找到最小的元素，因此大约必须遍历N&lt;em&gt;N次，因此为O(N&lt;/em&gt;N)。减少了交换次数！&lt;br&gt;最坏情况下，平均情况下：O(N*N)&lt;br&gt;由于每次都是选取未排序序列A中的最小元素x与A中的第一个元素交换，因此跨距离了，很可能破坏了元素间的相对位置，因此选择排序是不稳定的！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;
import java.util.LinkedList;
public class SelectSort {
    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        int min ;
        int postion;
        for(int i=0;i&amp;lt;in.size();i++){
            min=in.get(i);
            postion = i;
            for(int j=i+1;j&amp;lt;in.size();j++){
                if(min&amp;gt;in.get(j)){
                    min = in.get(j);
                    postion = j;
                }
            }
            in.set(postion,in.get(i));
            in.set(i, min);
        }
        return in;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;冒泡算法&quot;&gt;&lt;a href=&quot;#冒泡算法&quot; class=&quot;headerlink&quot; title=&quot;冒泡算法&quot;&gt;&lt;/a&gt;冒泡算法&lt;/h1&gt;&lt;p&gt;通过无序区中相邻记录关键字间的比较和位置的交换,使关键字最小的记录如气泡一般逐渐往上“漂浮”直至“水面”。&lt;br&gt;时间复杂度&lt;br&gt;最好情况下：正序有序，则只需要比较n次。故，为O(n)&lt;br&gt;最坏情况下:  逆序有序，则需要比较(n-1)+(n-2)+……+1，故，为O(N*N)&lt;br&gt;排序过程中只交换相邻两个元素的位置。因此，当两个数相等时，是没必要交换两个数的位置的。所以，它们的相对位置并没有改变，冒泡排序算法是稳定的！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;
import java.util.LinkedList;
public class BubbleSort {
    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        for(int i=0;i&amp;lt;in.size();i++){
            for(int j=0;j&amp;lt;in.size()-1;j++){
                if(in.get(j)&amp;gt;=in.get(j+1)){
                    int tmp = in.get(j);
                    in.set(j, in.get(j+1));
                    in.set(j+1, tmp) ;
                }
            }
        }
        return in;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;改进思路1：设置标志位，明显如果有一趟没有发生交换（flag = false)，说明排序已经完成&lt;br&gt;改进思路2：记录一轮下来标记的最后位置，下次从头部遍历到这个位置就Ok&lt;br&gt;实现代码:&lt;/p&gt;
&lt;h1 id=&quot;希尔排序&quot;&gt;&lt;a href=&quot;#希尔排序&quot; class=&quot;headerlink&quot; title=&quot;希尔排序&quot;&gt;&lt;/a&gt;希尔排序&lt;/h1&gt;&lt;p&gt;希尔排序的实质就是分组插入排序，该方法又称缩小增量排序&lt;br&gt;参考博客 &lt;a href=&quot;http://blog.csdn.net/morewindows/article/details/6668714&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/morewindows/article/details/6668714&lt;/a&gt;&lt;br&gt;    package com.jellygogo.sort;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.util.LinkedList;

public class ShellSort {

    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        int len=in.size()/2;
        while(len&amp;gt;=1){
            for(int k=0;k&amp;lt;len;k++){
                for(int i=len;i&amp;lt;in.size();i+=len){
                    if(in.get(i)&amp;lt;in.get(0)){
                        InsertionSort. move(in,in.get(i),0,i,len);
                    }
                    if(in.get(i)&amp;lt;in.get(i-1)){
                        for(int j=0;j&amp;lt;i;j++){
                            if(in.get(j)&amp;lt;=in.get(i)&amp;amp;&amp;amp;in.get(j+1)&amp;gt;=in.get(i)){
                                InsertionSort.move(in,in.get(i),j+1,i,len);
                                break;
                            }
                        }
                    }
                }
            }
            if(len==1)
                break;
            len=len/2;
        }
        return in;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;快速排序&quot;&gt;&lt;a href=&quot;#快速排序&quot; class=&quot;headerlink&quot; title=&quot;快速排序&quot;&gt;&lt;/a&gt;快速排序&lt;/h1&gt;&lt;p&gt;它是由冒泡排序改进而来的。在待排序的n个记录中任取一个记录(通常取第一个记录),把该记录放入适当位置后,数据序列被此记录划分成两部分。所有关键字比该记录关键字小的记录放置在前一部分,所有比它大的记录放置在后一部分,并把该记录排在这两部分的中间(称为该记录归位),这个过程称作一趟快速排序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;

import java.util.LinkedList;
import java.util.List;

public class QuickSort {

    public static List&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in,int start ,int end) {
        // [5, 1, 3, 2, 6]
        if(start==end)
            return in;
        int mid = in.get(start);
        int left=start;
        int right=end-1;
        for(int i = start+1;i&amp;lt;end&amp;amp;&amp;amp;right&amp;gt;=left;i++){
            if(in.get(i)&amp;lt;=mid){
                int tmp = in.get(i);
                in.set(i,in.get(left));
                in.set(left,tmp);
                left++;
            }else{
                int tmp = in.get(i);
                in.set(i,in.get(right));
                in.set(right,tmp);
                right--;
            }
        }
        sort(in,start,left);
        sort(in,left+1,end);
        return in;
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;堆排序&quot;&gt;&lt;a href=&quot;#堆排序&quot; class=&quot;headerlink&quot; title=&quot;堆排序&quot;&gt;&lt;/a&gt;堆排序&lt;/h1&gt;&lt;p&gt;分治算法:分治算法由两部分组成&lt;br&gt;分:递归解决较小问题(部分除外)&lt;br&gt;治:从子问题的解,构建原问题的解&lt;br&gt;&lt;a href=&quot;http://dsbryz.iteye.com/blog/1182056&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://dsbryz.iteye.com/blog/1182056&lt;/a&gt;&lt;br&gt;堆排序的思想是利用数据结构–堆。具体的实现细节： &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构建一个最大堆。对于给定的包含有n个元素的数组A[n]，构建一个最大堆（最大堆的特性是，某个节点的值最多和其父节点的值一样大。这样，堆中的最大元素存放在根节点中；并且，在以某一个节点为根的子树中，各节点的值都不大于该子树根节点的值）。从最底下的子树开始，调整这个堆结构，使其满足最大堆的特性。当为了满足最大堆特性时，堆结构发生变化，此时递归调整对应的子树。 &lt;/li&gt;
&lt;li&gt;堆排序算法，每次取出该最大堆的根节点（因为根节点是最大的），同时，取最末尾的叶子节点来作为根节点，从此根节点开始调整堆，使其满足最大堆的特性。 &lt;/li&gt;
&lt;li&gt;&lt;p&gt;重复上一步操作，直到堆的大小由n个元素降到2个。 &lt;/p&gt;
&lt;p&gt; package com.jellygogo.sort;&lt;/p&gt;
&lt;p&gt; import java.util.Arrays;&lt;br&gt; import java.util.LinkedList;&lt;br&gt; import java.util.List;&lt;/p&gt;
&lt;p&gt; public class HeapSort {&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static List&amp;lt;Integer&amp;gt; sort(List&amp;lt;Integer&amp;gt; in){
    int[] inArray = initHeap(in);
    List&amp;lt;Integer&amp;gt; out = new LinkedList&amp;lt;&amp;gt;();
    for(int i=in.size()-1;i&amp;gt;0;i--){
        int tmp = inArray[i];
        inArray[i] = inArray[0];
        inArray[0] = tmp;
        if(i&amp;gt;=1)
            maxHeap(inArray,i,0);
    }
    for(int i=0;i&amp;lt;in.size();i++){
        out.add(inArray[i]);
    }
    return out;
}

private static void maxHeap(int[] inArray,int size,int index) {
    int left = (index+1)*2-1;
    int right = (index+1)*2;
    int maxIndex = index;
    boolean changed = false;
    if(left&amp;lt;size&amp;amp;&amp;amp;inArray[left]&amp;gt;inArray[maxIndex]){
        maxIndex = left;
    }
    if(right&amp;lt;size&amp;amp;&amp;amp;inArray[right]&amp;gt;inArray[maxIndex]){
        maxIndex = right;
    }
    if(left&amp;lt;size&amp;amp;&amp;amp;maxIndex==left){
        int tmp = inArray[left];
        inArray[left] = inArray[index];
        inArray[index] = tmp;
        changed = true;
    }
    if(right&amp;lt;size&amp;amp;&amp;amp;maxIndex==right){
        int tmp = inArray[right];
        inArray[right] = inArray[index];
        inArray[index] = tmp;
        changed = true;
    }
    if(changed){
        maxHeap(inArray,size,maxIndex);
    }

}

public static int[] initHeap(List&amp;lt;Integer&amp;gt; in){
    int[] out = new int[in.size()];
    for(int i=0;i&amp;lt;in.size();i++){
        out[i]=in.get(i);
    }
    for(int i=in.size()/2;i&amp;gt;=0;i--){
        maxHeap(out,in.size(),i);
    }
    return out;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; }&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;归并排序&quot;&gt;&lt;a href=&quot;#归并排序&quot; class=&quot;headerlink&quot; title=&quot;归并排序&quot;&gt;&lt;/a&gt;归并排序&lt;/h1&gt;&lt;p&gt;假设初始序列含有n个记录,则可以看成n个有序的子序列,每个子序列的长度为1,然后两两归并,得到(不小于n/2的最小整数)个长度为2或1的有序子序列,再两两归并,…如此重复,直至得到一个长度为n的有序序列为止,这种排序方法称为2路归并排序。&lt;br&gt;时间复杂度为O(nlogn),空间复杂度为O(n+logn),如果非递归实现归并,则避免了递归时深度为logn的栈空间 空间复杂度为O(n)&lt;br&gt;空间复杂度较大&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;

import java.util.LinkedList;
import java.util.List;
import java.util.List;

public class MergeSort {

    public static List&amp;lt;Integer&amp;gt; sort(List&amp;lt;Integer&amp;gt; in){
        if(in.size()==1||in.size()==0){
            return in;
        }else{
            List&amp;lt;Integer&amp;gt; i1= sort(in.subList(0, in.size()/2));
            List&amp;lt;Integer&amp;gt; i2= sort(in.subList(in.size()/2, in.size()));
            List&amp;lt;Integer&amp;gt; returnList = new LinkedList&amp;lt;&amp;gt;();
            int index1=0;
            int index2=0;
            boolean oneNull =false,index1Boolean = true,index2Boolean = true;
            while(index1!=i1.size()||index2!=i2.size()){
                if(index1==i1.size()&amp;amp;&amp;amp;index1Boolean){
                    returnList.add(i2.get(index2));
                    index2++;
                    oneNull=true;
                    index2Boolean = false;
                }
                if(index2==i2.size()&amp;amp;&amp;amp;index2Boolean){
                    returnList.add(i1.get(index1));
                    index1++;
                    oneNull=true;
                    index1Boolean = false;
                }
                if(!oneNull){
                    if(i2.get(index2)&amp;gt;i1.get(index1)){
                        returnList.add(i1.get(index1));
                        index1++;
                    }else{
                        returnList.add(i2.get(index2));
                        index2++;
                    }
                }
            }
            return returnList;

        }

    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;计数排序&quot;&gt;&lt;a href=&quot;#计数排序&quot; class=&quot;headerlink&quot; title=&quot;计数排序&quot;&gt;&lt;/a&gt;计数排序&lt;/h1&gt;&lt;p&gt;计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。&lt;/p&gt;
&lt;h1 id=&quot;桶排序&quot;&gt;&lt;a href=&quot;#桶排序&quot; class=&quot;headerlink&quot; title=&quot;桶排序&quot;&gt;&lt;/a&gt;桶排序&lt;/h1&gt;&lt;h1 id=&quot;基数排序&quot;&gt;&lt;a href=&quot;#基数排序&quot; class=&quot;headerlink&quot; title=&quot;基数排序&quot;&gt;&lt;/a&gt;基数排序&lt;/h1&gt;&lt;p&gt;基数排序（英语：Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数&lt;/p&gt;
&lt;p&gt;参考博客&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/xiazdong/article/details/8462393&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/xiazdong/article/details/8462393&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.open-open.com/lib/view/open1420372620468.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.open-open.com/lib/view/open1420372620468.html&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;常用的排序算法我知道的有9种&lt;br&gt;在whuslei博客中发现这么一张图片能概括这9种算法.&lt;br&gt;&lt;img src=&quot;/img/2016/04/001.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些算法主要比较的是时间复杂性,稳定性,和实现的复杂度&lt;br&gt;稳定性，就是有两个
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="算法" scheme="http://jellygogo.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="排序" scheme="http://jellygogo.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>MRunit combiner partitioner</title>
    <link href="http://jellygogo.com/2016/04/07/MRunit_combiner_partitioner/"/>
    <id>http://jellygogo.com/2016/04/07/MRunit_combiner_partitioner/</id>
    <published>2016-04-07T15:50:55.000Z</published>
    <updated>2016-04-09T20:41:22.000Z</updated>
    
    <content type="html">&lt;p&gt;在maven中使用MRunit测试框架搭建了个mapreduce程序,里面使用了combiner和partitioner&lt;br&gt;并使用了 org.apache.hadoop.util.Tool&lt;br&gt;实现了找出对应年份的最大值,&lt;br&gt;        //数据样例&lt;br&gt;        1995 65&lt;br&gt;        1965 21&lt;br&gt;        1995 62&lt;br&gt;为了验证使用combiner和不适用combiner的不同,所以写了个生成数据的小程序&lt;br&gt;    package com.jellygogo.basejava;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
public class MaxNumOfYearTest implements Runnable{
    public static final int ONEFILEMAXLINE = 100000;
    public static final int STARTFILE = 0 ;
    public static final int ENDFILE = 1;
    public int num;
    public MaxNumOfYearTest(int num) {
        super();
        this.num = num;
    }
    public static void main(String[] args) {
        for(int i=STARTFILE;i&amp;lt;ENDFILE;i++){
            Thread thread = new Thread(new MaxNumOfYearTest(i));
            thread.start();
        }
    }
    public void run() {
        // TODO Auto-generated method stub
        File file = new File(&amp;quot;C:\\Users\\Administrator\\Desktop\\笔记\\testdata\\test&amp;quot;+num+&amp;quot;.txt&amp;quot;);
        FileWriter b =null;
        try {
            b= new FileWriter(file);
            for(int i = 0;i&amp;lt;ONEFILEMAXLINE;i++){
                int randomYear = 1900 + (int)(Math.random()*100);
                int randomNum = (int)(Math.random()*100);
                b.write(randomYear+&amp;quot; &amp;quot;+randomNum+&amp;quot;\n&amp;quot;);
            }
        } catch (IOException e) {
            e.printStackTrace();
            System.out.println(e);
        }finally{
            try {
                b.close();
            } catch (IOException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;下面是对应的源码&lt;/p&gt;
&lt;p&gt;pom.xml&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;lt;project xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot;  
     xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&amp;quot;&amp;gt;  
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;  
    &amp;lt;groupId&amp;gt;com.jellygogo.ToolTest&amp;lt;/groupId&amp;gt;  
    &amp;lt;artifactId&amp;gt;ToolTest&amp;lt;/artifactId&amp;gt;  
    &amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt;    
    &amp;lt;name&amp;gt;ToolTest&amp;lt;/name&amp;gt;  
    &amp;lt;url&amp;gt;http://maven.apache.org&amp;lt;/url&amp;gt;  
    &amp;lt;properties&amp;gt;  
    &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;  
    &amp;lt;/properties&amp;gt;
    &amp;lt;dependencies&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;hadoop-common&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;2.5.2&amp;lt;/version&amp;gt;  
        &amp;lt;/dependency&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;hadoop-hdfs&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;2.5.2&amp;lt;/version&amp;gt;  
        &amp;lt;/dependency&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;hadoop-client&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;2.5.2&amp;lt;/version&amp;gt;  
        &amp;lt;/dependency&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;4.10&amp;lt;/version&amp;gt;  
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;  
        &amp;lt;/dependency&amp;gt;  

        &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.mrunit&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;mrunit&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;0.9.0-incubating&amp;lt;/version&amp;gt;
        &amp;lt;classifier&amp;gt;hadoop2&amp;lt;/classifier&amp;gt; 
        &amp;lt;/dependency&amp;gt;

    &amp;lt;/dependencies&amp;gt;  
    &amp;lt;version&amp;gt;3.0&amp;lt;/version&amp;gt;
    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;3.3&amp;lt;/version&amp;gt;
                &amp;lt;configuration&amp;gt;
                    &amp;lt;source&amp;gt;1.7&amp;lt;/source&amp;gt;
                    &amp;lt;target&amp;gt;1.7&amp;lt;/target&amp;gt;
                &amp;lt;/configuration&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ToolTest.java&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.hadoop;    
import java.io.IOException;    
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Partitioner;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;    
public class ToolTest extends Configured implements Tool {        
    public int run(String[] arg0) throws Exception {
        Job job = Job.getInstance(getConf());
        job.setJarByClass(ToolTest.class);
        job.setInputFormatClass(TextInputFormat.class);
        job.setOutputFormatClass(TextOutputFormat.class);    
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);
        FileInputFormat.setInputPaths(job, new Path(arg0[0]));
        FileOutputFormat.setOutputPath(job, new Path(arg0[1]));
        job.setMapperClass(MapperTest.class);
        job.setReducerClass(ReduceTest.class);
        job.setCombinerClass(CTest.class);
        job.setNumReduceTasks(5);
        job.setPartitionerClass(MyPartitioner.class);
        if (job.waitForCompletion(true))
            return 0;
        else
            return 1;
    }
    public static void main(String[] args) {
        Configuration configuration = new Configuration();
        try {
            ToolRunner.run(new ToolTest(), args);
        } catch (Exception e) {
            e.printStackTrace();
            System.out.println(e);
        }
    }
}
class ReduceTest extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
    protected void reduce(Text arg0, Iterable&amp;lt;Text&amp;gt; arg1, Reducer&amp;lt;Text, Text, Text, Text&amp;gt;.Context arg2)
            throws IOException, InterruptedException {
        int max = 0;
        for (Text t : arg1) {
            String intString = t.toString();
            int thisvalue = Integer.valueOf(intString);
            if (thisvalue &amp;gt; max)
                max = thisvalue;
        }
        arg2.write(arg0, new Text(max + &amp;quot;&amp;quot;));
    }
}
class MapperTest extends Mapper&amp;lt;LongWritable, Text, Text, Text&amp;gt; {
    protected void map(LongWritable key, Text value, Mapper&amp;lt;LongWritable, Text, Text, Text&amp;gt;.Context context)
            throws IOException, InterruptedException {
        String v = value.toString();
        if (v != null &amp;amp;&amp;amp; v.length() &amp;gt; 5) {
            context.write(new Text(value.toString().substring(0, 4)),
                    new Text(value.toString().substring(5, v.length())));
        }
    }
}
class CTest extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
    protected void reduce(Text arg0, Iterable&amp;lt;Text&amp;gt; arg1, Reducer&amp;lt;Text, Text, Text, Text&amp;gt;.Context arg2)
            throws IOException, InterruptedException {
        int max = 0;
        for (Text t : arg1) {
            String intString = t.toString();
            int thisvalue = Integer.valueOf(intString);
            if (thisvalue &amp;gt; max)
                max = thisvalue;
        }
        arg2.write(arg0, new Text(max + &amp;quot;&amp;quot;));
    }
}

class MyPartitioner extends Partitioner{
    public int getPartition(Object key, Object value, int numPartitions) {
        // TODO Auto-generated method stub
        int result = 0;
        if (key.toString().startsWith(&amp;quot;1&amp;quot;)) {  
            result = 0 % numPartitions;  
        } else if (key.toString().startsWith(&amp;quot;2&amp;quot;)) {  
            result = 1 % numPartitions;  
        }else {
            result = 3 % numPartitions; 
        }
        return result;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MR2Test.java&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.hadoop;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mrunit.mapreduce.MapDriver;
import org.apache.hadoop.mrunit.mapreduce.MapReduceDriver;
import org.apache.hadoop.mrunit.mapreduce.ReduceDriver;
import org.apache.hadoop.mrunit.types.Pair;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Test;
import junit.framework.TestCase;
public class MR2Test extends TestCase{

    private Mapper&amp;lt;LongWritable, Text, Text, Text&amp;gt; mapper;
    private Reducer reducer;
    private MapDriver&amp;lt;LongWritable, Text, Text, Text&amp;gt; mapDirver;
    private ReduceDriver reduceDirver;
    private MapReduceDriver rdDirver; 
    @Test
    public void testMap(){
        mapper = new MapperTest();
        reducer = new ReduceTest();
        mapDirver = new MapDriver&amp;lt;&amp;gt;(mapper);
        reduceDirver = new ReduceDriver&amp;lt;&amp;gt;(reducer);
        rdDirver = new MapReduceDriver&amp;lt;&amp;gt;(mapper, reducer);
        mapDirver.withInput(new LongWritable(1L), new Text(&amp;quot;1995 56&amp;quot;));
        mapDirver.withOutput( new Text(&amp;quot;1995&amp;quot;), new Text(&amp;quot;56&amp;quot;));
        mapDirver.runTest();
    }
    @Test
    public void testReduceOneValue(){
        mapper = new MapperTest();
        reducer = new ReduceTest();
        mapDirver = new MapDriver&amp;lt;&amp;gt;(mapper);
        reduceDirver = new ReduceDriver&amp;lt;&amp;gt;(reducer);
        rdDirver = new MapReduceDriver&amp;lt;&amp;gt;(mapper, reducer);
        List&amp;lt;Text&amp;gt; list = new ArrayList&amp;lt;Text&amp;gt;();
        list.add(new Text(&amp;quot;1&amp;quot;));
        list.add(new Text(&amp;quot;5&amp;quot;));
        list.add(new Text(&amp;quot;4&amp;quot;));
        reduceDirver.withInput(new Text(&amp;quot;1995&amp;quot;), list);
        reduceDirver.withOutput( new Text(&amp;quot;1995&amp;quot;), new Text(&amp;quot;5&amp;quot;));
//        try {
//            List&amp;lt;Pair&amp;gt; l = reduceDirver.run();
//            System.out.println(&amp;quot;testReduceOneValue=====&amp;quot;);
//            for(Pair o:l)
//                System.out.println(o);
//        } catch (IOException e) {
//            // TODO Auto-generated catch block
//            e.printStackTrace();
//        }
    }
    @Test
    public void testMapReduce(){
        mapper = new MapperTest();
        reducer = new ReduceTest();
        mapDirver = new MapDriver&amp;lt;&amp;gt;(mapper);
        reduceDirver = new ReduceDriver&amp;lt;&amp;gt;(reducer);
        rdDirver = new MapReduceDriver&amp;lt;&amp;gt;(mapper, reducer);
        rdDirver.withInput(new LongWritable(1L), new Text(&amp;quot;1995 5&amp;quot;));
        rdDirver.withInput(new LongWritable(2L), new Text(&amp;quot;1995 6&amp;quot;));
        rdDirver.withInput(new LongWritable(3L), new Text(&amp;quot;1996 10&amp;quot;));
        rdDirver.withInput(new LongWritable(5L), new Text(&amp;quot;1996 1&amp;quot;));
        rdDirver.withInput(new LongWritable(6L), new Text(&amp;quot;1994 100&amp;quot;));
        rdDirver.withInput(new LongWritable(7L), new Text(&amp;quot;1996 2&amp;quot;));
        rdDirver.withOutput( new Text(&amp;quot;1994&amp;quot;), new Text(&amp;quot;100&amp;quot;));
        rdDirver.withOutput( new Text(&amp;quot;1995&amp;quot;), new Text(&amp;quot;6&amp;quot;));
        rdDirver.withOutput( new Text(&amp;quot;1996&amp;quot;), new Text(&amp;quot;10&amp;quot;));
//        withoutput应该按照key排序输入
//        (1994, 100)
//        (1995, 6)
//        (1996, 10)
        rdDirver.runTest();
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一次测试时,没有加job.setCombinerClass(CTest.class) 这一句,没有使用combiner&lt;br&gt;得出结果如下:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Map-Reduce Framework&lt;br&gt;               Map input records=100000&lt;br&gt;               Map output records=100000&lt;br&gt;               Map output bytes=789913&lt;br&gt;               Map output materialized bytes=989925&lt;br&gt;               Input split bytes=103&lt;br&gt;               Combine input records=0&lt;br&gt;               Combine output records=0&lt;br&gt;               Reduce input groups=100&lt;br&gt;               Reduce shuffle bytes=989925&lt;br&gt;               Reduce input records=100000&lt;br&gt;               Reduce output records=100&lt;br&gt;               Spilled Records=200000&lt;br&gt;               Shuffled Maps =2&lt;br&gt;               Failed Shuffles=0&lt;br&gt;               Merged Map outputs=2&lt;br&gt;               GC time elapsed (ms)=487&lt;br&gt;               CPU time spent (ms)=6770&lt;br&gt;               Physical memory (bytes) snapshot=383012864&lt;br&gt;               Virtual memory (bytes) snapshot=6227005440&lt;br&gt;               Total committed heap usage (bytes)=157134848&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用combiner之后&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Map-Reduce Framework&lt;br&gt;             Map input records=100000&lt;br&gt;             Map output records=100000&lt;br&gt;             Map output bytes=789913&lt;br&gt;             Map output materialized bytes=1012&lt;br&gt;             Input split bytes=103&lt;br&gt;             Combine input records=100000&lt;br&gt;             Combine output records=100&lt;br&gt;             Reduce input groups=100&lt;br&gt;             Reduce shuffle bytes=1012&lt;br&gt;             Reduce input records=100&lt;br&gt;             Reduce output records=100&lt;br&gt;             Spilled Records=200&lt;br&gt;             Shuffled Maps =2&lt;br&gt;             Failed Shuffles=0&lt;br&gt;             Merged Map outputs=2&lt;br&gt;             GC time elapsed (ms)=444&lt;br&gt;             CPU time spent (ms)=4860&lt;br&gt;             Physical memory (bytes) snapshot=392232960&lt;br&gt;             Virtual memory (bytes) snapshot=6227005440&lt;br&gt;             Total committed heap usage (bytes)=156102656&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以对比出&lt;br&gt;                Combine input records=0&lt;br&gt;                Combine output records=0&lt;br&gt;与&lt;br&gt;                Combine input records=100000&lt;br&gt;                Combine output records=100&lt;/p&gt;
&lt;p&gt;Combiner相关链接 &lt;a href=&quot;http://www.tuicool.com/articles/qAzUjav&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.tuicool.com/articles/qAzUjav&lt;/a&gt;&lt;br&gt;partitioner相关链接 &lt;a href=&quot;http://www.cnblogs.com/xwdreamer/archive/2011/10/27/2296943.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/xwdreamer/archive/2011/10/27/2296943.html&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;二次排序&quot;&gt;&lt;a href=&quot;#二次排序&quot; class=&quot;headerlink&quot; title=&quot;二次排序&quot;&gt;&lt;/a&gt;二次排序&lt;/h1&gt;&lt;p&gt;此次是把前面的例子修改下,使其满足使用二次排序&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.educity.cn/linux/1603517.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.educity.cn/linux/1603517.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/img/2016/04/002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;前面的例子只有年和最大数,现在的例子要求先按照年份降序再按月份升序,&lt;br&gt;修改数据的生成&lt;br&gt;                int randomYear = 1900 + (int)(Math.random()&lt;em&gt;100);&lt;br&gt;                int randomMonth = (int)(Math.random()&lt;/em&gt;12);&lt;br&gt;                int randomNum = (int)(Math.random()*100)+randomMonth;&lt;br&gt;                b.write(randomYear+” “+randomMonth+” “+randomNum+”\n”);&lt;/p&gt;
&lt;p&gt;自己新建key 在map output和reduce input中使用,compareTo方式实现了先按照年份降序再按月份升序,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    class YearAndMonthWritable implements WritableComparable&amp;lt;YearAndMonthWritable&amp;gt; {

    public Text year = new Text();
    public Text month = new Text();

    public YearAndMonthWritable() {
    }

    public YearAndMonthWritable(Text year, Text month) {
        this.year = year;
        this.month = month;
    }

    @Override
    public void write(DataOutput out) throws IOException {
        // TODO Auto-generated method stub
        this.year.write(out);
        this.month.write(out);
    }

    @Override
    public void readFields(DataInput in) throws IOException {
        // TODO Auto-generated method stub
        this.year.readFields(in);
        this.month.readFields(in);
    }

    @Override
    public int compareTo(YearAndMonthWritable other) {
        // TODO Auto-generated method stub
        int yearC = this.year.toString().compareTo(other.year.toString());
        int monthC = Math.abs(Integer.valueOf(this.month.toString()).compareTo(Integer.valueOf(other.month.toString())));
        if (yearC &amp;gt;= 0) {
            return -monthC;
        } else {
            return monthC;
        }
    }

    @Override
    public String toString() {
        // TODO Auto-generated method stub
        return this.year.toString() + &amp;quot; &amp;quot; + this.month.toString();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用默认的Partitioner,得出结果如下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;File System Counters
        FILE: Number of bytes read=4272
        FILE: Number of bytes written=1276859
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=101887
        HDFS: Number of bytes written=3532
        HDFS: Number of read operations=39
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=24
Job Counters
        Launched map tasks=1
        Launched reduce tasks=12
        Data-local map tasks=1
        Total time spent by all maps in occupied slots (ms)=8384
        Total time spent by all reduces in occupied slots (ms)=1075954
        Total time spent by all map tasks (ms)=8384
        Total time spent by all reduce tasks (ms)=1075954
        Total vcore-seconds taken by all map tasks=8384
        Total vcore-seconds taken by all reduce tasks=1075954
        Total megabyte-seconds taken by all map tasks=8585216
        Total megabyte-seconds taken by all reduce tasks=1101776896
Map-Reduce Framework
        Map input records=10000
        Map output records=10000
        Map output bytes=101781
        Map output materialized bytes=4272
        Input split bytes=106
        Combine input records=10000
        Combine output records=334
        Reduce input groups=334
        Reduce shuffle bytes=4272
        Reduce input records=334
        Reduce output records=334
        Spilled Records=668
        Shuffled Maps =12
        Failed Shuffles=0
        Merged Map outputs=12
        GC time elapsed (ms)=5909
        CPU time spent (ms)=30300
        Physical memory (bytes) snapshot=1146945536
        Virtual memory (bytes) snapshot=27008589824
        Total committed heap usage (bytes)=326991872
Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
File Input Format Counters
        Bytes Read=101781
File Output Format Counters
        Bytes Written=3532
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;在maven中使用MRunit测试框架搭建了个mapreduce程序,里面使用了combiner和partitioner&lt;br&gt;并使用了 org.apache.hadoop.util.Tool&lt;br&gt;实现了找出对应年份的最大值,&lt;br&gt;        //数据样例&lt;br&gt; 
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="mapreduce" scheme="http://jellygogo.com/tags/mapreduce/"/>
    
      <category term="combiner" scheme="http://jellygogo.com/tags/combiner/"/>
    
      <category term="partitioner" scheme="http://jellygogo.com/tags/partitioner/"/>
    
      <category term="MRunit" scheme="http://jellygogo.com/tags/MRunit/"/>
    
      <category term="Tool" scheme="http://jellygogo.com/tags/Tool/"/>
    
  </entry>
  
  <entry>
    <title>常用java类源码初窥</title>
    <link href="http://jellygogo.com/2016/03/31/%E5%B8%B8%E7%94%A8java%E7%B1%BB%E6%BA%90%E7%A0%81%E5%88%9D%E7%AA%A5/"/>
    <id>http://jellygogo.com/2016/03/31/常用java类源码初窥/</id>
    <published>2016-03-31T13:54:00.000Z</published>
    <updated>2016-04-03T09:03:20.356Z</updated>
    
    <content type="html">&lt;p&gt;包括内容:java常用类源码,java源码中常用数据结构&lt;br&gt;此篇博客用来记录我对java基础在源码上面的认识,不定时填坑&lt;/p&gt;
&lt;h1 id=&quot;1-List系列&quot;&gt;&lt;a href=&quot;#1-List系列&quot; class=&quot;headerlink&quot; title=&quot;1.List系列&quot;&gt;&lt;/a&gt;1.List系列&lt;/h1&gt;&lt;p&gt;List系列常用的实现类是LinkedList和ArrayList&lt;/p&gt;
&lt;h2 id=&quot;ArrayList&quot;&gt;&lt;a href=&quot;#ArrayList&quot; class=&quot;headerlink&quot; title=&quot;ArrayList&quot;&gt;&lt;/a&gt;ArrayList&lt;/h2&gt;&lt;p&gt;内部使用一个数组来实现List&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;private transient Object[] elementData;&lt;/p&gt;
&lt;p&gt;Java的serialization提供了一种持久化对象实例的机制。当持久化对象时，可能有一个特殊的对象数据成员，我们不想&lt;br&gt;用serialization机制来保存它。为了在一个特定对象的一个域上关闭serialization，可以在这个域前加上关键字transient。&lt;br&gt;transient是Java语言的关键字，用来表示一个域不是该对象串行化的一部分。当一个对象被串行化的时候，transient型变量的值不包括在串行化的表示中，然而非transient型的变量是被包括进去的&lt;br&gt;转自:&lt;a href=&quot;http://www.blogjava.net/fhtdy2004/archive/2009/06/20/286112.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.blogjava.net/fhtdy2004/archive/2009/06/20/286112.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ArrayList中插入一个元素需要将此元素后面的都往后移动,&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;public void add(int index, E element) {&lt;br&gt;        rangeCheckForAdd(index);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    ensureCapacityInternal(size + 1);  // Increments modCount!!
    System.arraycopy(elementData, index, elementData, index + 1,
                     size - index);
    elementData[index] = element;
    size++;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关于System.arraycopy()  &lt;a href=&quot;http://xuyuanshuaaa.iteye.com/blog/1046621&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://xuyuanshuaaa.iteye.com/blog/1046621&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ArrayList中删除元素时,并不会将内部的elementData变小&lt;/p&gt;
&lt;/blockquote&gt;&lt;/p&gt;
&lt;h2 id=&quot;LinkedList&quot;&gt;&lt;a href=&quot;#LinkedList&quot; class=&quot;headerlink&quot; title=&quot;LinkedList&quot;&gt;&lt;/a&gt;LinkedList&lt;/h2&gt;&lt;p&gt;内部使用内部对象存储,&lt;br&gt;public class LinkedList&lt;e&gt;&lt;br&gt;    extends AbstractSequentialList&lt;e&gt;&lt;br&gt;    implements List&lt;e&gt;, Deque&lt;e&gt;, Cloneable, java.io.Serializable&lt;/e&gt;&lt;/e&gt;&lt;/e&gt;&lt;/e&gt;&lt;/p&gt;
&lt;p&gt;如果有大量随机访问对象的需求,就使用ArrayList,如果有大量插入删除使用LinkedList&lt;/p&gt;
&lt;h1 id=&quot;2-Map系列&quot;&gt;&lt;a href=&quot;#2-Map系列&quot; class=&quot;headerlink&quot; title=&quot;2.Map系列&quot;&gt;&lt;/a&gt;2.Map系列&lt;/h1&gt;&lt;p&gt;几个常用Map实现类:HashMap TreeMap LinkedHashMap ConcurrentHashMap&lt;/p&gt;
&lt;h2 id=&quot;HashMap&quot;&gt;&lt;a href=&quot;#HashMap&quot; class=&quot;headerlink&quot; title=&quot;HashMap&quot;&gt;&lt;/a&gt;HashMap&lt;/h2&gt;&lt;p&gt; 使用数组和链表实现,在HashMap中使用一个数组,内部的hash()计算出hash值一样的数放入同一个Entry中,Entry中使用链表存储&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; transient Entry&amp;lt;K,V&amp;gt;[] table = (Entry&amp;lt;K,V&amp;gt;[]) EMPTY_TABLE;
 static class Entry&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final K key;
    V value;
    Entry&amp;lt;K,V&amp;gt; next;
    int hash;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;HashMap其实就是一个Entry数组，Entry对象中包含了键和值，其中next也是一个Entry对象，它就是用来处理hash冲突的，形成一个链表。&lt;/p&gt;
&lt;p&gt;关于HashMap很贴切的解释 &lt;a href=&quot;http://www.cnblogs.com/ITtangtang/p/3948406.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/ITtangtang/p/3948406.html&lt;/a&gt; 包含loadFactor加载因子的内容&lt;/p&gt;
&lt;h2 id=&quot;TreeMap&quot;&gt;&lt;a href=&quot;#TreeMap&quot; class=&quot;headerlink&quot; title=&quot;TreeMap&quot;&gt;&lt;/a&gt;TreeMap&lt;/h2&gt;&lt;p&gt;Tree内部使用二叉树(红黑树)来存储key-value&lt;br&gt;(先开个坑,有空再填)&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/chenssy/article/details/26668941&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/chenssy/article/details/26668941&lt;/a&gt; &lt;/p&gt;
&lt;h2 id=&quot;LinkedHashMap&quot;&gt;&lt;a href=&quot;#LinkedHashMap&quot; class=&quot;headerlink&quot; title=&quot;LinkedHashMap&quot;&gt;&lt;/a&gt;LinkedHashMap&lt;/h2&gt;&lt;p&gt;LinkedHashMap继承自HashMap,在HashMap基础上面增加了TreeMap的顺序输出功能,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Entry中,增加了next
static class Entry&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final K key;
    V value;
    Entry&amp;lt;K,V&amp;gt; next;
    int hash;
}
public V put(K key, V value) {
    if (table == EMPTY_TABLE) {
        inflateTable(threshold);
    }
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key);
    int i = indexFor(hash, table.length);
    for (Entry&amp;lt;K,V&amp;gt; e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);//&amp;lt;----------
            return oldValue;
        }
    }

    modCount++;
    addEntry(hash, key, value, i);
    return null;
}
//LinkedHashMap中重载了recordAccess这个方法.
//recordAccess中标记了
    void recordAccess(HashMap&amp;lt;K,V&amp;gt; m) {
        LinkedHashMap&amp;lt;K,V&amp;gt; lm = (LinkedHashMap&amp;lt;K,V&amp;gt;)m;
        if (lm.accessOrder) {
            lm.modCount++;
            remove();
            addBefore(lm.header);
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;ConcurrentHashMap&quot;&gt;&lt;a href=&quot;#ConcurrentHashMap&quot; class=&quot;headerlink&quot; title=&quot;ConcurrentHashMap&quot;&gt;&lt;/a&gt;ConcurrentHashMap&lt;/h2&gt;&lt;p&gt;这是一个线程安全的HashMap,在Collection中也提供了线程安全类&lt;br&gt;    public static &lt;k,v&gt; Map&lt;k,v&gt; synchronizedMap(Map&lt;k,v&gt; m) {&lt;br&gt;        return new SynchronizedMap&lt;k,v&gt;(m);&lt;br&gt;     }&lt;br&gt;SynchronizedMap中所有的方法都加上了synchronized,保证了方法的同步,但在使用中仍然会有安全问题&lt;br&gt;ConcurrentHashMap中使用了,锁分段技术具体细节刨个坑,以后再填&lt;/k,v&gt;&lt;/k,v&gt;&lt;/k,v&gt;&lt;/k,v&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/madun/article/details/6326337&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/madun/article/details/6326337&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;关于HashMap和hashTable&quot;&gt;&lt;a href=&quot;#关于HashMap和hashTable&quot; class=&quot;headerlink&quot; title=&quot;关于HashMap和hashTable &quot;&gt;&lt;/a&gt;关于HashMap和hashTable &lt;/h2&gt;&lt;p&gt;HashMap中key和value都可以是null,而在hashtable中key和value都不能是null&lt;br&gt;hashtable是线程安全的,但是效率低下,全局使用了一把锁,当其他线程访问时,容易堵塞&lt;/p&gt;
&lt;h2 id=&quot;WeakHashMap&quot;&gt;&lt;a href=&quot;#WeakHashMap&quot; class=&quot;headerlink&quot; title=&quot;WeakHashMap&quot;&gt;&lt;/a&gt;WeakHashMap&lt;/h2&gt;&lt;p&gt;Map总结(HashMap, Hashtable, TreeMap, WeakHashMap等使用场景)  &lt;a href=&quot;http://www.chawenti.com/articles/20110.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.chawenti.com/articles/20110.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2016-4-3 参考书籍:java程序员成功面试秘籍(书名感觉挺low的,但是里面还是有一定东西的)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;包括内容:java常用类源码,java源码中常用数据结构&lt;br&gt;此篇博客用来记录我对java基础在源码上面的认识,不定时填坑&lt;/p&gt;
&lt;h1 id=&quot;1-List系列&quot;&gt;&lt;a href=&quot;#1-List系列&quot; class=&quot;headerlink&quot; title=&quot;1.List
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="源码" scheme="http://jellygogo.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="数据结构" scheme="http://jellygogo.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop气象数据下载小程序</title>
    <link href="http://jellygogo.com/2016/03/17/Hadoop%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD%E5%B0%8F%E7%A8%8B%E5%BA%8F/"/>
    <id>http://jellygogo.com/2016/03/17/Hadoop气象数据下载小程序/</id>
    <published>2016-03-17T14:18:26.000Z</published>
    <updated>2016-03-17T14:41:22.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;a href=&quot;#Hadoop气象数据下载小程序&quot; class=&quot;headerlink&quot; title=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;/a&gt;Hadoop气象数据下载小程序&lt;/h1&gt;&lt;h2 id=&quot;写小程序的原因&quot;&gt;&lt;a href=&quot;#写小程序的原因&quot; class=&quot;headerlink&quot; title=&quot;写小程序的原因&quot;&gt;&lt;/a&gt;写小程序的原因&lt;/h2&gt;&lt;p&gt;在学习Hadoop学习指南时,遇到了&lt;a href=&quot;ftp://www1.ncdc.noaa.gov/pub/data/noaa&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ftp&lt;/a&gt;下载链接不能下载的原因,于是去找&lt;a href=&quot;http://www1.ncdc.noaa.gov/pub/data/noaa&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http下载&lt;/a&gt;的链接,但是使用迅雷批量下载时遇到了文件限制,在每个年份的文件夹下大约有1W-3W个文件,但是迅雷批量下载一次只能下载1000个连接,遂自己写了短代码,来自己下载&lt;/p&gt;
&lt;p&gt;顺便这段时间再看代码整洁之道,我试下尽我所能写出书什么样的代码&lt;/p&gt;
&lt;h2 id=&quot;java代码&quot;&gt;&lt;a href=&quot;#java代码&quot; class=&quot;headerlink&quot; title=&quot;java代码&quot;&gt;&lt;/a&gt;java代码&lt;/h2&gt;&lt;p&gt;现在还才刚开始学习Python,过段时间会来再用Python代码实现下这个功能&lt;br&gt;重新需要输入一个在1970-2016之间的数字来下载某一年的数据,因为我不需要太多的数据,所以这样设计的.&lt;/p&gt;
&lt;p&gt;关于线程池的选择&lt;br&gt;&lt;a href=&quot;http://coach.iteye.com/blog/855850&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;线程池的使用&lt;/a&gt; &lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	public class NcdcFileDownload &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	private final static String  HTTPURL = &amp;quot;http://www1.ncdc.noaa.gov/pub/data/noaa/&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	private final static String ROOTFOLDER = &amp;quot;D://filedowntest//&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	 public static void main(String[] args) throws Exception  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	    &amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 	int year = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 	Scanner scanner = new Scanner(System.in);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 	year = scanner.nextInt();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        // 创建HttpClient实例     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpClient httpclient = new DefaultHttpClient(); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        // 创建Get方法实例     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpGet httpgets = new HttpGet(HTTPURL+year+&amp;quot;/&amp;quot;);    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpResponse response = httpclient.execute(httpgets);    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpEntity entity = response.getEntity(); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        // 存储这一年每个气象数据的url&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HashSet&amp;lt;String&amp;gt; httpDownLoadURL = new HashSet&amp;lt;String&amp;gt;();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        if (entity != null) &amp;#123;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            InputStream instreams = entity.getContent();    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            //获取这一页的HTML代码,从中提取带有 -XXXX.gz的url&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            String responseHTMLInformation = convertStreamToString(instreams);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            String[] allHttpDownLoadURL = responseHTMLInformation.split(&amp;quot;-&amp;quot;+year+&amp;quot;.gz&amp;quot;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            HttpDownload httpDownload = null;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            //去除错误与重复的url,并放在httpDownLoadURL中&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            for(String tmp:allHttpDownLoadURL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	if(tmp!=null&amp;amp;&amp;amp;tmp.length()&amp;gt;13)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            	tmp = tmp.substring(tmp.length()-12)+&amp;quot;-2015.gz&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            	if(tmp!=null&amp;amp;&amp;amp;tmp.length()==20)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            		httpDownLoadURL.add(tmp);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            int downLoadTaskNum = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            ThreadPoolExecutor executor = new ThreadPoolExecutor(20, 30, 10,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            		TimeUnit.SECONDS, new ArrayBlockingQueue&amp;lt;Runnable&amp;gt;(10000),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            		new ThreadPoolExecutor.DiscardOldestPolicy());&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            for(String tmp:httpDownLoadURL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	downLoadTaskNum++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	File createFolder = new File(ROOTFOLDER+year);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	createFolder.mkdir();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload = new HttpDownload();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload.setUrl(HTTPURL+year+&amp;quot;/&amp;quot;+tmp);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload.setPath(ROOTFOLDER+year+&amp;quot;//&amp;quot;+tmp);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload.setI(downLoadTaskNum);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	executor.execute(httpDownload);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	           httpgets.abort();    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		public static String convertStreamToString(InputStream is) &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        BufferedReader reader = new BufferedReader(new InputStreamReader(is));      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        StringBuilder sb = new StringBuilder();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        String line = null;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        try &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            while ((line = reader.readLine()) != null) &amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	                sb.append(line + &amp;quot;\n&amp;quot;);      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125; catch (IOException e) &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            e.printStackTrace();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125; finally &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            try &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	                is.close();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125; catch (IOException e) &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	               e.printStackTrace();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        return sb.toString();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下载文件的类&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class HttpDownload implements Runnable{
public  final int cache = 10 * 1024;
public  final boolean isWindows;
public  final String splash;
public  final String root;
private String url;
private String path;
private int i;

 public int getI() {
    return i;
}
public void setI(int i) {
    this.i = i;
}

{
    if (System.getProperty(&amp;quot;os.name&amp;quot;) != null &amp;amp;&amp;amp; System.getProperty(&amp;quot;os.name&amp;quot;).toLowerCase().contains(&amp;quot;windows&amp;quot;)) {
        isWindows = true;
        splash = &amp;quot;\\&amp;quot;;
        root=&amp;quot;D:&amp;quot;;
    } else {
        isWindows = false;
        splash = &amp;quot;/&amp;quot;;
        root=&amp;quot;/search&amp;quot;;
    }
}


public  String download() {
    try {
        HttpClient client = new DefaultHttpClient();
        HttpGet httpget = new HttpGet(url);
        HttpResponse response = client.execute(httpget);

        HttpEntity entity = response.getEntity();
        InputStream is = entity.getContent();
        if (path == null)
            path = getFilePath(response);
        File file = new File(path);
        file.getParentFile().mkdirs();
        FileOutputStream fileout = new FileOutputStream(file);
        /**
         * 根据实际运行效果 设置缓冲区大小
         */
        byte[] buffer=new byte[cache];
        int ch = 0;
        while ((ch = is.read(buffer)) != -1) {
            fileout.write(buffer,0,ch);
        }
        is.close();
        fileout.flush();
        fileout.close();

    } catch (Exception e) {
        e.printStackTrace();
    }
    return null;
}

public  String getFilePath(HttpResponse response) {
    String filepath = root + splash;
    String filename = getFileName(response);

    if (filename != null) {
        filepath += filename;
    } else {
        filepath += getRandomFileName();
    }
    return filepath;
}

public  String getFileName(HttpResponse response) {
    Header contentHeader = response.getFirstHeader(&amp;quot;Content-Disposition&amp;quot;);
    String filename = null;
    if (contentHeader != null) {
        HeaderElement[] values = contentHeader.getElements();
        if (values.length == 1) {
            NameValuePair param = values[0].getParameterByName(&amp;quot;filename&amp;quot;);
            if (param != null) {
                try {
                    filename = param.getValue();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }
    return filename;
}
/**
 * 获取随机文件名
 * @return
 */
public  String getRandomFileName() {
    return String.valueOf(System.currentTimeMillis());
}
public  void outHeaders(HttpResponse response) {
    Header[] headers = response.getAllHeaders();
    for (int i = 0; i &amp;lt; headers.length; i++) {
        System.out.println(headers[i]);
    }
}

@Override
public void run() {
    // TODO Auto-generated method stub
    try{
    download();
        System.out.println(&amp;quot;task&amp;quot;+this.i+&amp;quot;--&amp;quot;+this.url+&amp;quot;------100% SUCCESS&amp;quot;);
    }catch(Exception e){
        System.out.println(&amp;quot;task&amp;quot;+this.i+&amp;quot;--&amp;quot;+this.url+&amp;quot;------0% FAIL !!!!!!!!!!!!!!!!!!!!!!&amp;quot;);
    }

}

public String getUrl() {
    return url;
}

public void setUrl(String url) {
    this.url = url;
}

public String getPath() {
    return path;
}

public void setPath(String path) {
    this.path = path;
}

public int getCache() {
    return cache;
}

public boolean isWindows() {
    return isWindows;
}

public String getSplash() {
    return splash;
}

public String getRoot() {
    return root;
}


}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;a href=&quot;#Hadoop气象数据下载小程序&quot; class=&quot;headerlink&quot; title=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;/a&gt;Hadoop气象数据下载小程序&lt;/h1&gt;&lt;h2 id=&quot;写小程序的原因&quot;&gt;&lt;a h
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="Hadoop" scheme="http://jellygogo.com/tags/Hadoop/"/>
    
      <category term="大数据" scheme="http://jellygogo.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>转移到github的第一篇博客</title>
    <link href="http://jellygogo.com/2016/03/16/%E8%BD%AC%E7%A7%BB%E5%88%B0github%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <id>http://jellygogo.com/2016/03/16/转移到github的第一篇博客/</id>
    <published>2016-03-16T09:56:10.000Z</published>
    <updated>2016-03-16T14:41:22.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h1&gt;&lt;h2 id=&quot;以前的故事&quot;&gt;&lt;a href=&quot;#以前的故事&quot; class=&quot;headerlink&quot; title=&quot;以前的故事&quot;&gt;&lt;/a&gt;以前的故事&lt;/h2&gt;&lt;p&gt;以前也在csdn写过博客,都是一些学习笔记之类的东西,断断续续的写了一段时间,这期间伴随我学习spring源码,高性能MySQL等一些东西,期间慢慢接触到github这个东东,虽然感觉很神奇但是苦于英文疲软,一直没敢开这个坑.现在慢慢的接触开源项目越来越多,不得不接触她((✿◡‿◡))了,这次使用github也算是对github的入门了.&lt;/p&gt;
&lt;h2 id=&quot;现在的打算&quot;&gt;&lt;a href=&quot;#现在的打算&quot; class=&quot;headerlink&quot; title=&quot;现在的打算&quot;&gt;&lt;/a&gt;现在的打算&lt;/h2&gt;&lt;p&gt;发现自己不完善的地方很多,自我感觉很差,下面列举下目前感觉到的缺点&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;基础知识不好,特别是算法基础(全心专注外功,没有好好修炼过内功)&lt;br&gt;英文能力差,阅读github的 &lt;a href=&quot;https://guides.github.com/activities/hello-world/&quot; title=&quot;hello world链接&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;helloworld&lt;/a&gt;的文档都不流畅,上面写10分钟读完的,我tm快读了20分钟&lt;br&gt;懒,间歇性懒癌&lt;br&gt;选择性遗忘症&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;以后的打算&quot;&gt;&lt;a href=&quot;#以后的打算&quot; class=&quot;headerlink&quot; title=&quot;以后的打算&quot;&gt;&lt;/a&gt;以后的打算&lt;/h2&gt;&lt;p&gt;现在是大三了,还有一年半毕业,是时候要为自己的就业做打算了,目前我学习的重点是大数据研发,愿与君共勉&lt;/p&gt;
&lt;p&gt;博客写作计划:每周至少用心写一篇,坚持最难得,希望我能坚持下去(怀疑)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h1&gt;&lt;h2 id=&quot;以前的故事&quot;&gt;&lt;a href=&quot;#以前的故事&quot; class=&quot;headerlink&quot; title=
    
    </summary>
    
    
      <category term="闲话扯淡" scheme="http://jellygogo.com/tags/%E9%97%B2%E8%AF%9D%E6%89%AF%E6%B7%A1/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop从零开始重学1</title>
    <link href="http://jellygogo.com/2016/01/18/Hadoop%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E9%87%8D%E5%AD%A6(2)MapReduce%E6%8E%A2%E7%B4%A2/"/>
    <id>http://jellygogo.com/2016/01/18/Hadoop从零开始重学(2)MapReduce探索/</id>
    <published>2016-01-18T15:52:21.000Z</published>
    <updated>2017-01-18T14:01:10.537Z</updated>
    
    <content type="html">&lt;p&gt;&lt;strong&gt;不论何时，请勿好高骛远！写给曾经自我膨胀的我！&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;MapReduce来了&quot;&gt;&lt;a href=&quot;#MapReduce来了&quot; class=&quot;headerlink&quot; title=&quot;MapReduce来了&quot;&gt;&lt;/a&gt;MapReduce来了&lt;/h1&gt;&lt;p&gt;Map-Reduce提供快速并行计算能力，这种能力可以随着&lt;br&gt;节点数的增加线性递增&lt;br&gt;Map-reduce的思想就是“分而治之”&lt;/p&gt;
&lt;h2 id=&quot;MapReduce概述&quot;&gt;&lt;a href=&quot;#MapReduce概述&quot; class=&quot;headerlink&quot; title=&quot;MapReduce概述&quot;&gt;&lt;/a&gt;MapReduce概述&lt;/h2&gt;&lt;p&gt;在hadoop中文件通过输入格式(input format)处理成一系列的输入split&lt;/p&gt;
&lt;h2 id=&quot;map&quot;&gt;&lt;a href=&quot;#map&quot; class=&quot;headerlink&quot; title=&quot;map&quot;&gt;&lt;/a&gt;map&lt;/h2&gt;&lt;p&gt;map过程分为4步&lt;br&gt;1.record reader&lt;br&gt;将输入数据转换为记录,但不负责解析记录,只是把数据转换为key/value对,并传递给mapper处理&lt;br&gt;2.Mapper&lt;br&gt;Mapper负责“分”，即把复杂的任务分解为若干个“简单的任务”执行&lt;br&gt;“简单的任务”有几个含义：1 数据戒计算规模相对于原任务要大大缩小；2 就近计算，即会被分配到存放了所需数据的节点迚行计算；3 这些小任务可以幵行计算，彼此间几乎没有依赖关系&lt;br&gt;3.combiner&lt;br&gt;4.partitioner&lt;/p&gt;
&lt;h2 id=&quot;reduce&quot;&gt;&lt;a href=&quot;#reduce&quot; class=&quot;headerlink&quot; title=&quot;reduce&quot;&gt;&lt;/a&gt;reduce&lt;/h2&gt;&lt;p&gt;reduce过程也分为4步&lt;br&gt;1.shuffle 混排&lt;br&gt;2.sort 排序&lt;/p&gt;
&lt;h2 id=&quot;3-Reducer&quot;&gt;&lt;a href=&quot;#3-Reducer&quot; class=&quot;headerlink&quot; title=&quot;3.Reducer&quot;&gt;&lt;/a&gt;3.Reducer&lt;/h2&gt;&lt;p&gt;对map阶段的结果进行汇总Reducer的数目由mapred-site.xml配置文件里的项目mapred.reduce.tasks决定。缺&lt;br&gt;省值为1，用户可以覆盖设置&lt;br&gt;4.输出格式 output format&lt;/p&gt;
&lt;h1 id=&quot;MRUnit测试&quot;&gt;&lt;a href=&quot;#MRUnit测试&quot; class=&quot;headerlink&quot; title=&quot;MRUnit测试&quot;&gt;&lt;/a&gt;MRUnit测试&lt;/h1&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;不论何时，请勿好高骛远！写给曾经自我膨胀的我！&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;MapReduce来了&quot;&gt;&lt;a href=&quot;#MapReduce来了&quot; class=&quot;headerlink&quot; title=&quot;MapReduce来了&quot;&gt;&lt;/a&gt;MapRe
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="MapReduce" scheme="http://jellygogo.com/tags/MapReduce/"/>
    
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JellyGoGo Blog</title>
  <subtitle>扯淡,发呆,思考之处</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://jellygogo.com/"/>
  <updated>2016-12-31T06:43:08.290Z</updated>
  <id>http://jellygogo.com/</id>
  
  <author>
    <name>Gordon Young</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>New Year New Beginning</title>
    <link href="http://jellygogo.com/2016/12/31/New-Year-New-Beginning/"/>
    <id>http://jellygogo.com/2016/12/31/New-Year-New-Beginning/</id>
    <published>2016-12-31T09:34:51.000Z</published>
    <updated>2016-12-31T06:43:08.290Z</updated>
    
    <content type="html">&lt;h1 id=&quot;新的一年，新的开始！&quot;&gt;&lt;a href=&quot;#新的一年，新的开始！&quot; class=&quot;headerlink&quot; title=&quot;新的一年，新的开始！&quot;&gt;&lt;/a&gt;新的一年，新的开始！&lt;/h1&gt;&lt;p&gt;考研已经结束了5天了，这几天一直在休息，但是休息的时候竟然会有一种失落感，感觉自己没有目标了，唉，我四不四剑。&lt;br&gt;这次考研正常发挥，数学比较简单，专业课有点难，题量有点大，不过过线应该没有太大问题。&lt;/p&gt;
&lt;h1 id=&quot;Now，新的征程又要开始了！&quot;&gt;&lt;a href=&quot;#Now，新的征程又要开始了！&quot; class=&quot;headerlink&quot; title=&quot;Now，新的征程又要开始了！&quot;&gt;&lt;/a&gt;Now，新的征程又要开始了！&lt;/h1&gt;&lt;p&gt;经过8个月的考研复习，以前学习的东西基本上都还给老师了，现在需要巩固复习以前学习的java hadoop python相关的东西，然后学习些新的东西。&lt;br&gt;所以，现在是时候做出下一阶段的计划和复试准备计划！&lt;/p&gt;
&lt;h2 id=&quot;扬帆起航&quot;&gt;&lt;a href=&quot;#扬帆起航&quot; class=&quot;headerlink&quot; title=&quot;扬帆起航~~&quot;&gt;&lt;/a&gt;扬帆起航~~&lt;/h2&gt;&lt;p&gt;下一步整个寒假的重点还是在hadoop体系上面，了解数据挖掘与机器学习，语言重点还是java与python&lt;/p&gt;
&lt;p&gt;第一门：英语 听力和口语，继续记单词，每天半小时，提神醒脑算法设计，刷算法题，毕竟复试有四个题；408其他课程的学习，基础课程不能挺，按照408的基础讲义来吧，矩阵和概率-大数据的矩阵计算基础（第11期）&lt;br&gt;第二门：python学习，python在dataguru上面的python基础，爬虫，数据分析三连击&lt;br&gt;第三门：hadoop 主要是mapreduce&lt;br&gt;第四门：机器学习 入门和了解&lt;/p&gt;
&lt;h1 id=&quot;每天的博客写作计划，坚持下去&quot;&gt;&lt;a href=&quot;#每天的博客写作计划，坚持下去&quot; class=&quot;headerlink&quot; title=&quot;每天的博客写作计划，坚持下去&quot;&gt;&lt;/a&gt;每天的博客写作计划，坚持下去&lt;/h1&gt;&lt;p&gt;目前的书目：（有点多）&lt;br&gt;python语言程序设计&lt;br&gt;数据挖掘技术与工程实践&lt;br&gt;机器学习相关：机器学习 周志华；机器学习的哲学探索；机器学习系统设计；mahout算法解析与案例实战；Mahout in action；&lt;/p&gt;
&lt;p&gt;hadoop相关：hadoop mapReduceV2 参考手册 ；hadoop技术内幕-深入解析yarn架构设计与实现原理  ；深入理解hadoop；hadoop技术内幕-深入解析mapreduce架构设计和实现原理；&lt;br&gt;mapreduce 2.0源码分析与编程实战；mapreduce设计模式；mahout算法解析与案例实战；Mahout in action；&lt;/p&gt;
&lt;p&gt;杂记：BigData大数据日知录-架构与算法；大数据智能；大数据架构师指南；hadoop mapreduce 实战手册（第一版中文）；探路大数据：海量大数据与大规模分析；大话数据挖掘；&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;新的一年，新的开始！&quot;&gt;&lt;a href=&quot;#新的一年，新的开始！&quot; class=&quot;headerlink&quot; title=&quot;新的一年，新的开始！&quot;&gt;&lt;/a&gt;新的一年，新的开始！&lt;/h1&gt;&lt;p&gt;考研已经结束了5天了，这几天一直在休息，但是休息的时候竟然会有一种失落感，感
    
    </summary>
    
    
      <category term="计划" scheme="http://jellygogo.com/tags/%E8%AE%A1%E5%88%92/"/>
    
  </entry>
  
  <entry>
    <title>我决定了，要去考研了！</title>
    <link href="http://jellygogo.com/2016/04/27/every_end/"/>
    <id>http://jellygogo.com/2016/04/27/every_end/</id>
    <published>2016-04-26T19:47:26.000Z</published>
    <updated>2016-04-26T11:54:12.668Z</updated>
    
    <content type="html">&lt;p&gt;我知道自己如果现在不试试的话，以后一定会后悔，就像高三没有好好学习一样，后悔进入这个普通二本。&lt;br&gt;我不想哪天自己不顺利的时候，会说这样的话：&lt;br&gt;如果当年我努努力，要是考上研究生，或许生活就不会这样了~~&lt;/p&gt;
&lt;p&gt;我不想以后自己后悔，我也知道我为了什么而去考研，为了我心底，那尚存的一丝希望。&lt;/p&gt;
&lt;p&gt;Hope！&lt;br&gt;永远都是最致命，最美好的东西！&lt;br&gt;以前的low Blog是时候停止了，是时候真正为自己拼一把了！我绝不后悔！&lt;/p&gt;
&lt;p&gt;2016年4月26日 19:52分，离今年考研只有242天。我能创造奇迹，零基础考上自己想要的大学！&lt;br&gt;等我博客重开日，定是春花烂漫时！&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;我知道自己如果现在不试试的话，以后一定会后悔，就像高三没有好好学习一样，后悔进入这个普通二本。&lt;br&gt;我不想哪天自己不顺利的时候，会说这样的话：&lt;br&gt;如果当年我努努力，要是考上研究生，或许生活就不会这样了~~&lt;/p&gt;
&lt;p&gt;我不想以后自己后悔，我也知道我为了什么而去考研，
    
    </summary>
    
    
      <category term="考研，stop the world！" scheme="http://jellygogo.com/tags/%E8%80%83%E7%A0%94%EF%BC%8Cstop-the-world%EF%BC%81/"/>
    
  </entry>
  
  <entry>
    <title>java并发实战-多任务执行</title>
    <link href="http://jellygogo.com/2016/04/24/java%E5%B9%B6%E5%8F%91%E5%AE%9E%E6%88%98_%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C/"/>
    <id>http://jellygogo.com/2016/04/24/java并发实战_多任务执行/</id>
    <published>2016-04-23T17:06:26.000Z</published>
    <updated>2016-04-23T12:45:31.782Z</updated>
    
    <content type="html">&lt;h1 id=&quot;1-延时任务与周期任务&quot;&gt;&lt;a href=&quot;#1-延时任务与周期任务&quot; class=&quot;headerlink&quot; title=&quot;1.延时任务与周期任务&quot;&gt;&lt;/a&gt;1.延时任务与周期任务&lt;/h1&gt;&lt;p&gt;DelayQueue类的主要作用：是一个无界的BlockingQueue，用于放置实现了Delayed接口的对象，其中的对象只能在其到期时才能从队列中取走。这种队列是有序的，即队头对象的延迟到期时间最长&lt;br&gt;.DelayQueue队列中保存的是实现了Delayed接口的实现类，里面必须实现getDelay()和compareTo()方法，&lt;br&gt;前者用于返回与此对象相关的剩余延迟时间，以给定的时间单位表示&lt;br&gt;compareTo()方法用于进行队列内部的排序&lt;/p&gt;
&lt;p&gt;Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部 是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且 poll 将返回 null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于 0 的值时，将发生到期。即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。例如，size 方法同时返回到期和未到期元素的计数。此队列不允许使用 null 元素。 &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.basejava;

import java.util.concurrent.Callable;
import java.util.concurrent.DelayQueue;
import java.util.concurrent.Delayed;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

public class DelayQueueTest {

    public static void main(String[] args) {
        ExecutorService exec = Executors.newFixedThreadPool(10);
        DelayQueue&amp;lt;MyTask&amp;gt; queue = new DelayQueue&amp;lt;&amp;gt;();
        queue.add(new MyTask(1000, &amp;quot;Task1:1s:&amp;quot;));
        queue.add(new MyTask(9000, &amp;quot;Task2:9s:&amp;quot;));
        queue.add(new MyTask(3000, &amp;quot;Task3:3s:&amp;quot;));
        try {
            while (!queue.isEmpty()) {
                MyTask my =  queue.take();
                Future&amp;lt;String&amp;gt; future = exec.submit(my);
                System.out.println(&amp;quot;start thread&amp;quot;+my.getTaskName());
                System.out.println(future.get(4,TimeUnit.SECONDS ));
                System.out.println(&amp;quot;end thread&amp;quot;+my.getTaskName());
                if (queue.isEmpty()) {
                    System.out.println(&amp;quot;Empty!&amp;quot;);
                    break;
                }
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();

        }catch (TimeoutException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
            System.out.println(&amp;quot;超时!&amp;quot;);
        }
        System.out.println(&amp;quot;main Thread end&amp;quot;);
    }
}

class MyTask implements Delayed, Callable&amp;lt;String&amp;gt; {

    private long waitTime;
    private String taskName;
    private long endTime;
    public MyTask(long waitTime, String taskName) {
        this.waitTime = waitTime;
        this.taskName = taskName;
        this.endTime = System.currentTimeMillis() + waitTime;
    }
    public long getDelay(TimeUnit unit) {
        return this.endTime - System.currentTimeMillis();
    }
    public String call() throws Exception {
        // sleep waitTime 
        System.out.println(this.taskName + &amp;quot;sleep before&amp;quot;);
        //wait(100);
        Thread.sleep(this.waitTime);
        System.out.println(this.taskName + &amp;quot;sleep end&amp;quot;);
        return &amp;quot;SUCCESS&amp;quot;;
    }

    public int compareTo(Delayed o) {
        MyTask other = (MyTask) o;
        return endTime - other.endTime &amp;gt; 0 ? 1 : 0;
    }
    public String getTaskName() {
        return taskName;
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Demo 解释.&lt;br&gt;例子中使用了Future get(long timeout, TimeUnit unit) 这个方法,指如果在规定时间内不能get()到结果,就抛异常&lt;br&gt;一个很实用的例子:&lt;a href=&quot;http://blog.csdn.net/yjl49/article/details/7088121&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/yjl49/article/details/7088121&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;2-CompletionService-Executor与BlockingQueue&quot;&gt;&lt;a href=&quot;#2-CompletionService-Executor与BlockingQueue&quot; class=&quot;headerlink&quot; title=&quot;2.CompletionService:Executor与BlockingQueue&quot;&gt;&lt;/a&gt;2.CompletionService:Executor与BlockingQueue&lt;/h1&gt;&lt;p&gt;CompletionService是结合了BlockingQueue&lt;/p&gt;
&lt;p&gt;Demo2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.basejava;

import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorCompletionService;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class CompletionServiceTest {

    public static void main(String[] args) {
        ExecutorService exec = Executors.newFixedThreadPool(10);
        ExecutorCompletionService&amp;lt;String&amp;gt; cs = new ExecutorCompletionService&amp;lt;&amp;gt;(exec);
        cs.submit(new MyTask(1000, &amp;quot;Task1:1s:&amp;quot;));
        cs.submit(new MyTask(9000, &amp;quot;Task2:9s:&amp;quot;));
        cs.submit(new MyTask(3000, &amp;quot;Task3:3s:&amp;quot;));
        int size = 3;
        while (size--==0) {
            System.out.println(&amp;quot;start thread&amp;quot;);
            try {
                System.out.println(cs.take());
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(&amp;quot;end thread&amp;quot;);
        }
    }
}

class MyTask2 implements Callable&amp;lt;String&amp;gt; {

    private long waitTime;
    private String taskName;
    public MyTask2(long waitTime, String taskName) {
        this.waitTime = waitTime;
        this.taskName = taskName;
    }
    public String call() throws Exception {
        System.out.println(this.taskName + &amp;quot;sleep before&amp;quot;);
        Thread.sleep(this.waitTime);
        System.out.println(this.taskName + &amp;quot;sleep end&amp;quot;);
        return &amp;quot;SUCCESS&amp;quot;;
    }

    public String getTaskName() {
        return taskName;
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;此种方法不能设定获取时间,不如第一种灵活,但是更容易实现&lt;/p&gt;
&lt;h1 id=&quot;3-invokeAll&quot;&gt;&lt;a href=&quot;#3-invokeAll&quot; class=&quot;headerlink&quot; title=&quot;3.invokeAll&quot;&gt;&lt;/a&gt;3.invokeAll&lt;/h1&gt;&lt;p&gt;此种方法更容易实现,而且能解决第二种出现的弊端&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.basejava;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;

public class InvokaAll {

    public static void main(String[] args) {
        ExecutorService exec = Executors.newFixedThreadPool(10);
        List&amp;lt;MyTask3&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();
        list.add(new MyTask3(1000, &amp;quot;Task1:1s:&amp;quot;));
        list.add(new MyTask3(10000, &amp;quot;Task2:9s:&amp;quot;));
        list.add(new MyTask3(3000, &amp;quot;Task3:3s:&amp;quot;));
        try {
            List&amp;lt;Future&amp;lt;String&amp;gt;&amp;gt; futures = exec.invokeAll(list,4,TimeUnit.SECONDS );
            for(Future f:futures){
                try {
                    System.out.println(f.get());
                } catch (ExecutionException e) {
                    e.printStackTrace();
                }
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

class MyTask3 implements Callable&amp;lt;String&amp;gt; {

    private long waitTime;
    private String taskName;
    public MyTask3(long waitTime, String taskName) {
        this.waitTime = waitTime;
        this.taskName = taskName;
    }
    public String call() throws Exception {
        System.out.println(this.taskName + &amp;quot;sleep before&amp;quot;+&amp;quot;wait:&amp;quot;+waitTime);
        Thread.sleep(waitTime);
        System.out.println(this.taskName + &amp;quot;sleep end&amp;quot;);
        return &amp;quot;SUCCESS&amp;quot;;
    }

    public String getTaskName() {
        return taskName;
    }

}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-延时任务与周期任务&quot;&gt;&lt;a href=&quot;#1-延时任务与周期任务&quot; class=&quot;headerlink&quot; title=&quot;1.延时任务与周期任务&quot;&gt;&lt;/a&gt;1.延时任务与周期任务&lt;/h1&gt;&lt;p&gt;DelayQueue类的主要作用：是一个无界的BlockingQue
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="并发" scheme="http://jellygogo.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>java并发实战-任务终止</title>
    <link href="http://jellygogo.com/2016/04/24/jvm_%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6/"/>
    <id>http://jellygogo.com/2016/04/24/jvm_内存管理机制/</id>
    <published>2016-04-23T17:06:26.000Z</published>
    <updated>2016-04-23T14:26:21.995Z</updated>
    
    <content type="html">&lt;h1 id=&quot;内存区域划分&quot;&gt;&lt;a href=&quot;#内存区域划分&quot; class=&quot;headerlink&quot; title=&quot;内存区域划分&quot;&gt;&lt;/a&gt;内存区域划分&lt;/h1&gt;&lt;h2 id=&quot;程序计数区&quot;&gt;&lt;a href=&quot;#程序计数区&quot; class=&quot;headerlink&quot; title=&quot;程序计数区&quot;&gt;&lt;/a&gt;程序计数区&lt;/h2&gt;&lt;p&gt;唯一没有规定任务OutOfmemery异常的区域&lt;/p&gt;
&lt;h2 id=&quot;java虚拟机栈&quot;&gt;&lt;a href=&quot;#java虚拟机栈&quot; class=&quot;headerlink&quot; title=&quot;java虚拟机栈&quot;&gt;&lt;/a&gt;java虚拟机栈&lt;/h2&gt;&lt;p&gt;java虚拟机栈是线程私有区域,每个方法执行时都会在java虚拟机栈中创建一个栈帧(Stack Flame)用于存储局部变量表,方法出口,操作数栈等参数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.jvm;

//Exception in thread &amp;quot;main&amp;quot; java.lang.StackOverflowError
//通过无限调用递归方法,来模拟StackOverflowError
public class JvmOutOfMemoryTest {
/*
 * -Xss128k
 */

    public static void main(String[] args) {
        new JvmOutOfMemoryTest().stack(1);
    }

    public void stack(int i){
        stack(++i);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;本地方法区&quot;&gt;&lt;a href=&quot;#本地方法区&quot; class=&quot;headerlink&quot; title=&quot;本地方法区&quot;&gt;&lt;/a&gt;本地方法区&lt;/h2&gt;&lt;p&gt;与java虚拟机栈类似,区别是执行native方法&lt;/p&gt;
&lt;h2 id=&quot;java堆&quot;&gt;&lt;a href=&quot;#java堆&quot; class=&quot;headerlink&quot; title=&quot;java堆&quot;&gt;&lt;/a&gt;java堆&lt;/h2&gt;&lt;p&gt;所有线程共享,此内存区域唯一目的是存放方法实例.&lt;br&gt;java堆可以分为新生代和老年代&lt;/p&gt;
&lt;p&gt;java堆溢出异常测试&lt;br&gt;只需要不断创建对象就可以模拟出这种现象&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.jvm;

import java.util.ArrayList;
import java.util.List;

public class JvmOutOfMemoryTest {
/*
 * -Xms10m -Xmx10m
 */

    public static void main(String[] args) {
        List l = new ArrayList&amp;lt;&amp;gt;();
        while(true)
        l.add(new JvmOutOfMemoryTest());
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;方法区&quot;&gt;&lt;a href=&quot;#方法区&quot; class=&quot;headerlink&quot; title=&quot;方法区&quot;&gt;&lt;/a&gt;方法区&lt;/h2&gt;&lt;p&gt;所有线程共享的区域,存储已被类加载的类信息,常量,静态变量.&lt;/p&gt;
&lt;h2 id=&quot;运行时常量池&quot;&gt;&lt;a href=&quot;#运行时常量池&quot; class=&quot;headerlink&quot; title=&quot;运行时常量池&quot;&gt;&lt;/a&gt;运行时常量池&lt;/h2&gt;&lt;p&gt;属于方法区的一部分,储存编译器生成的字面量与符号引用&lt;/p&gt;
&lt;h1 id=&quot;垃圾收集器&quot;&gt;&lt;a href=&quot;#垃圾收集器&quot; class=&quot;headerlink&quot; title=&quot;垃圾收集器&quot;&gt;&lt;/a&gt;垃圾收集器&lt;/h1&gt;&lt;p&gt;常用的垃圾收集算法：&lt;br&gt;标记-清除算法：&lt;br&gt;复制算法：新生代算法&lt;br&gt;标记-整理：&lt;br&gt;分代收集算法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/img/2016/04/Collectors.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;内存分配策略&quot;&gt;&lt;a href=&quot;#内存分配策略&quot; class=&quot;headerlink&quot; title=&quot;内存分配策略&quot;&gt;&lt;/a&gt;内存分配策略&lt;/h1&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;内存区域划分&quot;&gt;&lt;a href=&quot;#内存区域划分&quot; class=&quot;headerlink&quot; title=&quot;内存区域划分&quot;&gt;&lt;/a&gt;内存区域划分&lt;/h1&gt;&lt;h2 id=&quot;程序计数区&quot;&gt;&lt;a href=&quot;#程序计数区&quot; class=&quot;headerlink&quot; title=
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="并发" scheme="http://jellygogo.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>java并发实战-任务终止</title>
    <link href="http://jellygogo.com/2016/04/24/java%E5%B9%B6%E5%8F%91%E5%AE%9E%E6%88%98_%E4%BB%BB%E5%8A%A1%E7%BB%88%E6%AD%A2/"/>
    <id>http://jellygogo.com/2016/04/24/java并发实战_任务终止/</id>
    <published>2016-04-23T17:06:26.000Z</published>
    <updated>2016-04-23T13:07:55.670Z</updated>
    
    <content type="html"></content>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="并发" scheme="http://jellygogo.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之线性规划与梯度下降</title>
    <link href="http://jellygogo.com/2016/04/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <id>http://jellygogo.com/2016/04/23/机器学习之线性规划与梯度下降/</id>
    <published>2016-04-22T17:06:26.000Z</published>
    <updated>2016-04-22T13:56:37.135Z</updated>
    
    <content type="html">&lt;p&gt;自己试着听网易公开课上面翻译出来的机器学习课程(斯坦福大学公开课),课程上面很多东西都听不懂,所以参考别人博客来促进理解&lt;/p&gt;
&lt;h1 id=&quot;1-线性回归（Linear-Regression）&quot;&gt;&lt;a href=&quot;#1-线性回归（Linear-Regression）&quot; class=&quot;headerlink&quot; title=&quot;1.线性回归（Linear Regression）&quot;&gt;&lt;/a&gt;1.线性回归（Linear Regression）&lt;/h1&gt;&lt;p&gt;参考博客:&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/jzlxiaohei/article/details/8973410&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/jzlxiaohei/article/details/8973410&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;自己试着听网易公开课上面翻译出来的机器学习课程(斯坦福大学公开课),课程上面很多东西都听不懂,所以参考别人博客来促进理解&lt;/p&gt;
&lt;h1 id=&quot;1-线性回归（Linear-Regression）&quot;&gt;&lt;a href=&quot;#1-线性回归（Linear-Regression）&quot; 
    
    </summary>
    
    
      <category term="机器学习" scheme="http://jellygogo.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性规划" scheme="http://jellygogo.com/tags/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/"/>
    
      <category term="梯度下降" scheme="http://jellygogo.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
  </entry>
  
  <entry>
    <title>hbase学习</title>
    <link href="http://jellygogo.com/2016/04/19/hbase_learn/"/>
    <id>http://jellygogo.com/2016/04/19/hbase_learn/</id>
    <published>2016-04-18T17:06:26.000Z</published>
    <updated>2016-04-20T04:49:38.492Z</updated>
    
    <content type="html">&lt;h2 id=&quot;hbase应用场景&quot;&gt;&lt;a href=&quot;#hbase应用场景&quot; class=&quot;headerlink&quot; title=&quot;hbase应用场景&quot;&gt;&lt;/a&gt;hbase应用场景&lt;/h2&gt;&lt;p&gt;1、爬虫网站URL的写入。&lt;br&gt;2、淘宝在2011年之前所有的后端持久化存储基本上都是在mysql上进行的(不排除少量oracle/bdb/tair/mongdb等)，mysql由于开源，并且生态系统良好，本身拥有分库分表等多种解决方案，因此很长一段时间内都满足淘宝大量业务的需求。&lt;br&gt;但是由于业务的多样化发展，有越来越多的业务系统的需求开始发生了变化。一般来说有以下几类变化：&lt;br&gt;数据量变得越来越多，事实上现在淘宝几乎任何一个与用户相关的在线业务的数据量都在亿级别，每日系统调用次数从亿到百亿都有，且历史数据不能轻易删除。这需要有一个海量分布式文件系统，能对TB级甚至PB级别的数据提供在线服务&lt;br&gt;数据量的增长很快且不一定能准确预计，大多数应用系统从上线起在一段时间内数据量都呈很快的上升趋势，因此从成本的角度考虑对系统水平扩展能力有比较强烈的需求，且不希望存在单点制约&lt;br&gt;只需要简单的kv读取，没有复杂的join等需求。但对系统的并发能力以及吞吐量、响应延时有非常高的需求，并且希望系统能够保持强一致性&lt;br&gt;通常系统的写入非常频繁，尤其是大量系统依赖于实时的日志分析&lt;br&gt;希望能够快速读取批量数据 &lt;/p&gt;
&lt;p&gt;参考博客:&lt;a href=&quot;http://www.cnblogs.com/zhwl/p/3654346.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/zhwl/p/3654346.html&lt;/a&gt;&lt;br&gt;hbase应用场景重点参考博客:&lt;a href=&quot;http://blog.sina.com.cn/s/blog_ae33b83901016azb.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.sina.com.cn/s/blog_ae33b83901016azb.html&lt;/a&gt;  &lt;/p&gt;
&lt;h2 id=&quot;学习进度一-2016-04-20&quot;&gt;&lt;a href=&quot;#学习进度一-2016-04-20&quot; class=&quot;headerlink&quot; title=&quot;学习进度一:2016-04-20&quot;&gt;&lt;/a&gt;学习进度一:2016-04-20&lt;/h2&gt;&lt;p&gt;hbase的学习参考书籍为:Hbase权威指南&lt;br&gt;目前学习进度为hbase简单使用与java API:基础知识部分(此书前三章),后面的部分等到需要使用时再具体学习.&lt;/p&gt;
&lt;p&gt;Demo1 hbase数据插入&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;hbase应用场景&quot;&gt;&lt;a href=&quot;#hbase应用场景&quot; class=&quot;headerlink&quot; title=&quot;hbase应用场景&quot;&gt;&lt;/a&gt;hbase应用场景&lt;/h2&gt;&lt;p&gt;1、爬虫网站URL的写入。&lt;br&gt;2、淘宝在2011年之前所有的后端持久化存储基本上
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="hbase" scheme="http://jellygogo.com/tags/hbase/"/>
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>常用数据查找(搜索)算法总结</title>
    <link href="http://jellygogo.com/2016/04/19/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>http://jellygogo.com/2016/04/19/常用数据搜索算法总结/</id>
    <published>2016-04-18T17:06:26.000Z</published>
    <updated>2016-04-20T04:05:10.258Z</updated>
    
    <content type="html">&lt;p&gt;散列表&lt;br&gt;静态散列与动态散列 &lt;/p&gt;
&lt;p&gt;散列是一个非常有用的、非常基础的数据结构，在数据的查找方面尤其重要，应用的非常广泛。然而，任何事物都有两面性，散列也存在缺点，即数据的局部集中性会使散列的性能急剧下降，且越集中，性能越低。&lt;br&gt;数据集中，即搜索键在通过hash函数运算后，得到同一个结果，指向同一个桶，这时便产生了数据冲突。&lt;br&gt;通常解决数据冲突的方法有：拉链法(open hashing)和开地址法(open addressing)。拉链法我们用的非常多，即存在冲突时，简单的将元素链在当前桶的最后元素的尾部。开放地址法有线性探测再散列、二次线性探测再散列、再hash等方法。&lt;br&gt;在HashMap中采用拉链法,在每个桶后面使用一个链表储存冲突的数据&lt;br&gt;以上介绍的解决冲突的方法，存在一个前提：hash表(又称散列表)的桶的数目保持不变，即hash表在初始化时指定一个数，以后在使用的过程中，只允许在其中添加、删除、查找元素等操作，而不允许改变桶的数目。&lt;br&gt;在实际的应用中，当hash表较小，元素个数不多时，采用以上方法完全可以应付。但是，一旦元素较多，或数据存在一定的偏斜性(数据集中分布在某个桶上)时，以上方法不足以解决这一问题。我们引入一种称之为动态散列的方法：在hash表的元素增长的同时，动态的调整hash桶的数目&lt;br&gt;挖坑:动态哈希表~~&lt;br&gt;散列表:&lt;a href=&quot;http://blog.sina.com.cn/s/blog_5e4516af01019frj.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.sina.com.cn/s/blog_5e4516af01019frj.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;布隆过滤器&lt;/p&gt;
&lt;p&gt;布隆过滤器原理:&lt;a href=&quot;http://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html&lt;/a&gt;&lt;br&gt;布隆过滤器java代码:&lt;a href=&quot;http://blog.csdn.net/hwwzyh/article/details/38944513&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/hwwzyh/article/details/38944513&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;B树即二叉搜索树：&lt;br&gt;1.所有非叶子结点至多拥有两个儿子（Left和Right）；&lt;br&gt;2.所有结点存储一个关键字；&lt;br&gt;3.非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树；&lt;br&gt;B-树是一种多路搜索树（并不是二叉的）&lt;br&gt;B+树B-树的一种变种,在B-树基础上为所有叶子结点增加一个链指针&lt;br&gt;B*树,B+树的一种变种,为非叶节点的中间节点增加一个链指针&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/oldhorse/archive/2009/11/16/1604009.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/oldhorse/archive/2009/11/16/1604009.html&lt;/a&gt;&lt;br&gt;java二叉树实现:&lt;a href=&quot;http://blog.csdn.net/cdnight/article/details/11266969&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/cdnight/article/details/11266969&lt;/a&gt;&lt;br&gt;AVL树&lt;br&gt;红黑树&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;散列表&lt;br&gt;静态散列与动态散列 &lt;/p&gt;
&lt;p&gt;散列是一个非常有用的、非常基础的数据结构，在数据的查找方面尤其重要，应用的非常广泛。然而，任何事物都有两面性，散列也存在缺点，即数据的局部集中性会使散列的性能急剧下降，且越集中，性能越低。&lt;br&gt;数据集中，即搜索键在通过ha
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="算法" scheme="http://jellygogo.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="搜索" scheme="http://jellygogo.com/tags/%E6%90%9C%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>pig学习</title>
    <link href="http://jellygogo.com/2016/04/19/pig_learn/"/>
    <id>http://jellygogo.com/2016/04/19/pig_learn/</id>
    <published>2016-04-18T17:06:26.000Z</published>
    <updated>2016-04-18T05:28:52.324Z</updated>
    
    <content type="html">&lt;p&gt;grunt&amp;gt; cat hdfs://h1:9000/user/grip/toolSample.txt&lt;br&gt;2016 99&lt;br&gt;2015 6&lt;br&gt;2016 999&lt;br&gt;2015 5&lt;/p&gt;
&lt;p&gt;grunt&amp;gt; a = load ‘hdfs://h1:9000/user/grip/toolSample.txt’ using PigStorage(‘ ‘) as (year,max) ;&lt;/p&gt;
&lt;p&gt;grunt&amp;gt; a = load ‘hdfs://h1:9000/user/grip/toolSample.txt’ as (year,max) using PigStorage(‘ ‘);&lt;br&gt;2016-04-17 22:26:19,929 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: &lt;line 65=&quot;&quot; 16,=&quot;&quot; column=&quot;&quot;&gt;&lt;/line&gt;  mismatched input ‘using’ expecting SEMI_COLON&lt;br&gt;Details at logfile: /home/grip/hadoop-2.5.2/pig_1460955057730.log&lt;br&gt;grunt&amp;gt; a = load ‘hdfs://h1:9000/user/grip/toolSample.txt’ using PigStorage(‘ ‘) as (year,max) ;&lt;br&gt;2016-04-17 22:26:57,098 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS&lt;br&gt;grunt&amp;gt; dump a;&lt;br&gt;2016-04-17 22:27:05,950 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: UNKNOWN&lt;br&gt;2016-04-17 22:27:05,951 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter], RULES_DISABLED=[FilterLogicExpressionSimplifier]}&lt;br&gt;2016-04-17 22:27:06,028 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized&lt;br&gt;2016-04-17 22:27:06,047 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1&lt;br&gt;2016-04-17 22:27:06,047 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1&lt;br&gt;2016-04-17 22:27:06,140 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task ‘attempt&lt;strong&gt;0001_m_000001_1’ to hdfs://h1:9000/tmp/temp342437142/tmp293532517/_temporary/0/task&lt;/strong&gt;0001_m_000001&lt;br&gt;2016-04-17 22:27:06,180 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized&lt;br&gt;2016-04-17 22:27:06,185 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1&lt;br&gt;2016-04-17 22:27:06,185 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1&lt;br&gt;(2016,99)&lt;br&gt;(2015,6)&lt;br&gt;(2016,999)&lt;br&gt;(2015,5)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;grunt&amp;gt; cat hdfs://h1:9000/user/grip/toolSample.txt&lt;br&gt;2016 99&lt;br&gt;2015 6&lt;br&gt;2016 999&lt;br&gt;2015 5&lt;/p&gt;
&lt;p&gt;grunt&amp;gt; a = load ‘hdfs://h1:900
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="算法" scheme="http://jellygogo.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="排序" scheme="http://jellygogo.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>Hive学习</title>
    <link href="http://jellygogo.com/2016/04/13/hiveLearn/"/>
    <id>http://jellygogo.com/2016/04/13/hiveLearn/</id>
    <published>2016-04-13T12:50:55.000Z</published>
    <updated>2016-04-18T07:26:45.866Z</updated>
    
    <content type="html">&lt;p&gt;hive数据仓库,基于mapreduce计算模型，结构化数据的离线分析。&lt;br&gt;hive 应用场景:对搜索日志数据进行统计分析。&lt;br&gt;集团搜索刚上线不久，日志量并不大 。这些日志分布在 5 台前端机，按小时保存，并以小时为周期定时将上一小时产生的数据同步到日志分析机，统计数据要求按小时更新。这些统计项，&lt;br&gt;包括关键词搜索量 pv ，类别访问量，每秒访问量 tps 等等。&lt;br&gt;基于 Hive ，我们将这些数据按天为单位建表，每天一个表，后台脚本根据时间戳将每小时同步过来的 5 台前端机的日志数据合并成一个日志文件，导入 Hive 系统，每小时同步的日志数据&lt;br&gt;被追加到当天数据表中，导入完成后，当天各项统计项将被重新计算并输出统计结果。&lt;br&gt;以上需求若直接基于 hadoop 开发，需要自行管理数据，针对多个统计需求开发不同的 map/reduce 运算任务，对合并、排序等多项操作进行定制，并检测任务运行状态，工作量并不小。但&lt;br&gt;使用 Hive ，从导入到分析、排序、去重、结果输出，这些操作都可以运用 hql 语句来解决，一条语句经过处理被解析成几个任务来运行，即使是关键词访问量增量这种需要同时访问多天数&lt;br&gt;据的较为复杂的需求也能通过表关联这样的语句自动完 成，节省了大量工作量。&lt;/p&gt;
&lt;p&gt;参考博客:&lt;a href=&quot;http://www.cnblogs.com/zhwl/p/3654346.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/zhwl/p/3654346.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;hive基础操作&quot;&gt;&lt;a href=&quot;#hive基础操作&quot; class=&quot;headerlink&quot; title=&quot;hive基础操作&quot;&gt;&lt;/a&gt;hive基础操作&lt;/h2&gt;&lt;p&gt;hive导入数据方法:&lt;a href=&quot;http://blog.csdn.net/lifuxiangcaohui/article/details/40588929&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/lifuxiangcaohui/article/details/40588929&lt;/a&gt;&lt;br&gt;    hive&amp;gt; dfs -cat hdfs://h1:9000/user/grip/word.txt&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hive&amp;gt; create database test;
OK
Time taken: 8.764 seconds

hive&amp;gt; use test;
OK
Time taken: 1.91 seconds

hive&amp;gt;
hive&amp;gt; set hivevar:v=name;
hive&amp;gt; create table tabletest(id int,${hivevar:v} string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &amp;apos;\t&amp;apos; ;
OK
Time taken: 15.879 seconds

hive&amp;gt; describe tabletest;
OK
id                      int                                    
name                    string                                 
Time taken: 4.328 seconds, Fetched: 2 row(s)

[grip@h1 tData]$ cat hivedata.txt
101     jelly
102     gogo

hive (test)&amp;gt; load data local inpath &amp;quot;/home/grip/tData/hivedata.txt&amp;quot; into table tabletest;
Loading data to table test.tabletest
OK
Time taken: 2.252 seconds
hive (test)&amp;gt; select * from tabletest;
OK
101     jelly
102     gogo
Time taken: 0.569 seconds, Fetched: 2 row(s)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;wordcount-hive-Demo&quot;&gt;&lt;a href=&quot;#wordcount-hive-Demo&quot; class=&quot;headerlink&quot; title=&quot;wordcount hive Demo&quot;&gt;&lt;/a&gt;wordcount hive Demo&lt;/h2&gt;&lt;p&gt;create database wordcount;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;hive数据仓库,基于mapreduce计算模型，结构化数据的离线分析。&lt;br&gt;hive 应用场景:对搜索日志数据进行统计分析。&lt;br&gt;集团搜索刚上线不久，日志量并不大 。这些日志分布在 5 台前端机，按小时保存，并以小时为周期定时将上一小时产生的数据同步到日志分析机，统计
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="hive" scheme="http://jellygogo.com/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>常用排序算法总结</title>
    <link href="http://jellygogo.com/2016/04/08/%E5%B8%B8%E7%94%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>http://jellygogo.com/2016/04/08/常用排序算法总结/</id>
    <published>2016-04-07T17:06:26.000Z</published>
    <updated>2016-04-18T04:22:12.804Z</updated>
    
    <content type="html">&lt;p&gt;常用的排序算法我知道的有9种&lt;br&gt;在whuslei博客中发现这么一张图片能概括这9种算法.&lt;br&gt;&lt;img src=&quot;/img/2016/04/001.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些算法主要比较的是时间复杂性,稳定性,和实现的复杂度&lt;br&gt;稳定性，就是有两个相同的元素，排序先后的相对位置是否变化，主要用在排序时有多个排序规则的情况下。在插入排序中，K1是已排序部分中的元素，当K2和K1比较时，直接插到K1的后面(没有必要插到K1的前面，这样做还需要移动！！)&lt;/p&gt;
&lt;h1 id=&quot;直接插入排序法&quot;&gt;&lt;a href=&quot;#直接插入排序法&quot; class=&quot;headerlink&quot; title=&quot;直接插入排序法&quot;&gt;&lt;/a&gt;直接插入排序法&lt;/h1&gt;&lt;p&gt;陆续将一个记录插入到前面已经排好序的有序表中, 从而得到一个新的,记录数增1的有序表&lt;br&gt;算法时间复杂度。&lt;br&gt;最好的情况下：正序有序(从小到大)，这样只需要比较n次，不需要移动。因此时间复杂度为O(n)&lt;br&gt;最坏的情况下：逆序有序,这样每一个元素就需要比较n次，共有n个元素，因此实际复杂度为O(n­2)&lt;br&gt;平均情况下：O(n­2)&lt;br&gt;可以在原来存储的数组上面直接排序&lt;/p&gt;
&lt;p&gt;插入排序是稳定的。&lt;/p&gt;
&lt;p&gt;时间复杂度也为O(n^2), 比冒泡法和选择排序的性能要更好一些&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class InsertionSort {

    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        if(in.size()==1||in.size()==0)
            return in;
        for(int i=1;i&amp;lt;in.size();i++){
            if(in.get(i)&amp;lt;in.get(0)){
                move(in,in.get(i),0,i);
            }
            if(in.get(i)&amp;lt;in.get(i-1)){
                for(int j=0;j&amp;lt;i;j++){
                    if(in.get(j)&amp;lt;=in.get(i)&amp;amp;&amp;amp;in.get(j+1)&amp;gt;=in.get(i)){
                        move(in,in.get(i),j+1,i);
                        break;
                    }
                }
            }
        }
        return in;
    }
    public static void move(LinkedList&amp;lt;Integer&amp;gt; in,int value,int start,int end){
        int tmp = value;
        for(int i = start;i&amp;lt;end;i++){
            int ttmp = in.get(i);
            in.set(i, tmp);
            tmp = ttmp;
        }
        in.set(end, tmp);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;直接选择排序&quot;&gt;&lt;a href=&quot;#直接选择排序&quot; class=&quot;headerlink&quot; title=&quot;直接选择排序&quot;&gt;&lt;/a&gt;直接选择排序&lt;/h1&gt;&lt;p&gt;通过n-i次关键字之间的比较,从n-i+1 个记录中选择关键字最小的记录,并和第i(1&amp;lt;=i&amp;lt;=n)个记录交换之&lt;br&gt;尽管与冒泡排序同为O(n^2),但简单选择排序的性能要略优于冒泡排序&lt;br&gt;最好情况下：交换0次，但是每次都要找到最小的元素，因此大约必须遍历N&lt;em&gt;N次，因此为O(N&lt;/em&gt;N)。减少了交换次数！&lt;br&gt;最坏情况下，平均情况下：O(N*N)&lt;br&gt;由于每次都是选取未排序序列A中的最小元素x与A中的第一个元素交换，因此跨距离了，很可能破坏了元素间的相对位置，因此选择排序是不稳定的！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;
import java.util.LinkedList;
public class SelectSort {
    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        int min ;
        int postion;
        for(int i=0;i&amp;lt;in.size();i++){
            min=in.get(i);
            postion = i;
            for(int j=i+1;j&amp;lt;in.size();j++){
                if(min&amp;gt;in.get(j)){
                    min = in.get(j);
                    postion = j;
                }
            }
            in.set(postion,in.get(i));
            in.set(i, min);
        }
        return in;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;冒泡算法&quot;&gt;&lt;a href=&quot;#冒泡算法&quot; class=&quot;headerlink&quot; title=&quot;冒泡算法&quot;&gt;&lt;/a&gt;冒泡算法&lt;/h1&gt;&lt;p&gt;通过无序区中相邻记录关键字间的比较和位置的交换,使关键字最小的记录如气泡一般逐渐往上“漂浮”直至“水面”。&lt;br&gt;时间复杂度&lt;br&gt;最好情况下：正序有序，则只需要比较n次。故，为O(n)&lt;br&gt;最坏情况下:  逆序有序，则需要比较(n-1)+(n-2)+……+1，故，为O(N*N)&lt;br&gt;排序过程中只交换相邻两个元素的位置。因此，当两个数相等时，是没必要交换两个数的位置的。所以，它们的相对位置并没有改变，冒泡排序算法是稳定的！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;
import java.util.LinkedList;
public class BubbleSort {
    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        for(int i=0;i&amp;lt;in.size();i++){
            for(int j=0;j&amp;lt;in.size()-1;j++){
                if(in.get(j)&amp;gt;=in.get(j+1)){
                    int tmp = in.get(j);
                    in.set(j, in.get(j+1));
                    in.set(j+1, tmp) ;
                }
            }
        }
        return in;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;改进思路1：设置标志位，明显如果有一趟没有发生交换（flag = false)，说明排序已经完成&lt;br&gt;改进思路2：记录一轮下来标记的最后位置，下次从头部遍历到这个位置就Ok&lt;br&gt;实现代码:&lt;/p&gt;
&lt;h1 id=&quot;希尔排序&quot;&gt;&lt;a href=&quot;#希尔排序&quot; class=&quot;headerlink&quot; title=&quot;希尔排序&quot;&gt;&lt;/a&gt;希尔排序&lt;/h1&gt;&lt;p&gt;希尔排序的实质就是分组插入排序，该方法又称缩小增量排序&lt;br&gt;参考博客 &lt;a href=&quot;http://blog.csdn.net/morewindows/article/details/6668714&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/morewindows/article/details/6668714&lt;/a&gt;&lt;br&gt;    package com.jellygogo.sort;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.util.LinkedList;

public class ShellSort {

    public static LinkedList&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in){
        int len=in.size()/2;
        while(len&amp;gt;=1){
            for(int k=0;k&amp;lt;len;k++){
                for(int i=len;i&amp;lt;in.size();i+=len){
                    if(in.get(i)&amp;lt;in.get(0)){
                        InsertionSort. move(in,in.get(i),0,i,len);
                    }
                    if(in.get(i)&amp;lt;in.get(i-1)){
                        for(int j=0;j&amp;lt;i;j++){
                            if(in.get(j)&amp;lt;=in.get(i)&amp;amp;&amp;amp;in.get(j+1)&amp;gt;=in.get(i)){
                                InsertionSort.move(in,in.get(i),j+1,i,len);
                                break;
                            }
                        }
                    }
                }
            }
            if(len==1)
                break;
            len=len/2;
        }
        return in;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;快速排序&quot;&gt;&lt;a href=&quot;#快速排序&quot; class=&quot;headerlink&quot; title=&quot;快速排序&quot;&gt;&lt;/a&gt;快速排序&lt;/h1&gt;&lt;p&gt;它是由冒泡排序改进而来的。在待排序的n个记录中任取一个记录(通常取第一个记录),把该记录放入适当位置后,数据序列被此记录划分成两部分。所有关键字比该记录关键字小的记录放置在前一部分,所有比它大的记录放置在后一部分,并把该记录排在这两部分的中间(称为该记录归位),这个过程称作一趟快速排序&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;

import java.util.LinkedList;
import java.util.List;

public class QuickSort {

    public static List&amp;lt;Integer&amp;gt; sort(LinkedList&amp;lt;Integer&amp;gt; in,int start ,int end) {
        // [5, 1, 3, 2, 6]
        if(start==end)
            return in;
        int mid = in.get(start);
        int left=start;
        int right=end-1;
        for(int i = start+1;i&amp;lt;end&amp;amp;&amp;amp;right&amp;gt;=left;i++){
            if(in.get(i)&amp;lt;=mid){
                int tmp = in.get(i);
                in.set(i,in.get(left));
                in.set(left,tmp);
                left++;
            }else{
                int tmp = in.get(i);
                in.set(i,in.get(right));
                in.set(right,tmp);
                right--;
            }
        }
        sort(in,start,left);
        sort(in,left+1,end);
        return in;
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;堆排序&quot;&gt;&lt;a href=&quot;#堆排序&quot; class=&quot;headerlink&quot; title=&quot;堆排序&quot;&gt;&lt;/a&gt;堆排序&lt;/h1&gt;&lt;p&gt;分治算法:分治算法由两部分组成&lt;br&gt;分:递归解决较小问题(部分除外)&lt;br&gt;治:从子问题的解,构建原问题的解&lt;br&gt;&lt;a href=&quot;http://dsbryz.iteye.com/blog/1182056&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://dsbryz.iteye.com/blog/1182056&lt;/a&gt;&lt;br&gt;堆排序的思想是利用数据结构–堆。具体的实现细节： &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构建一个最大堆。对于给定的包含有n个元素的数组A[n]，构建一个最大堆（最大堆的特性是，某个节点的值最多和其父节点的值一样大。这样，堆中的最大元素存放在根节点中；并且，在以某一个节点为根的子树中，各节点的值都不大于该子树根节点的值）。从最底下的子树开始，调整这个堆结构，使其满足最大堆的特性。当为了满足最大堆特性时，堆结构发生变化，此时递归调整对应的子树。 &lt;/li&gt;
&lt;li&gt;堆排序算法，每次取出该最大堆的根节点（因为根节点是最大的），同时，取最末尾的叶子节点来作为根节点，从此根节点开始调整堆，使其满足最大堆的特性。 &lt;/li&gt;
&lt;li&gt;&lt;p&gt;重复上一步操作，直到堆的大小由n个元素降到2个。 &lt;/p&gt;
&lt;p&gt; package com.jellygogo.sort;&lt;/p&gt;
&lt;p&gt; import java.util.Arrays;&lt;br&gt; import java.util.LinkedList;&lt;br&gt; import java.util.List;&lt;/p&gt;
&lt;p&gt; public class HeapSort {&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public static List&amp;lt;Integer&amp;gt; sort(List&amp;lt;Integer&amp;gt; in){
    int[] inArray = initHeap(in);
    List&amp;lt;Integer&amp;gt; out = new LinkedList&amp;lt;&amp;gt;();
    for(int i=in.size()-1;i&amp;gt;0;i--){
        int tmp = inArray[i];
        inArray[i] = inArray[0];
        inArray[0] = tmp;
        if(i&amp;gt;=1)
            maxHeap(inArray,i,0);
    }
    for(int i=0;i&amp;lt;in.size();i++){
        out.add(inArray[i]);
    }
    return out;
}

private static void maxHeap(int[] inArray,int size,int index) {
    int left = (index+1)*2-1;
    int right = (index+1)*2;
    int maxIndex = index;
    boolean changed = false;
    if(left&amp;lt;size&amp;amp;&amp;amp;inArray[left]&amp;gt;inArray[maxIndex]){
        maxIndex = left;
    }
    if(right&amp;lt;size&amp;amp;&amp;amp;inArray[right]&amp;gt;inArray[maxIndex]){
        maxIndex = right;
    }
    if(left&amp;lt;size&amp;amp;&amp;amp;maxIndex==left){
        int tmp = inArray[left];
        inArray[left] = inArray[index];
        inArray[index] = tmp;
        changed = true;
    }
    if(right&amp;lt;size&amp;amp;&amp;amp;maxIndex==right){
        int tmp = inArray[right];
        inArray[right] = inArray[index];
        inArray[index] = tmp;
        changed = true;
    }
    if(changed){
        maxHeap(inArray,size,maxIndex);
    }

}

public static int[] initHeap(List&amp;lt;Integer&amp;gt; in){
    int[] out = new int[in.size()];
    for(int i=0;i&amp;lt;in.size();i++){
        out[i]=in.get(i);
    }
    for(int i=in.size()/2;i&amp;gt;=0;i--){
        maxHeap(out,in.size(),i);
    }
    return out;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; }&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;归并排序&quot;&gt;&lt;a href=&quot;#归并排序&quot; class=&quot;headerlink&quot; title=&quot;归并排序&quot;&gt;&lt;/a&gt;归并排序&lt;/h1&gt;&lt;p&gt;假设初始序列含有n个记录,则可以看成n个有序的子序列,每个子序列的长度为1,然后两两归并,得到(不小于n/2的最小整数)个长度为2或1的有序子序列,再两两归并,…如此重复,直至得到一个长度为n的有序序列为止,这种排序方法称为2路归并排序。&lt;br&gt;时间复杂度为O(nlogn),空间复杂度为O(n+logn),如果非递归实现归并,则避免了递归时深度为logn的栈空间 空间复杂度为O(n)&lt;br&gt;空间复杂度较大&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.sort;

import java.util.LinkedList;
import java.util.List;
import java.util.List;

public class MergeSort {

    public static List&amp;lt;Integer&amp;gt; sort(List&amp;lt;Integer&amp;gt; in){
        if(in.size()==1||in.size()==0){
            return in;
        }else{
            List&amp;lt;Integer&amp;gt; i1= sort(in.subList(0, in.size()/2));
            List&amp;lt;Integer&amp;gt; i2= sort(in.subList(in.size()/2, in.size()));
            List&amp;lt;Integer&amp;gt; returnList = new LinkedList&amp;lt;&amp;gt;();
            int index1=0;
            int index2=0;
            boolean oneNull =false,index1Boolean = true,index2Boolean = true;
            while(index1!=i1.size()||index2!=i2.size()){
                if(index1==i1.size()&amp;amp;&amp;amp;index1Boolean){
                    returnList.add(i2.get(index2));
                    index2++;
                    oneNull=true;
                    index2Boolean = false;
                }
                if(index2==i2.size()&amp;amp;&amp;amp;index2Boolean){
                    returnList.add(i1.get(index1));
                    index1++;
                    oneNull=true;
                    index1Boolean = false;
                }
                if(!oneNull){
                    if(i2.get(index2)&amp;gt;i1.get(index1)){
                        returnList.add(i1.get(index1));
                        index1++;
                    }else{
                        returnList.add(i2.get(index2));
                        index2++;
                    }
                }
            }
            return returnList;

        }

    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;计数排序&quot;&gt;&lt;a href=&quot;#计数排序&quot; class=&quot;headerlink&quot; title=&quot;计数排序&quot;&gt;&lt;/a&gt;计数排序&lt;/h1&gt;&lt;p&gt;计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。&lt;/p&gt;
&lt;h1 id=&quot;桶排序&quot;&gt;&lt;a href=&quot;#桶排序&quot; class=&quot;headerlink&quot; title=&quot;桶排序&quot;&gt;&lt;/a&gt;桶排序&lt;/h1&gt;&lt;h1 id=&quot;基数排序&quot;&gt;&lt;a href=&quot;#基数排序&quot; class=&quot;headerlink&quot; title=&quot;基数排序&quot;&gt;&lt;/a&gt;基数排序&lt;/h1&gt;&lt;p&gt;基数排序（英语：Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数&lt;/p&gt;
&lt;p&gt;参考博客&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/xiazdong/article/details/8462393&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/xiazdong/article/details/8462393&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://www.open-open.com/lib/view/open1420372620468.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.open-open.com/lib/view/open1420372620468.html&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;常用的排序算法我知道的有9种&lt;br&gt;在whuslei博客中发现这么一张图片能概括这9种算法.&lt;br&gt;&lt;img src=&quot;/img/2016/04/001.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些算法主要比较的是时间复杂性,稳定性,和实现的复杂度&lt;br&gt;稳定性，就是有两个
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="算法" scheme="http://jellygogo.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="排序" scheme="http://jellygogo.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>MRunit combiner partitioner</title>
    <link href="http://jellygogo.com/2016/04/07/MRunit_combiner_partitioner/"/>
    <id>http://jellygogo.com/2016/04/07/MRunit_combiner_partitioner/</id>
    <published>2016-04-07T15:50:55.000Z</published>
    <updated>2016-04-09T20:41:22.000Z</updated>
    
    <content type="html">&lt;p&gt;在maven中使用MRunit测试框架搭建了个mapreduce程序,里面使用了combiner和partitioner&lt;br&gt;并使用了 org.apache.hadoop.util.Tool&lt;br&gt;实现了找出对应年份的最大值,&lt;br&gt;        //数据样例&lt;br&gt;        1995 65&lt;br&gt;        1965 21&lt;br&gt;        1995 62&lt;br&gt;为了验证使用combiner和不适用combiner的不同,所以写了个生成数据的小程序&lt;br&gt;    package com.jellygogo.basejava;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
public class MaxNumOfYearTest implements Runnable{
    public static final int ONEFILEMAXLINE = 100000;
    public static final int STARTFILE = 0 ;
    public static final int ENDFILE = 1;
    public int num;
    public MaxNumOfYearTest(int num) {
        super();
        this.num = num;
    }
    public static void main(String[] args) {
        for(int i=STARTFILE;i&amp;lt;ENDFILE;i++){
            Thread thread = new Thread(new MaxNumOfYearTest(i));
            thread.start();
        }
    }
    public void run() {
        // TODO Auto-generated method stub
        File file = new File(&amp;quot;C:\\Users\\Administrator\\Desktop\\笔记\\testdata\\test&amp;quot;+num+&amp;quot;.txt&amp;quot;);
        FileWriter b =null;
        try {
            b= new FileWriter(file);
            for(int i = 0;i&amp;lt;ONEFILEMAXLINE;i++){
                int randomYear = 1900 + (int)(Math.random()*100);
                int randomNum = (int)(Math.random()*100);
                b.write(randomYear+&amp;quot; &amp;quot;+randomNum+&amp;quot;\n&amp;quot;);
            }
        } catch (IOException e) {
            e.printStackTrace();
            System.out.println(e);
        }finally{
            try {
                b.close();
            } catch (IOException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;下面是对应的源码&lt;/p&gt;
&lt;p&gt;pom.xml&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    &amp;lt;project xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot;  
     xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&amp;quot;&amp;gt;  
    &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;  
    &amp;lt;groupId&amp;gt;com.jellygogo.ToolTest&amp;lt;/groupId&amp;gt;  
    &amp;lt;artifactId&amp;gt;ToolTest&amp;lt;/artifactId&amp;gt;  
    &amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt;    
    &amp;lt;name&amp;gt;ToolTest&amp;lt;/name&amp;gt;  
    &amp;lt;url&amp;gt;http://maven.apache.org&amp;lt;/url&amp;gt;  
    &amp;lt;properties&amp;gt;  
    &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;  
    &amp;lt;/properties&amp;gt;
    &amp;lt;dependencies&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;hadoop-common&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;2.5.2&amp;lt;/version&amp;gt;  
        &amp;lt;/dependency&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;hadoop-hdfs&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;2.5.2&amp;lt;/version&amp;gt;  
        &amp;lt;/dependency&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;org.apache.hadoop&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;hadoop-client&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;2.5.2&amp;lt;/version&amp;gt;  
        &amp;lt;/dependency&amp;gt;  
        &amp;lt;dependency&amp;gt;  
            &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;  
            &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;  
            &amp;lt;version&amp;gt;4.10&amp;lt;/version&amp;gt;  
            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;  
        &amp;lt;/dependency&amp;gt;  

        &amp;lt;dependency&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.mrunit&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;mrunit&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;0.9.0-incubating&amp;lt;/version&amp;gt;
        &amp;lt;classifier&amp;gt;hadoop2&amp;lt;/classifier&amp;gt; 
        &amp;lt;/dependency&amp;gt;

    &amp;lt;/dependencies&amp;gt;  
    &amp;lt;version&amp;gt;3.0&amp;lt;/version&amp;gt;
    &amp;lt;build&amp;gt;
        &amp;lt;plugins&amp;gt;
            &amp;lt;plugin&amp;gt;
                &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;maven-compiler-plugin&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;3.3&amp;lt;/version&amp;gt;
                &amp;lt;configuration&amp;gt;
                    &amp;lt;source&amp;gt;1.7&amp;lt;/source&amp;gt;
                    &amp;lt;target&amp;gt;1.7&amp;lt;/target&amp;gt;
                &amp;lt;/configuration&amp;gt;
            &amp;lt;/plugin&amp;gt;
        &amp;lt;/plugins&amp;gt;
    &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ToolTest.java&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.hadoop;    
import java.io.IOException;    
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Partitioner;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;    
public class ToolTest extends Configured implements Tool {        
    public int run(String[] arg0) throws Exception {
        Job job = Job.getInstance(getConf());
        job.setJarByClass(ToolTest.class);
        job.setInputFormatClass(TextInputFormat.class);
        job.setOutputFormatClass(TextOutputFormat.class);    
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);
        FileInputFormat.setInputPaths(job, new Path(arg0[0]));
        FileOutputFormat.setOutputPath(job, new Path(arg0[1]));
        job.setMapperClass(MapperTest.class);
        job.setReducerClass(ReduceTest.class);
        job.setCombinerClass(CTest.class);
        job.setNumReduceTasks(5);
        job.setPartitionerClass(MyPartitioner.class);
        if (job.waitForCompletion(true))
            return 0;
        else
            return 1;
    }
    public static void main(String[] args) {
        Configuration configuration = new Configuration();
        try {
            ToolRunner.run(new ToolTest(), args);
        } catch (Exception e) {
            e.printStackTrace();
            System.out.println(e);
        }
    }
}
class ReduceTest extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
    protected void reduce(Text arg0, Iterable&amp;lt;Text&amp;gt; arg1, Reducer&amp;lt;Text, Text, Text, Text&amp;gt;.Context arg2)
            throws IOException, InterruptedException {
        int max = 0;
        for (Text t : arg1) {
            String intString = t.toString();
            int thisvalue = Integer.valueOf(intString);
            if (thisvalue &amp;gt; max)
                max = thisvalue;
        }
        arg2.write(arg0, new Text(max + &amp;quot;&amp;quot;));
    }
}
class MapperTest extends Mapper&amp;lt;LongWritable, Text, Text, Text&amp;gt; {
    protected void map(LongWritable key, Text value, Mapper&amp;lt;LongWritable, Text, Text, Text&amp;gt;.Context context)
            throws IOException, InterruptedException {
        String v = value.toString();
        if (v != null &amp;amp;&amp;amp; v.length() &amp;gt; 5) {
            context.write(new Text(value.toString().substring(0, 4)),
                    new Text(value.toString().substring(5, v.length())));
        }
    }
}
class CTest extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
    protected void reduce(Text arg0, Iterable&amp;lt;Text&amp;gt; arg1, Reducer&amp;lt;Text, Text, Text, Text&amp;gt;.Context arg2)
            throws IOException, InterruptedException {
        int max = 0;
        for (Text t : arg1) {
            String intString = t.toString();
            int thisvalue = Integer.valueOf(intString);
            if (thisvalue &amp;gt; max)
                max = thisvalue;
        }
        arg2.write(arg0, new Text(max + &amp;quot;&amp;quot;));
    }
}

class MyPartitioner extends Partitioner{
    public int getPartition(Object key, Object value, int numPartitions) {
        // TODO Auto-generated method stub
        int result = 0;
        if (key.toString().startsWith(&amp;quot;1&amp;quot;)) {  
            result = 0 % numPartitions;  
        } else if (key.toString().startsWith(&amp;quot;2&amp;quot;)) {  
            result = 1 % numPartitions;  
        }else {
            result = 3 % numPartitions; 
        }
        return result;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MR2Test.java&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package com.jellygogo.hadoop;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mrunit.mapreduce.MapDriver;
import org.apache.hadoop.mrunit.mapreduce.MapReduceDriver;
import org.apache.hadoop.mrunit.mapreduce.ReduceDriver;
import org.apache.hadoop.mrunit.types.Pair;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Test;
import junit.framework.TestCase;
public class MR2Test extends TestCase{

    private Mapper&amp;lt;LongWritable, Text, Text, Text&amp;gt; mapper;
    private Reducer reducer;
    private MapDriver&amp;lt;LongWritable, Text, Text, Text&amp;gt; mapDirver;
    private ReduceDriver reduceDirver;
    private MapReduceDriver rdDirver; 
    @Test
    public void testMap(){
        mapper = new MapperTest();
        reducer = new ReduceTest();
        mapDirver = new MapDriver&amp;lt;&amp;gt;(mapper);
        reduceDirver = new ReduceDriver&amp;lt;&amp;gt;(reducer);
        rdDirver = new MapReduceDriver&amp;lt;&amp;gt;(mapper, reducer);
        mapDirver.withInput(new LongWritable(1L), new Text(&amp;quot;1995 56&amp;quot;));
        mapDirver.withOutput( new Text(&amp;quot;1995&amp;quot;), new Text(&amp;quot;56&amp;quot;));
        mapDirver.runTest();
    }
    @Test
    public void testReduceOneValue(){
        mapper = new MapperTest();
        reducer = new ReduceTest();
        mapDirver = new MapDriver&amp;lt;&amp;gt;(mapper);
        reduceDirver = new ReduceDriver&amp;lt;&amp;gt;(reducer);
        rdDirver = new MapReduceDriver&amp;lt;&amp;gt;(mapper, reducer);
        List&amp;lt;Text&amp;gt; list = new ArrayList&amp;lt;Text&amp;gt;();
        list.add(new Text(&amp;quot;1&amp;quot;));
        list.add(new Text(&amp;quot;5&amp;quot;));
        list.add(new Text(&amp;quot;4&amp;quot;));
        reduceDirver.withInput(new Text(&amp;quot;1995&amp;quot;), list);
        reduceDirver.withOutput( new Text(&amp;quot;1995&amp;quot;), new Text(&amp;quot;5&amp;quot;));
//        try {
//            List&amp;lt;Pair&amp;gt; l = reduceDirver.run();
//            System.out.println(&amp;quot;testReduceOneValue=====&amp;quot;);
//            for(Pair o:l)
//                System.out.println(o);
//        } catch (IOException e) {
//            // TODO Auto-generated catch block
//            e.printStackTrace();
//        }
    }
    @Test
    public void testMapReduce(){
        mapper = new MapperTest();
        reducer = new ReduceTest();
        mapDirver = new MapDriver&amp;lt;&amp;gt;(mapper);
        reduceDirver = new ReduceDriver&amp;lt;&amp;gt;(reducer);
        rdDirver = new MapReduceDriver&amp;lt;&amp;gt;(mapper, reducer);
        rdDirver.withInput(new LongWritable(1L), new Text(&amp;quot;1995 5&amp;quot;));
        rdDirver.withInput(new LongWritable(2L), new Text(&amp;quot;1995 6&amp;quot;));
        rdDirver.withInput(new LongWritable(3L), new Text(&amp;quot;1996 10&amp;quot;));
        rdDirver.withInput(new LongWritable(5L), new Text(&amp;quot;1996 1&amp;quot;));
        rdDirver.withInput(new LongWritable(6L), new Text(&amp;quot;1994 100&amp;quot;));
        rdDirver.withInput(new LongWritable(7L), new Text(&amp;quot;1996 2&amp;quot;));
        rdDirver.withOutput( new Text(&amp;quot;1994&amp;quot;), new Text(&amp;quot;100&amp;quot;));
        rdDirver.withOutput( new Text(&amp;quot;1995&amp;quot;), new Text(&amp;quot;6&amp;quot;));
        rdDirver.withOutput( new Text(&amp;quot;1996&amp;quot;), new Text(&amp;quot;10&amp;quot;));
//        withoutput应该按照key排序输入
//        (1994, 100)
//        (1995, 6)
//        (1996, 10)
        rdDirver.runTest();
    }

}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;第一次测试时,没有加job.setCombinerClass(CTest.class) 这一句,没有使用combiner&lt;br&gt;得出结果如下:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Map-Reduce Framework&lt;br&gt;               Map input records=100000&lt;br&gt;               Map output records=100000&lt;br&gt;               Map output bytes=789913&lt;br&gt;               Map output materialized bytes=989925&lt;br&gt;               Input split bytes=103&lt;br&gt;               Combine input records=0&lt;br&gt;               Combine output records=0&lt;br&gt;               Reduce input groups=100&lt;br&gt;               Reduce shuffle bytes=989925&lt;br&gt;               Reduce input records=100000&lt;br&gt;               Reduce output records=100&lt;br&gt;               Spilled Records=200000&lt;br&gt;               Shuffled Maps =2&lt;br&gt;               Failed Shuffles=0&lt;br&gt;               Merged Map outputs=2&lt;br&gt;               GC time elapsed (ms)=487&lt;br&gt;               CPU time spent (ms)=6770&lt;br&gt;               Physical memory (bytes) snapshot=383012864&lt;br&gt;               Virtual memory (bytes) snapshot=6227005440&lt;br&gt;               Total committed heap usage (bytes)=157134848&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用combiner之后&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Map-Reduce Framework&lt;br&gt;             Map input records=100000&lt;br&gt;             Map output records=100000&lt;br&gt;             Map output bytes=789913&lt;br&gt;             Map output materialized bytes=1012&lt;br&gt;             Input split bytes=103&lt;br&gt;             Combine input records=100000&lt;br&gt;             Combine output records=100&lt;br&gt;             Reduce input groups=100&lt;br&gt;             Reduce shuffle bytes=1012&lt;br&gt;             Reduce input records=100&lt;br&gt;             Reduce output records=100&lt;br&gt;             Spilled Records=200&lt;br&gt;             Shuffled Maps =2&lt;br&gt;             Failed Shuffles=0&lt;br&gt;             Merged Map outputs=2&lt;br&gt;             GC time elapsed (ms)=444&lt;br&gt;             CPU time spent (ms)=4860&lt;br&gt;             Physical memory (bytes) snapshot=392232960&lt;br&gt;             Virtual memory (bytes) snapshot=6227005440&lt;br&gt;             Total committed heap usage (bytes)=156102656&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以对比出&lt;br&gt;                Combine input records=0&lt;br&gt;                Combine output records=0&lt;br&gt;与&lt;br&gt;                Combine input records=100000&lt;br&gt;                Combine output records=100&lt;/p&gt;
&lt;p&gt;Combiner相关链接 &lt;a href=&quot;http://www.tuicool.com/articles/qAzUjav&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.tuicool.com/articles/qAzUjav&lt;/a&gt;&lt;br&gt;partitioner相关链接 &lt;a href=&quot;http://www.cnblogs.com/xwdreamer/archive/2011/10/27/2296943.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/xwdreamer/archive/2011/10/27/2296943.html&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;二次排序&quot;&gt;&lt;a href=&quot;#二次排序&quot; class=&quot;headerlink&quot; title=&quot;二次排序&quot;&gt;&lt;/a&gt;二次排序&lt;/h1&gt;&lt;p&gt;此次是把前面的例子修改下,使其满足使用二次排序&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.educity.cn/linux/1603517.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.educity.cn/linux/1603517.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/img/2016/04/002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;前面的例子只有年和最大数,现在的例子要求先按照年份降序再按月份升序,&lt;br&gt;修改数据的生成&lt;br&gt;                int randomYear = 1900 + (int)(Math.random()&lt;em&gt;100);&lt;br&gt;                int randomMonth = (int)(Math.random()&lt;/em&gt;12);&lt;br&gt;                int randomNum = (int)(Math.random()*100)+randomMonth;&lt;br&gt;                b.write(randomYear+” “+randomMonth+” “+randomNum+”\n”);&lt;/p&gt;
&lt;p&gt;自己新建key 在map output和reduce input中使用,compareTo方式实现了先按照年份降序再按月份升序,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    class YearAndMonthWritable implements WritableComparable&amp;lt;YearAndMonthWritable&amp;gt; {

    public Text year = new Text();
    public Text month = new Text();

    public YearAndMonthWritable() {
    }

    public YearAndMonthWritable(Text year, Text month) {
        this.year = year;
        this.month = month;
    }

    @Override
    public void write(DataOutput out) throws IOException {
        // TODO Auto-generated method stub
        this.year.write(out);
        this.month.write(out);
    }

    @Override
    public void readFields(DataInput in) throws IOException {
        // TODO Auto-generated method stub
        this.year.readFields(in);
        this.month.readFields(in);
    }

    @Override
    public int compareTo(YearAndMonthWritable other) {
        // TODO Auto-generated method stub
        int yearC = this.year.toString().compareTo(other.year.toString());
        int monthC = Math.abs(Integer.valueOf(this.month.toString()).compareTo(Integer.valueOf(other.month.toString())));
        if (yearC &amp;gt;= 0) {
            return -monthC;
        } else {
            return monthC;
        }
    }

    @Override
    public String toString() {
        // TODO Auto-generated method stub
        return this.year.toString() + &amp;quot; &amp;quot; + this.month.toString();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;使用默认的Partitioner,得出结果如下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;File System Counters
        FILE: Number of bytes read=4272
        FILE: Number of bytes written=1276859
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=101887
        HDFS: Number of bytes written=3532
        HDFS: Number of read operations=39
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=24
Job Counters
        Launched map tasks=1
        Launched reduce tasks=12
        Data-local map tasks=1
        Total time spent by all maps in occupied slots (ms)=8384
        Total time spent by all reduces in occupied slots (ms)=1075954
        Total time spent by all map tasks (ms)=8384
        Total time spent by all reduce tasks (ms)=1075954
        Total vcore-seconds taken by all map tasks=8384
        Total vcore-seconds taken by all reduce tasks=1075954
        Total megabyte-seconds taken by all map tasks=8585216
        Total megabyte-seconds taken by all reduce tasks=1101776896
Map-Reduce Framework
        Map input records=10000
        Map output records=10000
        Map output bytes=101781
        Map output materialized bytes=4272
        Input split bytes=106
        Combine input records=10000
        Combine output records=334
        Reduce input groups=334
        Reduce shuffle bytes=4272
        Reduce input records=334
        Reduce output records=334
        Spilled Records=668
        Shuffled Maps =12
        Failed Shuffles=0
        Merged Map outputs=12
        GC time elapsed (ms)=5909
        CPU time spent (ms)=30300
        Physical memory (bytes) snapshot=1146945536
        Virtual memory (bytes) snapshot=27008589824
        Total committed heap usage (bytes)=326991872
Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
File Input Format Counters
        Bytes Read=101781
File Output Format Counters
        Bytes Written=3532
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;p&gt;在maven中使用MRunit测试框架搭建了个mapreduce程序,里面使用了combiner和partitioner&lt;br&gt;并使用了 org.apache.hadoop.util.Tool&lt;br&gt;实现了找出对应年份的最大值,&lt;br&gt;        //数据样例&lt;br&gt; 
    
    </summary>
    
    
      <category term="hadoop" scheme="http://jellygogo.com/tags/hadoop/"/>
    
      <category term="mapreduce" scheme="http://jellygogo.com/tags/mapreduce/"/>
    
      <category term="combiner" scheme="http://jellygogo.com/tags/combiner/"/>
    
      <category term="partitioner" scheme="http://jellygogo.com/tags/partitioner/"/>
    
      <category term="MRunit" scheme="http://jellygogo.com/tags/MRunit/"/>
    
      <category term="Tool" scheme="http://jellygogo.com/tags/Tool/"/>
    
  </entry>
  
  <entry>
    <title>常用java类源码初窥</title>
    <link href="http://jellygogo.com/2016/03/31/%E5%B8%B8%E7%94%A8java%E7%B1%BB%E6%BA%90%E7%A0%81%E5%88%9D%E7%AA%A5/"/>
    <id>http://jellygogo.com/2016/03/31/常用java类源码初窥/</id>
    <published>2016-03-31T13:54:00.000Z</published>
    <updated>2016-04-03T09:03:20.356Z</updated>
    
    <content type="html">&lt;p&gt;包括内容:java常用类源码,java源码中常用数据结构&lt;br&gt;此篇博客用来记录我对java基础在源码上面的认识,不定时填坑&lt;/p&gt;
&lt;h1 id=&quot;1-List系列&quot;&gt;&lt;a href=&quot;#1-List系列&quot; class=&quot;headerlink&quot; title=&quot;1.List系列&quot;&gt;&lt;/a&gt;1.List系列&lt;/h1&gt;&lt;p&gt;List系列常用的实现类是LinkedList和ArrayList&lt;/p&gt;
&lt;h2 id=&quot;ArrayList&quot;&gt;&lt;a href=&quot;#ArrayList&quot; class=&quot;headerlink&quot; title=&quot;ArrayList&quot;&gt;&lt;/a&gt;ArrayList&lt;/h2&gt;&lt;p&gt;内部使用一个数组来实现List&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;private transient Object[] elementData;&lt;/p&gt;
&lt;p&gt;Java的serialization提供了一种持久化对象实例的机制。当持久化对象时，可能有一个特殊的对象数据成员，我们不想&lt;br&gt;用serialization机制来保存它。为了在一个特定对象的一个域上关闭serialization，可以在这个域前加上关键字transient。&lt;br&gt;transient是Java语言的关键字，用来表示一个域不是该对象串行化的一部分。当一个对象被串行化的时候，transient型变量的值不包括在串行化的表示中，然而非transient型的变量是被包括进去的&lt;br&gt;转自:&lt;a href=&quot;http://www.blogjava.net/fhtdy2004/archive/2009/06/20/286112.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.blogjava.net/fhtdy2004/archive/2009/06/20/286112.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ArrayList中插入一个元素需要将此元素后面的都往后移动,&lt;br&gt;&lt;blockquote&gt;&lt;p&gt;public void add(int index, E element) {&lt;br&gt;        rangeCheckForAdd(index);&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    ensureCapacityInternal(size + 1);  // Increments modCount!!
    System.arraycopy(elementData, index, elementData, index + 1,
                     size - index);
    elementData[index] = element;
    size++;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;关于System.arraycopy()  &lt;a href=&quot;http://xuyuanshuaaa.iteye.com/blog/1046621&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://xuyuanshuaaa.iteye.com/blog/1046621&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ArrayList中删除元素时,并不会将内部的elementData变小&lt;/p&gt;
&lt;/blockquote&gt;&lt;/p&gt;
&lt;h2 id=&quot;LinkedList&quot;&gt;&lt;a href=&quot;#LinkedList&quot; class=&quot;headerlink&quot; title=&quot;LinkedList&quot;&gt;&lt;/a&gt;LinkedList&lt;/h2&gt;&lt;p&gt;内部使用内部对象存储,&lt;br&gt;public class LinkedList&lt;e&gt;&lt;br&gt;    extends AbstractSequentialList&lt;e&gt;&lt;br&gt;    implements List&lt;e&gt;, Deque&lt;e&gt;, Cloneable, java.io.Serializable&lt;/e&gt;&lt;/e&gt;&lt;/e&gt;&lt;/e&gt;&lt;/p&gt;
&lt;p&gt;如果有大量随机访问对象的需求,就使用ArrayList,如果有大量插入删除使用LinkedList&lt;/p&gt;
&lt;h1 id=&quot;2-Map系列&quot;&gt;&lt;a href=&quot;#2-Map系列&quot; class=&quot;headerlink&quot; title=&quot;2.Map系列&quot;&gt;&lt;/a&gt;2.Map系列&lt;/h1&gt;&lt;p&gt;几个常用Map实现类:HashMap TreeMap LinkedHashMap ConcurrentHashMap&lt;/p&gt;
&lt;h2 id=&quot;HashMap&quot;&gt;&lt;a href=&quot;#HashMap&quot; class=&quot;headerlink&quot; title=&quot;HashMap&quot;&gt;&lt;/a&gt;HashMap&lt;/h2&gt;&lt;p&gt; 使用数组和链表实现,在HashMap中使用一个数组,内部的hash()计算出hash值一样的数放入同一个Entry中,Entry中使用链表存储&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; transient Entry&amp;lt;K,V&amp;gt;[] table = (Entry&amp;lt;K,V&amp;gt;[]) EMPTY_TABLE;
 static class Entry&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final K key;
    V value;
    Entry&amp;lt;K,V&amp;gt; next;
    int hash;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;HashMap其实就是一个Entry数组，Entry对象中包含了键和值，其中next也是一个Entry对象，它就是用来处理hash冲突的，形成一个链表。&lt;/p&gt;
&lt;p&gt;关于HashMap很贴切的解释 &lt;a href=&quot;http://www.cnblogs.com/ITtangtang/p/3948406.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/ITtangtang/p/3948406.html&lt;/a&gt; 包含loadFactor加载因子的内容&lt;/p&gt;
&lt;h2 id=&quot;TreeMap&quot;&gt;&lt;a href=&quot;#TreeMap&quot; class=&quot;headerlink&quot; title=&quot;TreeMap&quot;&gt;&lt;/a&gt;TreeMap&lt;/h2&gt;&lt;p&gt;Tree内部使用二叉树(红黑树)来存储key-value&lt;br&gt;(先开个坑,有空再填)&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/chenssy/article/details/26668941&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/chenssy/article/details/26668941&lt;/a&gt; &lt;/p&gt;
&lt;h2 id=&quot;LinkedHashMap&quot;&gt;&lt;a href=&quot;#LinkedHashMap&quot; class=&quot;headerlink&quot; title=&quot;LinkedHashMap&quot;&gt;&lt;/a&gt;LinkedHashMap&lt;/h2&gt;&lt;p&gt;LinkedHashMap继承自HashMap,在HashMap基础上面增加了TreeMap的顺序输出功能,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Entry中,增加了next
static class Entry&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final K key;
    V value;
    Entry&amp;lt;K,V&amp;gt; next;
    int hash;
}
public V put(K key, V value) {
    if (table == EMPTY_TABLE) {
        inflateTable(threshold);
    }
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key);
    int i = indexFor(hash, table.length);
    for (Entry&amp;lt;K,V&amp;gt; e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);//&amp;lt;----------
            return oldValue;
        }
    }

    modCount++;
    addEntry(hash, key, value, i);
    return null;
}
//LinkedHashMap中重载了recordAccess这个方法.
//recordAccess中标记了
    void recordAccess(HashMap&amp;lt;K,V&amp;gt; m) {
        LinkedHashMap&amp;lt;K,V&amp;gt; lm = (LinkedHashMap&amp;lt;K,V&amp;gt;)m;
        if (lm.accessOrder) {
            lm.modCount++;
            remove();
            addBefore(lm.header);
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;ConcurrentHashMap&quot;&gt;&lt;a href=&quot;#ConcurrentHashMap&quot; class=&quot;headerlink&quot; title=&quot;ConcurrentHashMap&quot;&gt;&lt;/a&gt;ConcurrentHashMap&lt;/h2&gt;&lt;p&gt;这是一个线程安全的HashMap,在Collection中也提供了线程安全类&lt;br&gt;    public static &lt;k,v&gt; Map&lt;k,v&gt; synchronizedMap(Map&lt;k,v&gt; m) {&lt;br&gt;        return new SynchronizedMap&lt;k,v&gt;(m);&lt;br&gt;     }&lt;br&gt;SynchronizedMap中所有的方法都加上了synchronized,保证了方法的同步,但在使用中仍然会有安全问题&lt;br&gt;ConcurrentHashMap中使用了,锁分段技术具体细节刨个坑,以后再填&lt;/k,v&gt;&lt;/k,v&gt;&lt;/k,v&gt;&lt;/k,v&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/madun/article/details/6326337&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/madun/article/details/6326337&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;关于HashMap和hashTable&quot;&gt;&lt;a href=&quot;#关于HashMap和hashTable&quot; class=&quot;headerlink&quot; title=&quot;关于HashMap和hashTable &quot;&gt;&lt;/a&gt;关于HashMap和hashTable &lt;/h2&gt;&lt;p&gt;HashMap中key和value都可以是null,而在hashtable中key和value都不能是null&lt;br&gt;hashtable是线程安全的,但是效率低下,全局使用了一把锁,当其他线程访问时,容易堵塞&lt;/p&gt;
&lt;h2 id=&quot;WeakHashMap&quot;&gt;&lt;a href=&quot;#WeakHashMap&quot; class=&quot;headerlink&quot; title=&quot;WeakHashMap&quot;&gt;&lt;/a&gt;WeakHashMap&lt;/h2&gt;&lt;p&gt;Map总结(HashMap, Hashtable, TreeMap, WeakHashMap等使用场景)  &lt;a href=&quot;http://www.chawenti.com/articles/20110.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.chawenti.com/articles/20110.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2016-4-3 参考书籍:java程序员成功面试秘籍(书名感觉挺low的,但是里面还是有一定东西的)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;包括内容:java常用类源码,java源码中常用数据结构&lt;br&gt;此篇博客用来记录我对java基础在源码上面的认识,不定时填坑&lt;/p&gt;
&lt;h1 id=&quot;1-List系列&quot;&gt;&lt;a href=&quot;#1-List系列&quot; class=&quot;headerlink&quot; title=&quot;1.List
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="源码" scheme="http://jellygogo.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="数据结构" scheme="http://jellygogo.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop气象数据下载小程序</title>
    <link href="http://jellygogo.com/2016/03/17/Hadoop%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD%E5%B0%8F%E7%A8%8B%E5%BA%8F/"/>
    <id>http://jellygogo.com/2016/03/17/Hadoop气象数据下载小程序/</id>
    <published>2016-03-17T14:18:26.000Z</published>
    <updated>2016-03-17T14:41:22.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;a href=&quot;#Hadoop气象数据下载小程序&quot; class=&quot;headerlink&quot; title=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;/a&gt;Hadoop气象数据下载小程序&lt;/h1&gt;&lt;h2 id=&quot;写小程序的原因&quot;&gt;&lt;a href=&quot;#写小程序的原因&quot; class=&quot;headerlink&quot; title=&quot;写小程序的原因&quot;&gt;&lt;/a&gt;写小程序的原因&lt;/h2&gt;&lt;p&gt;在学习Hadoop学习指南时,遇到了&lt;a href=&quot;ftp://www1.ncdc.noaa.gov/pub/data/noaa&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ftp&lt;/a&gt;下载链接不能下载的原因,于是去找&lt;a href=&quot;http://www1.ncdc.noaa.gov/pub/data/noaa&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http下载&lt;/a&gt;的链接,但是使用迅雷批量下载时遇到了文件限制,在每个年份的文件夹下大约有1W-3W个文件,但是迅雷批量下载一次只能下载1000个连接,遂自己写了短代码,来自己下载&lt;/p&gt;
&lt;p&gt;顺便这段时间再看代码整洁之道,我试下尽我所能写出书什么样的代码&lt;/p&gt;
&lt;h2 id=&quot;java代码&quot;&gt;&lt;a href=&quot;#java代码&quot; class=&quot;headerlink&quot; title=&quot;java代码&quot;&gt;&lt;/a&gt;java代码&lt;/h2&gt;&lt;p&gt;现在还才刚开始学习Python,过段时间会来再用Python代码实现下这个功能&lt;br&gt;重新需要输入一个在1970-2016之间的数字来下载某一年的数据,因为我不需要太多的数据,所以这样设计的.&lt;/p&gt;
&lt;p&gt;关于线程池的选择&lt;br&gt;&lt;a href=&quot;http://coach.iteye.com/blog/855850&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;线程池的使用&lt;/a&gt; &lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	public class NcdcFileDownload &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	private final static String  HTTPURL = &amp;quot;http://www1.ncdc.noaa.gov/pub/data/noaa/&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	private final static String ROOTFOLDER = &amp;quot;D://filedowntest//&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	 public static void main(String[] args) throws Exception  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	    &amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 	int year = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 	Scanner scanner = new Scanner(System.in);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		 	year = scanner.nextInt();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        // 创建HttpClient实例     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpClient httpclient = new DefaultHttpClient(); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        // 创建Get方法实例     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpGet httpgets = new HttpGet(HTTPURL+year+&amp;quot;/&amp;quot;);    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpResponse response = httpclient.execute(httpgets);    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HttpEntity entity = response.getEntity(); &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        // 存储这一年每个气象数据的url&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        HashSet&amp;lt;String&amp;gt; httpDownLoadURL = new HashSet&amp;lt;String&amp;gt;();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        if (entity != null) &amp;#123;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            InputStream instreams = entity.getContent();    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            //获取这一页的HTML代码,从中提取带有 -XXXX.gz的url&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            String responseHTMLInformation = convertStreamToString(instreams);  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            String[] allHttpDownLoadURL = responseHTMLInformation.split(&amp;quot;-&amp;quot;+year+&amp;quot;.gz&amp;quot;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            HttpDownload httpDownload = null;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            //去除错误与重复的url,并放在httpDownLoadURL中&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            for(String tmp:allHttpDownLoadURL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	if(tmp!=null&amp;amp;&amp;amp;tmp.length()&amp;gt;13)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            	tmp = tmp.substring(tmp.length()-12)+&amp;quot;-2015.gz&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            	if(tmp!=null&amp;amp;&amp;amp;tmp.length()==20)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            		httpDownLoadURL.add(tmp);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		            	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            int downLoadTaskNum = 0;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            ThreadPoolExecutor executor = new ThreadPoolExecutor(20, 30, 10,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            		TimeUnit.SECONDS, new ArrayBlockingQueue&amp;lt;Runnable&amp;gt;(10000),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            		new ThreadPoolExecutor.DiscardOldestPolicy());&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            for(String tmp:httpDownLoadURL)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	downLoadTaskNum++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	File createFolder = new File(ROOTFOLDER+year);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	createFolder.mkdir();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload = new HttpDownload();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload.setUrl(HTTPURL+year+&amp;quot;/&amp;quot;+tmp);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload.setPath(ROOTFOLDER+year+&amp;quot;//&amp;quot;+tmp);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	httpDownload.setI(downLoadTaskNum);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            	executor.execute(httpDownload);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	           httpgets.abort();    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		public static String convertStreamToString(InputStream is) &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        BufferedReader reader = new BufferedReader(new InputStreamReader(is));      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        StringBuilder sb = new StringBuilder();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        String line = null;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        try &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            while ((line = reader.readLine()) != null) &amp;#123;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	                sb.append(line + &amp;quot;\n&amp;quot;);      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125; catch (IOException e) &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            e.printStackTrace();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125; finally &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            try &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	                is.close();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125; catch (IOException e) &amp;#123;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	               e.printStackTrace();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	            &amp;#125;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        &amp;#125;      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	        return sb.toString();      &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	    &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;下载文件的类&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class HttpDownload implements Runnable{
public  final int cache = 10 * 1024;
public  final boolean isWindows;
public  final String splash;
public  final String root;
private String url;
private String path;
private int i;

 public int getI() {
    return i;
}
public void setI(int i) {
    this.i = i;
}

{
    if (System.getProperty(&amp;quot;os.name&amp;quot;) != null &amp;amp;&amp;amp; System.getProperty(&amp;quot;os.name&amp;quot;).toLowerCase().contains(&amp;quot;windows&amp;quot;)) {
        isWindows = true;
        splash = &amp;quot;\\&amp;quot;;
        root=&amp;quot;D:&amp;quot;;
    } else {
        isWindows = false;
        splash = &amp;quot;/&amp;quot;;
        root=&amp;quot;/search&amp;quot;;
    }
}


public  String download() {
    try {
        HttpClient client = new DefaultHttpClient();
        HttpGet httpget = new HttpGet(url);
        HttpResponse response = client.execute(httpget);

        HttpEntity entity = response.getEntity();
        InputStream is = entity.getContent();
        if (path == null)
            path = getFilePath(response);
        File file = new File(path);
        file.getParentFile().mkdirs();
        FileOutputStream fileout = new FileOutputStream(file);
        /**
         * 根据实际运行效果 设置缓冲区大小
         */
        byte[] buffer=new byte[cache];
        int ch = 0;
        while ((ch = is.read(buffer)) != -1) {
            fileout.write(buffer,0,ch);
        }
        is.close();
        fileout.flush();
        fileout.close();

    } catch (Exception e) {
        e.printStackTrace();
    }
    return null;
}

public  String getFilePath(HttpResponse response) {
    String filepath = root + splash;
    String filename = getFileName(response);

    if (filename != null) {
        filepath += filename;
    } else {
        filepath += getRandomFileName();
    }
    return filepath;
}

public  String getFileName(HttpResponse response) {
    Header contentHeader = response.getFirstHeader(&amp;quot;Content-Disposition&amp;quot;);
    String filename = null;
    if (contentHeader != null) {
        HeaderElement[] values = contentHeader.getElements();
        if (values.length == 1) {
            NameValuePair param = values[0].getParameterByName(&amp;quot;filename&amp;quot;);
            if (param != null) {
                try {
                    filename = param.getValue();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
    }
    return filename;
}
/**
 * 获取随机文件名
 * @return
 */
public  String getRandomFileName() {
    return String.valueOf(System.currentTimeMillis());
}
public  void outHeaders(HttpResponse response) {
    Header[] headers = response.getAllHeaders();
    for (int i = 0; i &amp;lt; headers.length; i++) {
        System.out.println(headers[i]);
    }
}

@Override
public void run() {
    // TODO Auto-generated method stub
    try{
    download();
        System.out.println(&amp;quot;task&amp;quot;+this.i+&amp;quot;--&amp;quot;+this.url+&amp;quot;------100% SUCCESS&amp;quot;);
    }catch(Exception e){
        System.out.println(&amp;quot;task&amp;quot;+this.i+&amp;quot;--&amp;quot;+this.url+&amp;quot;------0% FAIL !!!!!!!!!!!!!!!!!!!!!!&amp;quot;);
    }

}

public String getUrl() {
    return url;
}

public void setUrl(String url) {
    this.url = url;
}

public String getPath() {
    return path;
}

public void setPath(String path) {
    this.path = path;
}

public int getCache() {
    return cache;
}

public boolean isWindows() {
    return isWindows;
}

public String getSplash() {
    return splash;
}

public String getRoot() {
    return root;
}


}
&lt;/code&gt;&lt;/pre&gt;</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;a href=&quot;#Hadoop气象数据下载小程序&quot; class=&quot;headerlink&quot; title=&quot;Hadoop气象数据下载小程序&quot;&gt;&lt;/a&gt;Hadoop气象数据下载小程序&lt;/h1&gt;&lt;h2 id=&quot;写小程序的原因&quot;&gt;&lt;a h
    
    </summary>
    
    
      <category term="java" scheme="http://jellygogo.com/tags/java/"/>
    
      <category term="Hadoop" scheme="http://jellygogo.com/tags/Hadoop/"/>
    
      <category term="大数据" scheme="http://jellygogo.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>转移到github的第一篇博客</title>
    <link href="http://jellygogo.com/2016/03/16/%E8%BD%AC%E7%A7%BB%E5%88%B0github%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <id>http://jellygogo.com/2016/03/16/转移到github的第一篇博客/</id>
    <published>2016-03-16T09:56:10.000Z</published>
    <updated>2016-03-16T14:41:22.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h1&gt;&lt;h2 id=&quot;以前的故事&quot;&gt;&lt;a href=&quot;#以前的故事&quot; class=&quot;headerlink&quot; title=&quot;以前的故事&quot;&gt;&lt;/a&gt;以前的故事&lt;/h2&gt;&lt;p&gt;以前也在csdn写过博客,都是一些学习笔记之类的东西,断断续续的写了一段时间,这期间伴随我学习spring源码,高性能MySQL等一些东西,期间慢慢接触到github这个东东,虽然感觉很神奇但是苦于英文疲软,一直没敢开这个坑.现在慢慢的接触开源项目越来越多,不得不接触她((✿◡‿◡))了,这次使用github也算是对github的入门了.&lt;/p&gt;
&lt;h2 id=&quot;现在的打算&quot;&gt;&lt;a href=&quot;#现在的打算&quot; class=&quot;headerlink&quot; title=&quot;现在的打算&quot;&gt;&lt;/a&gt;现在的打算&lt;/h2&gt;&lt;p&gt;发现自己不完善的地方很多,自我感觉很差,下面列举下目前感觉到的缺点&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;基础知识不好,特别是算法基础(全心专注外功,没有好好修炼过内功)&lt;br&gt;英文能力差,阅读github的 &lt;a href=&quot;https://guides.github.com/activities/hello-world/&quot; title=&quot;hello world链接&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;helloworld&lt;/a&gt;的文档都不流畅,上面写10分钟读完的,我tm快读了20分钟&lt;br&gt;懒,间歇性懒癌&lt;br&gt;选择性遗忘症&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;以后的打算&quot;&gt;&lt;a href=&quot;#以后的打算&quot; class=&quot;headerlink&quot; title=&quot;以后的打算&quot;&gt;&lt;/a&gt;以后的打算&lt;/h2&gt;&lt;p&gt;现在是大三了,还有一年半毕业,是时候要为自己的就业做打算了,目前我学习的重点是大数据研发,愿与君共勉&lt;/p&gt;
&lt;p&gt;博客写作计划:每周至少用心写一篇,坚持最难得,希望我能坚持下去(怀疑)&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;写在前面的话&quot;&gt;&lt;a href=&quot;#写在前面的话&quot; class=&quot;headerlink&quot; title=&quot;写在前面的话&quot;&gt;&lt;/a&gt;写在前面的话&lt;/h1&gt;&lt;h2 id=&quot;以前的故事&quot;&gt;&lt;a href=&quot;#以前的故事&quot; class=&quot;headerlink&quot; title=
    
    </summary>
    
    
      <category term="闲话扯淡" scheme="http://jellygogo.com/tags/%E9%97%B2%E8%AF%9D%E6%89%AF%E6%B7%A1/"/>
    
  </entry>
  
</feed>
